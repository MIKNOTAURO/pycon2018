{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by DSX for sharing."
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "class hn_collector():\n    \n    import requests\n    from bs4 import BeautifulSoup\n    \n    def __init__(self):\n        self.API_BASE = 'https://hacker-news.firebaseio.com/v0/'\n        self.TOP ='topstories.json'\n        self.NEW ='newstories.json'\n        self.ITEM ='item/'\n        self.HEADERS = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36'}\n        \n    def get_top_stories(self):\n        return(eval(requests.get(self.API_BASE + self.TOP).content))\n    \n    def get_new_stories(self):\n        return(eval(requests.get(self.API_BASE + self.NEW).content))\n    \n    def get_story(self, story_id):\n        try:\n            return(eval(requests.get(self.API_BASE + self.ITEM + str(story_id)+\".json\").content))\n        except:\n            pass\n    \n    def get_text(self, story_url):\n\n        try:\n            page = requests.get(story_url, headers=self.HEADERS)\n            soup = BeautifulSoup(page.content,'lxml')\n            s= ' '.join([p.text for p in soup.find_all('p')])\n            return(s)\n        except:\n            return(None)\n        "
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "hn = hn_collector() #instantiate class then use methods to initiate process\n\nCURRENT_NEW = 'current_new.json'\nCURRENT_TOP = 'current_top.json'"
        }, 
        {
            "execution_count": 98, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "story_list = []\nNEW_STORIES = hn.get_new_stories()\ncos.download_file(Bucket=credentials['BUCKET'],Key='new_stories.json',Filename=CURRENT_NEW)\n\nwith open(CURRENT_NEW) as json_data:\n    d = json.load(json_data)\n    \ndf = json_normalize(d).drop_duplicates('url',keep='first')\ndiff_stories = set(NEW_STORIES) - set(df.id)\nfor story in list(diff_stories)[:100]:\n    try:\n        s = hn.get_story(story)\n        raw_text = hn.get_text(s.get('url',''))\n        s['kids'] = str(s.get('kids',None))\n        s['text'] = raw_text\n        story_list.append(s)\n    except Exception as e:\n        print(e)\n\nif len(story_list) > 0:\n    samp = pd.DataFrame(story_list).drop_duplicates('id').sort_values('time',ascending=False)\n    samp = samp[samp.text.str.len() > 200][:100]\n    samp.to_json(CURRENT_NEW,orient='records')\n    cos.upload_file(Filename='new_stories.json',Bucket=credentials['BUCKET'],Key=CURRENT_NEW)"
        }, 
        {
            "execution_count": 60, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "393\n"
                }
            ], 
            "source": "story_list = []\nTOP_STORIES = hn.get_top_stories()\ncos.download_file(Bucket=credentials['BUCKET'],Key=CURRENT_TOP,Filename=CURRENT_TOP)\n\nwith open(CURRENT_TOP) as json_data:\n    d = json.load(json_data)\n    \ndf = json_normalize(d).drop_duplicates('url',keep='first')\ndiff_stories = set(TOP_STORIES) - set(df.id)\n\nfor story in list(diff_stories)[:100]:\n    try:\n        s = hn.get_story(story)\n        raw_text = hn.get_text(s.get('url',''))\n        s['kids'] = str(s.get('kids',None))\n        s['text'] = raw_text\n        story_list.append(s)\n    except Exception as e:\n        print(e)\n\nif len(story_list) > 0:\n    samp = pd.DataFrame(story_list).drop_duplicates('id').sort_values('time',ascending=False)\n    samp = samp[samp.text.str.len() > 200][:100]\n    samp.to_json(CURRENT_TOP,orient='records')\n    cos.upload_file(Filename=CURRENT_TOP,Bucket=credentials['BUCKET'],Key=CURRENT_TOP)"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}