[{"by":"Gravityloss","descendants":13,"id":17028121,"kids":"[17028275, 17028232, 17029104, 17028372]","score":61,"text":"\nResearchers at the University of Exeter (UK) have developed a novel p-type LaFeO3 photoelectrode using an inexpensive and scalable spray pyrolysis method. The nanostructured photoelectrode results in spontaneous hydrogen evolution from water without any external bias applied with a faradaic efficiency of 30% and excellent stability.\n The researchers believe this new type of photoelectrode is not only cheap to produce, but can also be recreated on a larger scale for mass and worldwide use.\nAn open-access paper on the work is published in Scientific Reports.\n A promising way of storing solar energy is via chemical fuels, in particular hydrogen as it is considered as a future energy carrier. The greatest challenge is to develop a suitable technology for large scale and cost effective solar fuel production to compete with fossil fuel. One way this could be achieved is by using photoelectrochemical (PEC) water splitting which directly converts water and sunlight to solar fuel (hydrogen).  \u2026 Cost effective solar fuel generation is hindered by the semiconductor material not meeting certain essential criteria to achieve highly efficient solar to hydrogen conversion. These criteria are as follows: (i) the visible part of the solar spectrum must be absorbed for higher efficiency of hydrogen production and the band edges should ideally straddle the redox potential of water splitting, (ii) the photoexcited carriers must separate and migrate to the surface without recombination, (iii) adsorbed species must be reduced and oxidized by the photogenerated electrons and holes to produce H2 and O2. Also for cost effective, environmental and scalability issues, earth abundant non-toxic materials should be the focus of research into new semiconductor materials. \u2026 To the best of our knowledge, we report for the first time the nanostructured LaFeO3 photoelectrode for spontaneous hydrogen evolution from water without any external applied bias. \nTo prepare the photoelectrode, the researchers sprayed precursor solution at 150\u2009\u00b0C and then annealed at different temperature from 475\u2009\u00b0C to 625\u2009\u00b0C with an increment of 25\u2009\u00b0C to get single phase crystalline LaFeO3 material. \n \nThe team analyzed the photoelectrochemical (PEC) performance of LaFeO3 in 0.1\u2009M aqueous NaOH (pH 13) solution by illuminating the photoelectrode from the electrolyte side. \n They found the annealing temperature was found to be an important factor which directly affected the photocurrent density of the LaFeO3 photoelectrodes.\n \nThe water splitting was conducted in a glass reactor vessel. The LaFeO3 working electrode and Pt counter electrode were connected by a single looped wire, without any external bias being applied. Hydrogen was produced spontaneously during the water splitting test during the first 6\u2009hour cycle where the photoelectrode generated 0.18 \u03bcmol\/cm2 of hydrogen after 6\u2009hours, with a faradaic efficiency of 30%. \n \nIt then underwent a second cycle of water splitting test to determine if the electrode was re-usable and how much the performance varied. After a further 6\u2009hours illumination, the LaFeO3 thin film generated 0.08 \u03bcmol\/cm2 of hydrogen (Figure S8). This provided additional evidence that the film is re-useable, although the amount of hydrogen produced is almost halved, the researchers said.\n These findings demonstrate that LaFeO3 is a potential candidate to act as a photoelectrode for unassisted PEC water splitting to generate solar fuel (hydrogen) cost effectively. However further work is required to investigate and improve slow charge carrier dynamics and low light absorption challenges of LaFeO3 photoelectrodes. Resources \nGovinder S. Pawar & Asif A. Tahir (2018) \u201cUnbiased Spontaneous Solar Fuel Production using Stable LaFeO3 Photoelectrode\u201d Scientific Reports volume 8, Article number: 3501 doi: 10.1038\/s41598-018-21821-z Posted on 09 May 2018 in Hydrogen, Hydrogen Production, Solar fuels  | Permalink\n | \nComments (0)\n \n\t\t\t\tPosted by: \n\t\t\t\t\u00a0|\u00a0\n This is only a preview. Your comment has not yet been posted. The letters and numbers you entered did not match the image. Please try again. As a final step before posting your comment, enter the letters and numbers you see in the image below. This prevents automated programs from posting comments. Having trouble reading this image? View an alternate. \n\n\n \n            \t\t\t\t    (You can use HTML tags like <b> <i> and <ul> to style your text.)\n            \t\t\t\t Your Information \n                                (Name is required. Email address will not be displayed with the comment.)\n                            \n                             \n\nName is required to post a comment\n \n\nPlease enter a valid email address\n \n\nInvalid URL\n This weblog only allows comments from registered users. To comment, please enable JavaScript so you can sign in. More...","time":1525852828,"title":"Exeter team develops low-cost photoelectrode for water-splitting using sunlight","type":"story","url":"http:\/\/www.greencarcongress.com\/2018\/05\/20180509-exeter.html"},{"by":"openmosix","descendants":52,"id":17027287,"kids":"[17029228, 17029180, 17027869, 17028460, 17028084, 17028341, 17027878, 17027821]","score":86,"text":"The job-hunting website Glassdoor has been bought for $1.2 billion in what is one of the largest U.S. tech acquisitions of 2018. Recruit Holdings, a large Japanese human resources company that owns other job sites like Indeed, spent eight figures in cash to acquire the decade-old company. Glassdoor hadn\u2019t raised new money in about two years, when it was valued by investors at around $860 million, so it likely needed to decide whether to raise more money, sell or try to go public. The company reportedly was at least considering an IPO in the second half of 2018 and was interviewing banks that could take them there. The deal, at a premium compared to that last price, is a long-anticipated win for venture investors who have waited as long as eleven years to take home some cash. Early investors have included Benchmark, Sutter Hill Ventures and Battery Ventures. In addition to job listings, Glassdoor also gives employees the chance to anonymously describe their experience at companies to prospective employees. The deal is about as big as 2018\u2019s other major U.S. tech acquisition: Amazon\u2019s purchase of the smart doorbell company Ring. Sign up for our Recode Daily newsletter to get the top tech and business news stories delivered to your inbox. Sign up for our Recode Daily newsletter to get the top tech and business news stories delivered to your inbox. \"After this huge thing happens \u2014 our country gets attacked \u2014 I think the customers would have been like, \u2018Okay! That makes me feel like you\u2019ve got it!\u2019\" And there were zero fatalities in commercial airline crashes in 2017. \"[People don\u2019t] want to mix Facebook with their dating lives,\" says Match CEO Mandy Ginsberg. Zients, who is the CEO of Cranemere Group Limited, will officially join the board at the end of the month. A Verge affiliate site","time":1525837687,"title":"Glassdoor has been acquired by Recruit Holdings for $1.2B","type":"story","url":"https:\/\/www.recode.net\/2018\/5\/8\/17333912\/glassdoor-acquisiton-recruit-holdings-1-2-billion"},{"by":"davidmr","descendants":24,"id":17027097,"kids":"[17027489, 17027985, 17027117, 17027459, 17027580]","score":103,"text":"Welcome,  Log in to your Red Hat account Your Red Hat account gives you access to your member profile and preferences, and the following services based on your customer status: Your Red Hat account gives you access to your member profile, preferences, and other services depending on your customer status. For your security, if you're on a public computer and have finished using your Red Hat services, please be sure to log out. Press release Red Hat, Inc. (NYSE: RHT), the world's leading provider of open source solutions, today announced the first steps for integrating CoreOS Tectonic, Quay, and Container Linux with Red Hat\u2019s robust container and Kubernetes-based solutions portfolio. Container application platforms like Red Hat OpenShift Container Platform already provide CIOs with a powerful, open standards-based solution to fuel digital transformation efforts, helping enterprises more quickly adopt emerging technologies like Linux containers and Kubernetes without sacrificing existing applications or IT investments. CoreOS\u2019 technologies advance the comprehensive nature of Red Hat\u2019s container infrastructure offerings, providing a clear roadmap for the digital enterprise while simultaneously making hybrid cloud environments an excellent choice for deploying both modern and traditional applications. We strongly believe that the integration of CoreOS\u2019 automation technologies with Red Hat\u2019s powerful infrastructure solutions will redefine the hybrid cloud, meshing the simplicity of public cloud deployments with the enhanced security of private cloud computing. Acquired with CoreOS in January 2018, Tectonic and Container Linux will help drive automation at every layer of the cloud-native stack, backed by Red Hat\u2019s commitment to enterprise-grade stability and support. This automation will extend to Red Hat\u2019s robust independent software vendor (ISV) ecosystem, enabling them to more easily deliver and maintain applications and services on top of Red Hat OpenShift Container Platform across hybrid environments with the simplicity of public clouds. OpenShift automated operations\nTectonic, CoreOS\u2019 enterprise Kubernetes solution, offered a powerful way to manage large Kubernetes footprints through automated \u201cover-the-air\u201d updates. With this feature, systems administrators and IT managers can more easily roll-out upgrades to entire Tectonic clusters and underlying Container Linux hosts all via an automated process. Now, Red Hat plans to integrate this capability with Red Hat OpenShift Container Platform, Red Hat\u2019s comprehensive enterprise-grade Kubernetes distribution, as automated operations. With automated operations, IT teams will be able to use the automated upgrades of Tectonic paired with the reliability, support, and extensive application development capabilities of Red Hat OpenShift Container Platform. This makes managing Kubernetes deployments at-scale easier, with the vast majority of rote maintenance tasks performed automatically, lessening the need for constant administrator action and providing a \u201clights out\u201d approach to cluster oversight. Other enterprise needs are retained through the addition of automated operations to Red Hat OpenShift as well, including platform stability and support for existing IT assets. The Operator Framework\nCoreOS also established the concept of \u201coperators\u201d within Kubernetes, application-specific controllers that extend the Kubernetes API to create, configure, and manage instances of complex stateful applications on behalf of a Kubernetes user. This effectively takes the \u201chuman knowledge\u201d of managing a Kubernetes application and builds it into software, making typically challenging workloads easier to deploy and maintain on Kubernetes. Announced at KubeCon Europe 2018, the Operator concept is now encapsulated by the Operator Framework open source project. Building on this initiative, Red Hat today announced that Red Hat OpenShift Container Platform will use this project for the benefit of Red Hat\u2019s ISV ecosystem. This makes it easier for ISVs to bring cloud services, like messaging, big data, analytics, and more, to the hybrid cloud and address a broader set of enterprise deployment models while avoiding cloud lock-in. Red Hat also intends to extend its existing ISV certification program to encompass the automation capabilities provided by the Operator Framework. The result will be a consistent, common experience for these services on Red Hat OpenShift, enabling ISVs to bring their offerings to market more quickly on any cloud infrastructure where Red Hat OpenShift runs. Bringing Container Linux to Red Hat OpenShift\nContainer Linux provides several key pieces of the modern, container-native operating system, most notably a fully immutable, container-optimized Linux host that includes automated, \u201cover-the-air\u201d updates, to keep large deployments up to date more easily. Built around a robust existing community, Container Linux plans to \u00a0retain its vision of providing a free, fast-moving, and automated container host while also providing content options from the Red Hat Enterprise Linux and Fedora ecosystem, with a supported variant being provided under the name Red Hat CoreOS. Red Hat CoreOS is expected to integrate concepts, technology, and the user experience of Container Linux. This offering is intended to ultimately supersede Atomic Host and function as Red Hat\u2019s immutable, container-centric operating system. Red Hat CoreOS is also expected to provide the foundation for Red Hat OpenShift Container Platform, Red Hat OpenShift Online, and Red Hat OpenShift Dedicated for customers who prefer an immutable infrastructure-based Kubernetes platform with automated updates. Red Hat OpenShift Container Platform will also continue to support Red Hat Enterprise Linux, for customers who prefer a traditional lifecycle and packaging as the foundation for their Kubernetes deployments.  Red Hat Quay and OpenShift\nOver the past few years, many Red Hat OpenShift customers have used CoreOS Quay as their enterprise registry solution. While OpenShift provides an integrated container registry, customers who require more comprehensive enterprise grade registry capabilities now have the option to get Quay Enterprise and Quay.io from Red Hat. Quay includes automated geographic replication, integrated security scanning with Clair, image time machine for viewing history, performs rollbacks and automated pruning, and more. Quay is now added to the Red Hat portfolio, available both as an enterprise software solution and as a hosted service at Quay.io, and is expected to see future enhancements and continued integration with OpenShift in future releases. Availability\nTectonic\u2019s automated operations, Red Hat CoreOS and more are expected to be fully integrated into Red Hat OpenShift Container Platform in future versions. Container Linux is expected to \u00a0continue to be maintained while its successor will be developed with the Fedora and CoreOS Communities. Red Hat Quay is available immediately at https:\/\/quay.io\/. Press Conference\nRed Hat executives, including Paul Cormier, the company\u2019s president of Products and Technologies, will host a webcast live from Red Hat Summit to discuss this and today's other announcements at 2 p.m. ET. Following remarks, press and analysts are invited to participate in a question and answer session. To join the webcast or view the replay after the event, visit: https:\/\/onlinexperiences.com\/Launch\/QReg\/ShowKey=51468 Supporting Quote\nAshesh Badani, vice president and general manager, OpenShift, Red Hat\n\u201cWe strongly believe that the integration of CoreOS\u2019 automation technologies with Red Hat\u2019s powerful infrastructure solutions will redefine the hybrid cloud, meshing the simplicity of public cloud deployments with the enhanced security of private cloud computing. Previously, enterprises had to choose between public cloud lock-in for ease-of-use or managing the complexity of a hybrid IT environment to retain full control over workloads and data. Now, Red Hat OpenShift Container Platform will be positioned to settle this argument, delivering automation across the entire container stack, from the underlying operating system to the application services, to make hybrid IT easier to consume while retaining enhanced security, driving a new model for how enterprises perceive the open hybrid cloud.\u201d Red Hat is the world's leading provider of open source software solutions, using a community-powered approach to provide reliable and high-performing cloud, Linux, middleware, storage and virtualization technologies. Red Hat also offers award-winning support, training, and consulting services. As a connective hub in a global network of enterprises, partners, and open source communities, Red Hat helps create relevant, innovative technologies that liberate resources for growth and prepare customers for the future of IT. Learn more at http:\/\/www.redhat.com. Certain statements contained in this press release may constitute \"forward-looking statements\" within the meaning of the Private Securities Litigation Reform Act of 1995. Forward-looking statements provide current expectations of future events based on certain assumptions and include any statement that does not directly relate to any historical or current fact. Actual results may differ materially from those indicated by such forward-looking statements as a result of various important factors, including: risks related to the ability of the Company to compete effectively; the ability to deliver and stimulate demand for new products and technological innovations on a timely basis; delays or reductions in information technology spending; the integration of acquisitions and the ability to market successfully acquired technologies and products; risks related to errors or defects in our offerings and third-party products upon which our offerings depend; risks related to the security of our offerings and other data security vulnerabilities; fluctuations in exchange rates; the effects of industry consolidation; uncertainty and adverse results in litigation and related settlements; the inability to adequately protect Company intellectual property and the potential for infringement or breach of license claims of or relating to third party intellectual property; changes in and a dependence on key personnel; the ability to meet financial and operational challenges encountered in our international operations; and ineffective management of, and control over, the Company's growth and international operations, as well as other factors contained in our most recent Annual Report on Form 10-K (copies of which may be accessed through the Securities and Exchange Commission's website at http:\/\/www.sec.gov), including those found therein under the captions \"Risk Factors\" and \"Management's Discussion and Analysis of Financial Condition and Results of Operations\". In addition to these factors, actual future performance, outcomes, and results may differ materially because of more general factors including (without limitation) general industry and market conditions and growth rates, economic and political conditions, governmental and public policy changes and the impact of natural disasters such as earthquakes and floods. The forward-looking statements included in this press release represent the Company's views as of the date of this press release and these views could change. However, while the Company may elect to update these forward-looking statements at some point in the future, the Company specifically disclaims any obligation to do so. These forward-looking statements should not be relied upon as representing the Company's views as of any date subsequent to the date of this press release. Red Hat unveils integration roadmap for CoreOS technologies with the Red Hat OpenShfit portfolio. Red Hat, CoreOS, OpenShift, Tectonic, Quay, Container Linux, Fedora, etc, Prometheus, Red Hat Enterprise Linux Read more about Red Hat OpenShift Container Platform Find out more about Red Hat Quay Learn about the Operator Framework Learn more about Red Hat Summit Follow @RedHatSummit or via the hashtag #RHSummit on Twitter Become a fan of Red Hat Summit on Facebook","time":1525833976,"title":"Red Hat Releases Roadmap for CoreOS Integration","type":"story","url":"https:\/\/www.redhat.com\/en\/about\/press-releases\/red-hat-unveils-roadmap-coreos-integration-red-hat-openshift"},{"by":"sconstantinides","descendants":9,"id":17026150,"kids":"[17027156, 17028536, 17028797, 17026580]","score":67,"text":"In case you haven\u2019t heard, Progressive Web Apps (PWAs) are finally ready for prime time. It might not yet be obvious to many people how to install a PWA, but if you\u2019ve done it once you won\u2019t forget it and it\u2019s simpler than using an app store. There are many reasons to start building PWAs and converting current responsive web apps, including: You need 4 things to make a PWA: HTTPS hosting, a service worker, a properly configured index.html file, and a web app manifest.json file. The examples below are geared towards React but are similar for any framework. Firebase provides free SSL certificates and freemium hosting. Another great choice is Netlify. If you want your app to work offline once installed, you\u2019ll need a service worker. Create React App makes one for you, but you can always configure your own using something like this. Learn more about how they work. A challenge in configuring your app is understanding the difference in how iOS and Android use the meta tags in index.html and the web app manifest. We\u2019ll explain how each option is used below. One painful part to this process is creating the massive number of splash screens for iOS: one for each screen size and orientation you want to support, otherwise users will see a white screen while your app loads. Create React App makes a manifest.json file in your public directory, but if you don\u2019t have one yet create it and make sure it\u2019s referenced in index.html (lines 19\u201320 above). With a service worker, your app loads without a network connection, however it won\u2019t have much functionality. Enter Firebase. Firebase\u2019s brand new Cloud Firestore improves upon their Realtime Database with several enhancements but most notably it will continuously attempt to sync data while offline. To make sure users also *start* with data when they launch your PWA without a connection, use localStorage. Our sample React app combines these two methods to let you access tasks you\u2019ve already created and add new ones regardless of connection status. Much like responsive design, PWAs offer unique design options. Should something be styled differently when viewed as an installed PWA and when viewed on the same device but in a browser? Here are handy media queries for targeting installed PWAs: Similarly, to see how users are viewing your PWAs in JavaScript: By clapping more or less, you can signal to us which stories really stand out. UX Designer\/Engineer We serve as digital craftsmen. We combine emerging technology, creativity, and exceptional usability to build beautiful products and unique experiences. https:\/\/perficientdigitallabs.com","time":1525820854,"title":"Building a Progressive Web App in React, using Firestore for offline support","type":"story","url":"https:\/\/blog.truthlabs.com\/building-a-progressive-web-app-in-react-11c77a7fccb3"},{"by":"abhi3","descendants":175,"id":17025212,"kids":"[17026066, 17025648, 17025837, 17025569, 17026958, 17025776, 17026382, 17025954, 17028708, 17025441, 17026405, 17025728, 17025681, 17027905, 17026644, 17026874, 17027331, 17026282, 17026384, 17026280, 17027147, 17026684, 17025898, 17025876, 17026217, 17026971, 17026201, 17026398, 17028001, 17026710, 17025547, 17026922, 17025970, 17026093, 17025519, 17025817]","score":160,"text":" Mindfulness meditation has been practiced for millennia \u2013 and today is a\u00a0billion-dollar business. But how much does the practice really change our health? In late 1971, US Navy veteran Stephen Islas returned from Vietnam, but the war continued to rage in his head. \u201cI came very close to committing suicide when I came home, I was that emotionally and mentally damaged,\u201d Islas remembers. At his college campus in Los Angeles, a friend suggested he check out a meditation class. He was sceptical, but he found that before long \u201cthere were moments that started shifting, where I was happy. I would experience these glimpses of calmness.\u201d Forty-six years later, Islas says that he has never completely freed himself from his post-traumatic stress disorder (PTSD), which was formally diagnosed in 2000 at the Veterans Affairs (VA) West Los Angeles Medical Center. But he\u2019s convinced that meditation has saved his life. Various forms of meditation are now routinely offered to veterans with PTSD. It\u2019s also touted as a therapeutic tool to help anyone suffering from conditions and disorders including stress, anxiety, depression, addiction and chronic pain. More broadly, meditation has come into vogue as a way to enhance human performance, finding its way into classrooms, businesses, sports locker rooms and people\u2019s smartphones through Internet apps like Headspace and Calm. You might also like:\u2022 Can meditation prevent the effects of ageing? \u2022 An effortless way to improve your memory \u2022 Why it pays to be grumpy and bad-tempered \u2018Mindfulness\u2019 meditation, a type of meditation that focuses the mind on the present moment, is wildly popular. It has even become a billion-dollar business. For all its popularity, however, it\u2019s still unclear exactly what mindfulness meditation does to the human brain, how it influences health and to what extent it helps people suffering from physical and mental challenges. Meditation has been practiced for thousands of years, but psychologists and neuroscientists have studied it for only a few decades.  Some studies suggest that meditation can help people relax, manage chronic stress and even reduce reliance on pain medication. Some of the most impressive studies to date involve a treatment called mindfulness-based cognitive therapy, which combines meditation with psychotherapy to help patients deal with thoughts that lead to depression. Randomised controlled trials have shown that the approach significantly reduces the risk of depression relapse in individuals who have previously had three or more major depressive episodes. But many other studies on the effects of meditation have used only small numbers of subjects, lacked follow-up and generally been less scientifically rigorous than other medical studies \u2013 clinical trials for new drugs, for example. A 2017 article that assessed evidence on meditation as a treatment for PTSD summed up the overall state of affairs: \u201cThis line of research is in its relative infancy.\u201d  While questions about the clinical outcomes of meditation persist, other studies have focused on a more fundamental issue: does meditation physically change the brain? It\u2019s a tough question to answer, but as brain imaging techniques have advanced and meditation interventions have grown more popular, scientists have begun to take a systematic look at what\u2019s going on. Seeking stillness Meditation that requires one to sit still and focus on the mere act of breathing can encourage mindfulness, says psychologist David Creswell, who directs the Health and Human Performance Laboratory at Carnegie Mellon University in Pittsburgh. But most people spend most or all of their day being anything but mindful. They skip from one thought to another. They daydream. They ruminate about the past, and they worry about the future. They self-analyse and self-criticise.  In a 2010 study, Harvard researchers asked 2,250 adults about their thoughts and actions at moments throughout their day via an iPhone app. People\u2019s minds wandered 47% of the time and mind wandering often triggered unhappiness, the scientists reported in Science.  The capacity to be mindful is associated with higher well-being in daily life \u2013 David Creswell  \u201cIn contrast, the capacity to be mindful is associated with higher well-being in daily life,\u201d Creswell wrote in the 2017 Annual Review of Psychology. He cites a 2003 study showing a correlation between mindfulness and a number of indicators of well-being.  When people who meditate say they are paying attention to the present moment, they may be focused on their breathing, but maybe also on an emotion that surfaces and then passes, a mental image, inner chatter or a sensation in the body. \u201cAdopting an attitude of openness and acceptance toward one\u2019s experience is critical\u201d to becoming more mindful, Creswell says. The idea is to be view these moments with a detached and non-judgmental curiosity. Creswell first became interested in mindfulness meditation when he took courses on psychology and Buddhism in high school. Later, in graduate school, he began studying meditation in connection with reducing stress and improving overall health. \u201cAs a scientist, I\u2019m never convinced. I\u2019ve been trained to be sceptical,\u201d Creswell says. \u201cNonetheless, I do think that there were a number of experiences I had while on meditation retreats that really struck me as very foundational.\u201d Even the simple but challenging act of sitting still for an hour while meditating made a great impact on Creswell. \u201cHaving this disconnect between my body feeling in pain but my mind being completely silent and open\u2026 these were very powerful insights for me about how a [meditation] practice could really change people\u2019s lives, or fundamentally change how they relate to suffering in their lives,\u201d he says. \u201cThere wasn\u2019t a bolt-of-lightning moment for me, but a lot of these moments of insight in my own retreat experiences that suggested to me that it was worth spending time and effort to do the science.\u201d People from different religious, cultural and philosophical backgrounds have expounded the benefits of meditation for millennia. Meditation is perhaps most commonly associated with Buddhism, which views it as an instrument for achieving spiritual fulfilment and peace. Creswell calls the act of meditation \u201ca basic feature of being human.\u201d  But the scientific evidence for its benefits is still lacking.  Mindfulness-based therapies have shown a mixture of only moderate, low or no efficacy, depending on the disorder being treated  \u201cThere is a common misperception in public and government domains that compelling clinical evidence exists for the broad and strong efficacy of mindfulness as a therapeutic intervention,\u201d a group of 15 scholars wrote in a recent article entitled Mind the Hype. The reality is that mindfulness-based therapies have shown \u201ca mixture of only moderate, low or no efficacy, depending on the disorder being treated,\u201d the scholars wrote, citing a 2014 meta-analysis commissioned by the US Agency for Healthcare Research and Quality. Much more research is needed before scientists can say what mental and physical disorders, in which individuals, can be effectively treated with mindfulness meditation, they concluded. Mudra mind  Alongside clinical work, neuroscientists have wanted to know how, if at all, meditation might change what actually happens inside the brain. Does meditation make certain regions more active than others, or more robustly connect one region to another? Does meditation result in new neurons, actually changing brain structure? Some studies suggest the answer is yes.  Mindfulness meditation may spark neuroplastic renovations in the brain\u2019s function and structure  Neuroscientists have studied the physical effects of mindfulness meditation using functional magnetic resonance imaging (fMRI) and other techniques for the last two decades. Progress has followed on the growing recognition that the human brain is capable of physical changes throughout adulthood, even into old age \u2013 forming new connections and growing new neurons when someone learns a new skill, challenges themselves mentally or even just exercises. The emerging view of a brain that can be continually shaped through experience, dubbed neuroplasticity, replaced the long-held idea that after the first few decades of life, the brain\u2019s physiological trajectory was basically one of decline. A number of brain studies suggest that mindfulness meditation may spark neuroplastic renovations in the brain\u2019s function and structure.  Looking under the hood with fMRI, scientists have found that mindfulness meditation activates a network of brain regions that includes the insula (associated with compassion, empathy and self-awareness), the putamen (learning) and portions of the anterior cingulate cortex (regulating blood pressure, heart rate and other autonomic functions) and the prefrontal cortex (the hub of higher-order thinking skills such as planning, decision-making and moderating social behaviour). It\u2019s uncertain, however, whether these changes in brain activity can be sustained when the individual is not actively meditating, and if so how much people need to meditate for that to happen. When it comes to actual structural changes in the brain, some studies suggest that mindfulness meditation may increase grey matter density in the hippocampus, a brain region essential to memory. Researchers including Britta H\u00f6lzel, now at the Technical University of Munich, and Sara Lazar of Massachusetts General Hospital found evidence for this in a 2011 study. Though intriguing, these studies are nowhere near the end goal. \u201cWe need to understand the benefits that the changes in the brain have on behaviour and well-being,\u201d H\u00f6lzel says. \u201c\u2018Changing the brain\u2019 sounds very impressive, but we don\u2019t understand what it actually means.\u201d Lazar agrees. \u201cMost of the data has only looked at changes over the course of two months of [meditation] practice\u2026 Most people feel that [meditation] continues to change and get deeper with extended practice. So we need to conduct studies that follow people for much longer time points.\u201d Brain wave Based on their studies of people engaged in meditation, Creswell and his colleagues have proposed that mindfulness acts as a buffer specifically against stress. It does this by increasing activity in regions of the prefrontal cortex that are important for \u201ctop-down stress regulation\u201d, while reducing activity and functional connectivity in regions associated with the brain\u2019s fight-or-flight stress response \u2013 in particular the amygdala. The idea that mindfulness meditation engages parts of the brain involved in top-down stress regulation is widely accepted among researchers, says University of Michigan clinical psychologist Anthony King. But what\u2019s happening in relation to the amygdala is less clear, he says. The amygdala, one of the most primitive parts of the brain, is not just a simple alarm centre associated with responding to threats. It\u2019s central to what\u2019s called the salience network, which is vital for noticing all kinds of important things in one\u2019s environment. In a mother, for example, the amygdala may become very active in response to her baby\u2019s joyful face.  Mindfulness meditation \u201chelps people have what the old school psychotherapists call \u2018reflective capacity,\u2019\u201d King says. \u201cInstead of automatically responding in certain ways, it allows people to have more nuance in their ability to respond to any type of situation \u2013 stressful, fearful or otherwise \u2013 and create some psychological distance.\u201d Two studies by Creswell and his colleagues, one in 2015 and the other in 2016, offer some initial findings that seem to support their view of mindfulness meditation as a buffer against stress. Both studies focused on the physiological effects of mindfulness mediation training on small groups of unemployed adults experiencing stress.  In the 2015 study, the researchers found that three days of intensive mindfulness meditation training reduced functional connectivity between the right amygdala, associated with the fight-or-flight stress response, and the subgenual anterior cingulate cortex, which plays a role in modulating emotions. In the 2016 study, the researchers found that three days of intensive mindfulness meditation training led to increased connectivity between the default mode network, a network of regions engaged when the brain is at rest, and parts of the prefrontal cortex involved in regulating stress. The study also found that meditation led to reduced levels of interleukin-6, a biomarker in the blood for systemic inflammation that\u2019s elevated in high-stress populations. King and his colleagues showed similarly promising results in 23 combat veterans of Afghanistan and Iraq with post-traumatic stress disorder in 2016. Brain scans before and after mindfulness-based group therapy revealed an increase in resting-state connectivity between a network in the brain that allows people to control their attention and other parts of the brain involved in rumination and spontaneous thought. This particular connectivity has been seen in healthy people, as well as people who have meditated for long periods, says King. \u201cWhat\u2019s important about our study\u2026 is that people with PTSD can also have this change in brain connectivity patterns when they do mindfulness practice,\u201d King says. The more this connectivity increases as a result of mindfulness training, \u201cthe more their symptoms improve,\u201d he adds, summarising a key finding of the study.  Studies of other conditions suggest similar improvements, although many involve small numbers of subjects and other limitations that make them far from conclusive.  Mindfulness meditation may alleviate symptoms of general anxiety disorder  Nevertheless, mindfulness meditation may alleviate symptoms of general anxiety disorder by increasing connectivity between the amygdala and the prefrontal cortex, thereby increasing a patient\u2019s ability to regulate emotions. Meditation may also lessen the perception of pain by reducing pain-related activation of the somatosensory cortex and increasing activation of areas involved in the cognitive regulation of pain. Work ahead Fundamentally, mindfulness is an elusive quality to study. It\u2019s an internally generated experience, not a drug that scientists can give to a patient. That creates a question when comparing mindfulness between individuals and especially between distinct studies. What\u2019s more, there is no universally accepted definition of mindfulness or agreement among researchers on the details of what it entails, Lazar and her colleagues note in the Perspectives on Psychological Science article.  In the context of PTSD, King says it\u2019s likely that mindfulness meditation will continue to supplement more conventional psychiatric treatments. \u201cI would never recommend for people to go to a mindfulness class at the YMCA or the local health centre and think that that\u2019s going to be the same as psychotherapy, because it is not. It really is not,\u201d King says. But \u201cI think mindfulness is a useful technique in the context of therapy with somebody who\u2019s trained in PTSD treatment.\u201d But people like Islas who have faced serious mental illness, and others who use mindfulness meditation to ease daily stress, say they\u2019re convinced the practice improves their lives. One day, scientists hope to be able to link that experience to what\u2019s physically happening in the meditating mind. This article originally appeared in Knowable Magazine, and is republished under a Creative Commons licence. Join 500,000+ Future fans by liking us on\u00a0Facebook, or follow us on\u00a0Twitter,\u00a0Google+,\u00a0LinkedIn\u00a0and\u00a0Instagram If you liked this story,\u00a0sign up for the weekly bbc.com features newsletter, called \u201cIf You Only Read 6 Things This Week\u201d. A handpicked selection of stories from BBC Future, Earth, Culture, Capital, Travel and Autos, delivered to your inbox every Friday. \n\n","time":1525814198,"title":"Mindfulness may have been over-hyped","type":"story","url":"http:\/\/www.bbc.com\/future\/story\/20180502-does-mindfulness-really-improve-our-health"},{"by":"alanfranzoni","descendants":235,"id":17024245,"kids":"[17025003, 17027277, 17025765, 17029204, 17026386, 17024656, 17025346, 17027461, 17026327, 17028449, 17026343, 17028555, 17027158, 17028216, 17024743, 17024479, 17024947, 17026664, 17025717, 17027676, 17026600, 17028684, 17024851, 17025088, 17025400, 17026107, 17026133, 17025010, 17024571, 17027246, 17025999, 17027838, 17025755, 17027523, 17024981, 17024734, 17024773, 17026786]","score":320,"text":"\n\n\n\n Android Ten years ago, when we launched the first Android phone\u2014the T-Mobile G1\u2014it was with a simple but bold idea: to build a mobile platform that\u2019s free and open to everyone. Today, that idea is thriving\u2014billions of people around the world rely on their Android phone every day.  To make Android smarter and easier to use than ever, today we\u2019re unveiling a beta version of Android P, the next release of Android. Android P makes your smartphone smarter, helping it learn from and adapt to you. Take battery life, for instance\u2014I think all of us often wish we had more of it. In Android P, we partnered with DeepMind to build Adaptive Battery, which prioritizes battery power only for the apps and services you use the most, to help you squeeze the most out of your battery. We also used machine learning to create Adaptive Brightness, which learns how you like to set the brightness slider given your surroundings. Across the platform, your phone will help you better navigate your day, using context to give you smart suggestions based on what you like to do the most and automatically anticipating your next action. App Actions, for instance, help you get to your next task more quickly by predicting what you want to do next. Say you connect your headphones to your device, Android will surface an action to resume your favorite Spotify playlist. Actions show up throughout Android in places like the Launcher, Smart Text Selection, the Play Store, the Google Search app and the Assistant.  Adaptive Battery App Actions Slices We want the entire device experience to be smarter, not just the OS, so we\u2019re bringing the power of Google\u2019s machine learning to app developers with the launch of ML Kit, a new set of cross-platform APIs available through Firebase. ML Kit offers developers on-device APIs for text recognition, face detection, image labeling and more. So mobile developers building apps like Lose It!, a nutrition tracker, can easily deploy our text recognition model to scan nutritional information and ML Kit\u2019s custom model APIs to automatically classify over 200 different foods with your phone\u2019s camera.  With Android P, we put a special emphasis on simplicity. The look and feel of Android is more approachable with a brand new system navigation. In Android P, we\u2019re extending gestures to enable navigation right from your homescreen. This is especially helpful as phones grow taller and it\u2019s more difficult to get things done on your phone with one hand. With a single, clean home button, you can swipe up to see a newly designed Overview, the spot where at a glance you have full-screen previews of your recently used apps. Simply tap to jump back into one of them. If you find yourself constantly switching between apps, we\u2019ve got good news for you: Smart Text Selection (which recognizes the meaning of the text you\u2019re selecting and suggests relevant actions) now works in Overview, making it easier to perform the action you want. Changing how you navigate your phone is a big deal, but small changes can make a big difference too. Android P also brings a redesigned Quick Settings, a better way to take and edit screenshots (say goodbye to the vulcan grip that was required before), simplified volume controls, an easier way to manage notifications and more. You\u2019ll notice small changes like these across the platform, to help make the things you do all the time easier than ever. \u00a0 Dashboard, App Timer, Wind Down Beyond smarts, simplicity and digital wellbeing, there are hundreds of additional improvements coming in Android P, including security and privacy improvements such as DNS over TLS, encrypted backups, Protected Confirmations and more.\u00a0\u00a0 Android P Beta is available today on Google Pixel. And thanks to work on Project Treble, an effort we introduced last year to make OS upgrades easier for partners, a number of our partners are making Android P Beta available today on their own devices, including Sony Xperia XZ2, Xiaomi Mi Mix 2S, Nokia 7 Plus, Oppo R15 Pro, Vivo X21, OnePlus 6, and Essential PH\u20111.\u00a0\u00a0 Since we first launched Android ten years ago, we\u2019ve been focused on how to build a platform for everyone. Android P is an important step toward bringing machine learning to everyone with an operating system that learns from you, adapts to you and helps you with everyday tasks. \n              Follow Us\n            ","time":1525809091,"title":"Android P","type":"story","url":"https:\/\/www.blog.google\/products\/android\/android-p\/"},{"by":"hackyio","descendants":11,"id":17024127,"kids":"[17027021, 17024722, 17025544]","score":11,"text":"In late 2016, whilst leading the Developer Platform team at Intercom, I published a blog post titled \u201cBrowsers, not apps, are the future of mobile.\u201d It quickly became the most-read post published on Inside Intercom that year, and generated a lot of debate\u200a\u2014\u200aexternally on Hacker News and Medium, and internally within Intercom. At one point I was summonsed to the Inside Intercom podcast to explain myself. For some people, I had hit a nerve. So, 18 months later, what\u2019s changed? Are native apps dead yet? Are browsers and the web still the future of mobile? What is a browser, anyway? Let\u2019s dig in. The main argument of the post was this: browsers and the web are fast becoming the mobile operating system of the future, and native mobile apps are dying. There were three theories core to the argument, each of which i\u2019ll revisit and reexamine here. Recent mobile infrastructure, standards, and product development trends are fast making this theory a reality for most internet businesses. Granted, native apps are still useful for services like messengers and social networks\u200a\u2014\u200aall of which demand hours of user time daily (more on those types of apps later). For everything else, though, native apps are bloated and unnecessary. Networks like Verizon have confirmed their ambition to launch 5G broadband before the end of 2018. A battle between Samsung, Ericsson, Nokia and Huawei to become the 5G infrastructure provider of choice is also hotting up. Native apps were useful at a time when spotty 2G connections meant our smartphones were in offline mode most of the day. 5G is slated to be about 10 times faster than 4G, with less latency to boot\u200a\u2014\u200athe \u2018pipes\u2019 are in place to enable fast and immediate streaming of immersive and responsive experiences through the browser. No need for native apps. Standards have evolved quickly too, in favor of the mobile web. Fast-following Chrome and ChromeOS, Microsoft launched Progressive Web Apps to Microsoft Edge and the half a billion devices running Windows 10. This is a huge leap towards adoption of browser based progressive mobile web apps, particularly for enterprise users. And, hidden in the release notes of Safari 11.1 on iOS 11.3, was the addition of Service Workers and Payments APIs, key elements of progressive web apps. Apple still rely on Native apps sold through their App Store to bolster revenues, hence the lack of fanfare about this update. But developers now have a viable web based alternative to native apps. Realising that native apps are good for some things, but not all things, businesses are allocating resources to progressive web apps over iOS or Android apps. Platforms like Mobify are helping retailers like Debenhams, Crocs, and Lancome to make the transition. The frictionless mobile web experience (no native app download required) gave Lancome a 17% lift in mobile revenue, whilst Debenhams reported double digit increases in mobile revenues within weeks of launching their progressive web app. Money talks, and there\u2019s more of it to be made on the mobile web if you\u2019re an ecommerce business. Key to this theory is an evolving definition of what a \u2018browser\u2019 is. We\u2019re still spending increasing amounts of time inside messaging apps and social networks, themselves wrappers for the mobile web. They\u2019re new types of browsers, bringing social context and connections into the experience, something traditional browsers lack. And, in markets like India and China, these social networks and messengers are main way new internet users discover content on the web. The lines that divide traditional browsers, social networks, and messengers are blurring quickly. Mary Meeker\u2019s excellent KPCP 2017 Internet Trends report highlights just how blurry those lines have become. The slide below on China tells some interesting stories. Aside from Tencent now dominating the market over incumbents Alibaba and Baidu, messaging apps like WeChat (Tencent) are directly compared to \u2018traditional\u2019 browsers like UC Browser (Alibaba). In China, legacy categorisations like \u2018social network\u2019 or \u2018browser\u2019 don\u2019t matter. What matters are the tools that enable users to create, consume, and share information with each other, and the usage of those tools. On mobile, traditional browsers are but one of these tools. These slides on India tell a similar story, even if it\u2019s not immediately apparent. One one hand, \u2018Mobile Browser Usage Market Share\u2019 only includes traditional browsers like UC Browser, Opera, and Chrome. Messengers and social networks are nowhere to be seen. The full story becomes clear one slide later. Of the Top 10 Downloaded Android Apps, UC Browser appears just 6th in the list, far behind WhatApp and Facebook Messenger in 1st and 2nd place\u200a\u2014\u200aboth comparable products to WeChat in China. Let\u2019s not forget that UC Browser was mentioned as the market leading mobile browser in the previous slide. This is not accurate. Users in India are primarily creating, consuming and sharing information through messengers, not through traditional browsers. It\u2019s time to rethink our definition of what a browser is. Why do we use social networks and messengers? In part, to discover relevant information based on friend recommendations and to ask businesses for product recommendations. The information shared back to us includes links to pages on the internet. This is browsing the web, just a more modern and personalised way of doing it. This is the idea that bots are new type of intelligent, dynamic bookmark for mobile web browsers. Based on previous messenger interactions, bots push us relevant content, with improved relevancy over time. Like a social network feed, but based on your interactions only\u200a\u2014\u200anot those of your friends. For the most part, this has come to pass. Pinterest acknowledged the value of this new way to browse the internet through their bot, which recommends new pins based on users\u2019 previous requests and interactions. AI curation bots like Neil take this idea one step further, by using like, dislike, and bookmark additions as signals to improve the relevancy of recommendations. In Mexico, airline Aeromexico leveraged the power of Facebook Messenger bots to provide destination inspiration to customers, help them book flights, and guide them to knowledge base content to address frequently asked questions. And Tommy Hilfiger took the ecommerce browsing experience to Messenger through their \u201cSee now, buy now\u201d bot, which allows customers to purchase items featured on a virtual runway. Just two of the 300,000 active bots available on Facebook\u2019s Messenger platform. The evolution of the internet has come full circle. Whereas the world wide web started out as a collection of connected sources of information, native mobile apps siloed that information again, adding friction to our experience. Progressive web apps, and improved 5G connectivity are set to break those silos, reinstating the web as the most popular mobile operating system in the world\u200a\u2014\u200anot iOS or Android. For developers and start ups, this means a dedicating more focus to mobile web technologies, from progressive web apps, to new ways of delivering those apps closer to users and their mobile devices. New tools like Netlify have made this easier and cheaper than ever. It also means valuable time is spent creating new value\u200a\u2014\u200anot reinventing the wheel across multiple operating systems. And where do distribution opportunities exist\u200a\u2014\u200anot just in China and India, but globally? The biggest opportunities are still in consumer social and messaging apps, the new mobile browsers for an increasingly bot-enabled world. Originally published at www.developerecosystem.com. By clapping more or less, you can signal to us which stories really stand out. AI Platform Product Management & DX at @ZalandoTech. Previous: Platform at @Facebook & @Intercom. Blog: https:\/\/www.developerecosystem.com\/ Strategies and tools to build, grow and participate in developer ecosystems","time":1525808379,"title":"Browsers, not apps, are still the future of mobile","type":"story","url":"https:\/\/medium.com\/developer-ecosystem\/browsers-not-apps-are-still-the-future-of-mobile-e42f661f12eb"},{"by":"skybrian","descendants":0,"id":17024097,"kids":"None","score":7,"text":"The other day, I ran a photograph of my penis potato through an AI to see what the technology would call it. Would it know my potato was a potato despite the penis-like protuberance that had earned the tuber its nickname? I asked the system to look at several different shots of my penis potato\u200a\u2014\u200awith flash and without, indoor and outdoor and at a variety of angles\u200a\u2014\u200aand obtained answers that ranged from \u2018butternut squash\u2019 to \u2018dough,\u2019 even when I shot the potato in such a way that its private parts were demurely hidden. What I didn\u2019t know at the time was that the system would never identify my potato as a potato, not because of its penis, but because it did not know about potatoes at all. The AI I was using is famous in certain circles and performed remarkably well in the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) a few years back. For those unfamiliar with this contest, I\u2019d compare it to the Kentucky Derby, well known and equally exciting to those interested in horses and racing. The AI is called VGG-19, and ImageNet, the image data set used to train and test it, is famous in its own right, providing thousands of labeled images that researchers can use. As of now, according the site, ImageNet contains over fourteen million images for over 21,000 categories of things; however, only 1000 of these categories are used in the competition\u200a\u2014\u200a1000 synsets, as they are called, of which \u2018potato\u2019 is not one. In other words, because the AI had been trained on the ILSVRC contest data set, no matter how often I showed the system a potato or how perfect that potato\u2019s form, the system would never come up with the word \u2018potato\u2019 because it had not been taught to identify it. Potato is not one of the 1000. I took a look at the 1000 categories and learned that the AI ought to be able to identify a brassiere, a rifle, a feather boa, lotion, a manhole cover, a computer mouse, a pinwheel, a prayer rug, a whiskey jug. Mostly, as I looked through the list of the chosen, I wondered, why these? A paper on the contest explains that the 1000 contest categories were chosen randomly in 2010, the first year of the contest, and then curated to ensure they were not too obscure and that there was no overlap between any two categories in the hierarchy (if \u2018hound\u2019 is included, then \u2018hunting dog\u2019 (superclass) or \u2018beagle\u2019 (subclass) is not. Over the years, the set has changed, but 639 of the categories have been used in every challenge (through 2015, at least, the year the paper was published). In other words, I had randomness to thank for why the model could identify a brassiere, but not a painting, a pomegranate, but not a kiwi, a mashed potato, not my potato, a bookshop, but not a book. Wait\u2026 no books? I showed the AI a couple photographs of a book and I was told that it was an \u2018eraser\u2019 or \u2018envelope\u2019, or sometimes, more eerily, something that was in the photograph but that I hadn\u2019t really noticed at all. When I showed the AI a woman holding a stack of books, for example, it classified the photograph as a \u2018jersey\u2019. In another photograph, the AI looked right past the man reading, but identified the shelves of books in the background as a bookshop. The thing the AI predicts most confidently is not incorrect, it\u2019s just not necessarily where my eye is drawn when I look at the photo. To be clear, I do not expect the AI to see something it does not know about, and yet it is interesting to think about what we are teaching our technologies and what they are blind to because we have not shown them examples. I was able to spy on the AI to see where it looked thanks to the work of researchers at Virginia Tech and Georgia Institute of Technology, who built Guided Grad-CAM, which I used to generate the illustrations above. The Guided Grad-CAM technology has a number of interesting applications, but the one that struck me most was identifying bias based on the direction of the AI\u2019s gaze. In the example below, the biased model notices a female face and identifies her as a nurse. The biased model learned its bias from the data it was trained on, the researchers write, but using \u201cthe insights gained from the Grad-CAM visualizations, we balanced the dataset and retrained the model.\u201d The unbiased model looks at the stethoscope instead of the face when it determines the profession. In another thought-provoking study, researchers at Facebook looked at how well our technologies are doing at classifying objects, and where they are failing, with a special look at basketballs and the images used to illustrate them in ImageNet. Though the percentage of images they looked at in which at least one white or one black person appear is very similar (55% for the former, 53% for the latter), a model trained on this data behaves in an unexpected way. When asked to make predictions on a set of images selected so that \u2018the primary apparent difference between the two images is the skin color of the persons\u2019, the model demonstrates this pattern: \u201cAll images containing a black person are classified as basketball while similar photos with persons of different skin color are labeled differently\u201d (as a Volleyball, ping-pong ball, or baseball player, for example). In other words, the model has learned a bias. The researchers note: The reasons why the model learns these biases are unclear. One hypothesis is that despite the balanced distribution of races in pictures labeled basketball, blacks persons are more represented in this class in comparison to the other classes. I read the above passage a few times and thought about the implications. Who exactly is represented in ImageNet and who is not, I wondered. And what patterns are our technologies picking up simply because of who and what is included (or omitted) in the data? Our models are great at identifying patterns, only some of these patterns are not intended, or worse, harmful. Unsettling decisions by algorithms have appeared in the world of beauty contests, facial recognition, and natural language processing, among other areas. Last year, researchers found significant gender bias in several of our large image data sets. AIs trained on these images have not only picked up on but amplified these biases, associating women with things like kitchens and men with sporting goods (see the story in Wired). I appreciate the tremendous efforts that goes into creating and maintaining the image data sets that we rely on to train and test our AIs. Without ImageNet and the competition around it, I do not think our technologies would have evolved as rapidly. Still, I have not come across a study relating to skin color and representation in this data set, and I am concerned about what it means to associate human skin tones with some types of things and not others. Repeatedly, I hear image data called \u2018real world data\u2019. But do the data reflect reality? And how can we make sure that the data are not simply reinforcing the biases that we as a society must strive to conquer as well? * * * Further reading: \u201cGrad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization,\u201d Ramprasaath R. Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, Dhruv Batra https:\/\/arxiv.org\/abs\/1610.02391 \u201cConvNets and ImageNet Beyond Accuracy: Explanations, Bias Detection, Adversarial Examples and Model Criticism,\u201d Pierre Stock, Moustapha Cisse https:\/\/arxiv.org\/abs\/1711.11443 \u201cImageNet Large Scale Visual Recognition Challenge,\u201d Olga Russakovsky* \u00b7 Jia Deng* \u00b7 Hao Su \u00b7 Jonathan Krause \u00b7 Sanjeev Satheesh \u00b7 Sean Ma \u00b7 Zhiheng Huang \u00b7 Andrej Karpathy \u00b7 Aditya Khosla \u00b7 Michael Bernstein \u00b7 Alexander C. Berg \u00b7 Li Fei-Fei https:\/\/arxiv.org\/pdf\/1409.0575.pdf By clapping more or less, you can signal to us which stories really stand out. Writer of fiction and technical docs Sharing concepts, ideas, and codes.","time":1525808247,"title":"What Does It See? The troubled gaze of an artificial intelligence","type":"story","url":"https:\/\/towardsdatascience.com\/what-does-it-see-f2dcd9dff9af"},{"by":"d2p","descendants":0,"id":17024057,"kids":"None","score":14,"text":"This week marks the release of the third beta for Flutter, our toolkit for building beautiful mobile UI for iOS and Android. In our announcement over at the Google Developer site, we provide a broader overview of the Flutter project and showcase some examples of how customers are using it to create amazing applications. In this blog post, we\u2019ll take a deeper look at the specific improvements we\u2019ve made in Beta 3 itself. As mentioned when we shipped our first beta at Mobile World Congress in February, our intent is to continue to ship releases that are at least of beta quality on approximately a monthly cadence. This release (v0.3.2) is the third release in that lineage, and demonstrates continued progress towards completing the 1.0 release. Our work in this release has focused on three primary areas: fundamentals, ecosystem and tooling. Let\u2019s start with the fundamentals, where we\u2019ve improved the built-in UI widgets, completed the remaining feature work for Dart 2, and introduced a new embedding API. In Flutter Beta 3, we\u2019ve made a number of improvements to the Material Design widgets to enable greater flexibility and customization. For example: Additionally, we\u2019ve added support for animated resources in formats like GIF and WebP, ready for your best meme apps to be published to the app stores! We also made a number of updates to the Flutter Gallery application to demonstrate these and other changes. For example: We\u2019ve completed the work to enable Dart 2, our reboot of the Dart language that is optimized for client development. As of this release, Dart 2 is feature complete and enabled by default. In this release, Dart 2 adds some syntactic sugar to help with instantiating widgets in Flutter. The new keyword is now entirely optional: there should be no need to use it any longer, and it\u2019s a bug if the compiler complains. A build() method like this is easier than ever to write: The const keyword becomes optional for any child constructors within an existing const scope. During the first two betas, we identified scenarios where it was difficult to infer from the context whether an object\u2019s children are immutable, so we require the const keyword at the top level to make the constant nature of the code explicit. Once you\u2019ve declared a section as const, however, the children are automatically const without requiring further declaration, so now a statement like the following is valid: In other areas, we\u2019ve made improvements to the accessibility support for apps that use Flutter, including improving support for screen readers, large text and contrast capabilities, as well as starting to document our accessibility support. We\u2019re also ready for apps that are offered in languages with right-to-left scripts. In addition to supporting right-to-left text, controls mirror where appropriate (for example the left \u2018back\u2019 button has inverted direction and justification in languages like Arabic). We\u2019ve also rewritten the Flutter engine\u2019s threading model to make it possible to host multiple FlutterViews within a single application. This is part of our larger focus on making it easier to add Flutter to your existing app\u200a\u2014\u200awork that continues in progress. We launched an initial suite of Firebase plugins at Google I\/O last year. Several of those plugins are reaching their 1.0 milestone this week: Realtime Database, Firebase Analytics, Firebase Messaging, and Firebase Core. In addition, we have added new, fully-featured plugins for Remote Config, Cloud Firestore, and Performance Monitoring. For an overview of our Firebase support, please see the FlutterFire page. Our support for ads powered by AdMob by Google is graduating to beta, enabling you to monetize your Flutter-based applications. The AdMob plugin supports loading and displaying banner, interstitial (full-screen), and rewarded video ads using the AdMob API. There are many other packages that have recently been made available for Flutter, some contributed by the Flutter team directly, others by community members. As mentioned in our I\/O announcement post, Flutter is a first-class toolkit for Material, which means the Material and Flutter teams have partnered to deliver even more support for Material Design. We continue to release regular updates to the Flutter plugin for Android Studio and IntelliJ to improve the development experience. In particular, we\u2019ve redesigned the UI Inspector with a new \u201cJust My Widgets\u201d feature that filters out auto-generated widgets. You can also run your Flutter app in profile mode, which adds frames-per-second and memory usage displays. Visual Studio Code is now considered a fully-supported development environment for Flutter, in addition to the Android Studio support mentioned above. Flutter support is enabled through the Flutter extension, available through the Visual Studio Marketplace. The latest version of our Visual Studio Code extension supports Flutter Beta 3 features including Dart 2, and the changelog is here. Other notable features in this release for both Android Studio and Visual Studio Code include a broader set of refactorings. This includes an Extract Widget refactor that creates a new Widget class and inserts a call to its constructor in the original position: There are a few ways to get in touch with us and find out what\u2019s going on with Flutter. By clapping more or less, you can signal to us which stories really stand out. Flutter is Google\u2019s mobile UI framework for crafting high-quality native interfaces on iOS and Android in record time. Flutter works with existing code, is used by developers and organizations around the world, and is free and open source. Learn more at https:\/\/flutter.io","time":1525808065,"title":"What\u2019s New in Flutter Beta 3?","type":"story","url":"https:\/\/medium.com\/flutter-io\/flutter-beta-3-7d88125245dc"},{"by":"jimschley","descendants":178,"id":17023220,"kids":"[17023711, 17023707, 17023682, 17024079, 17023914, 17024849, 17026252, 17023675, 17024032, 17027839, 17024651, 17025435, 17025054, 17026949, 17023941, 17026627, 17023954]","score":170,"text":"Lying or spreading \u201cfalse news\u201d was treated as a crime in colonial Massachusetts.\u00a0 In 1645 the Massachusetts Bay Colony passed a law which stated: \u201cWhereas truth in words as well as in actions is required of all men, especially of Christians, who are the professed of the God of Truth; and whereas all lying is contrary to truth, and some sort of lies are not only sinful, (as all lies are) but pernicious to the publick weal, and injurious to particular persons: It is therefore ordered by this court and authority thereof, that every person of the age of discretion (which is accounted fourteen years) who shall wittingly and willingly make, or publish any lie, which may be pernicious to the publick weal, or tending to the damage or injury of any particular person, or with the intent to deceive and abuse the people with false news and reports, \u2026 such person shall be fined for the first offense ten shillings, or if the party be unable to pay the same, then to be set in the stocks\u2026 in some open place, not exceeding two hours. For the second offense in that kind, whereof any shall be legally convicted, shall pay the sum of twenty shillings, or be whipped upon the naked body, not exceeding ten stripes. And for the third offense forty shillings, or if the party be unable to pay, then to be whipped with more stripes, not exceeding fifteen. \u201c For a fourth offense, the punishment was 10 shillings more than formerly, or if unable to pay, then 5-6 more stripes than formerly, not exceeding 40. [Bold letters are\u00a0 mine.] This law was included in the Massachusetts Bay Colony\u2019s first printed compilation of statutes\u00a0The Book of the General Lawes and Libertyes Concerning the Inhabitants of Massachusetts\u00a0(1648). Facsimiles of this book\u00a0are owned by the\u00a0Massachusetts Trial Court Law Libraries. One can also read selections of this book online at Le Projet Albion\/Puritan Studies on the Web\/Primary Sources.\u00a0\u00a0(see # 35) \u00a0 The Puritan-dominated Colony clearly hoped to instill Christian values in the community, and protect the vulnerable young colony from danger, by threatening to punish all lying, not only those lies that damaged\u00a0 a particular individual, but also any lies that were simply \u201cpernicious to the publick weal\u201d. (Plymouth Colony passed its own law against spreading false news in 1653, with very similar wording; Virginia followed in 1661; Maryland in 1671; New York in 1664; Pennsylvania in 1682; and South Carolina in 1691.) If someone lied about a particular individual, that individual could sue for slander, which was often done; but the liar could also face criminal sanctions, especially if the person lied about an important government or church official. \u00a0This had been typical in English common law for centuries. \u00a0The impetus was to protect the reputations of important men, because the stability of the government depended upon their good relations with each other (and with the crown) and the nation\u2019s trust in their integrity.\u00a0 That was, in essence, the old conception of \u201cfalse news\u201d. The new conception of \u201cfalse news\u201d, which arose in the seventeenth century, had to do with events rather than particular people.\u00a0 If one lied about a supposed event, especially in a way that endangered the public good, one could face the criminal charge of lying and spreading \u201cfalse news and reports\u201d. Lying often accompanies other crimes, so it is sometimes difficult to separate the crime of lying from other charges an individual might face simultaneously, as for example, when someone were charged with both lying and theft, lying and blasphemy, or lying in order to entrap a young woman so as to pander her. EXAMPLES of people in colonial Massachusetts convicted and punished for lying alone include the following. In 1678, Nicholas Shapleigh and Richard Naggs, mariners on a ship, were fined 10 shillings apiece for their\u00a0 \u201cpernicious lie to ye \u00a0country\u201d, for claiming that there was French contraband and brandy on a ship, and then denying their lie in court, saying it was just \u201cthe slip of the pen\u201d. \u00a0In this apparently civil case, the plaintiff was their captain Andrew Craty; they agreed to give him their wages as libel, so he withdrew his case.\u00a0 But the court fined them for lying to the court about it. In 1682, James Fuller of Springfield claimed that he had prayed to the Devil for help, and was familiar with the Devil on several occasions; in court he admitted that he had lied about this; he was found not guilty by a jury for witchcraft, but the Court, \u201cconsidering his wicked and pernicious willful lying and continuance in it till now putting the country to so great a charge\u201d sentenced him to be whipped 30 stripes and fined 5 pounds. In 1691, Josiah Littlefield (bound over to the General Court in Boston from the County Court of Salem) \u00a0was convicted of lying for reporting that he knew men who had had sold powder and shot to the Indians; he denied it in court; he was fined 10 shillings and fees of Court. [Records of the Court of Assistants of the Colony of the Massachusetts Bay 1630-1692, (1901). Vol 1, p. 147, 228, & 356 respectively.] \u00a0 Today, the Massachusetts General Laws have no proscription against spreading false news, except as it relates to libel and slander of particular individuals.\u00a0 (Slander is oral defamation, libel is written.) For further information, including laws, regulations, case law, and online and print resources, see our web page \u201cMassachusetts Law about Defamation\u201d. \u00a0  Written By: \u00a0 Words of law\u00a0is a regular feature of\u00a0Massachusetts Law Updates, highlighting a particular word or phrase and its meaning in law. Today\u2019s phrase is search\u00a0warrant. search warrant, n. (18c) Criminal law. A judge\u2019s written order authorizing a law-enforcement officer to conduct a search of a\u00a0 \u00a0\u2026Continue Reading Word(s) of the Month \u2013 search warrant Portraits in Massachusetts Law is a regular feature of Massachusetts Law Updates.\u00a0These pages provide links to biographical information abut people who have been particularly important in legal history in Massachusetts, as our government took shape in the cauldron of the American Revolution and grew and\u00a0 \u00a0\u2026Continue Reading Portraits in Massachusetts Law: Lemuel Shaw National Freedom of Information Day\u00a0is observed on March 16, 2018 to recognize the public\u2019s right to information held by government agencies. Freedom of Information Day is an annual event held on the birthday of James Madison, one of our founding fathers. The Freedom of Information\u00a0 \u00a0\u2026Continue Reading Freedom of Information Day We want to hear from you.  Connect with us. \u00a0 Words of law\u00a0is a regular feature of\u00a0Massachusetts Law Updates, highlighting a particular word or phrase and its meaning in law. Today\u2019s phrase is search\u00a0warrant. search warrant, n. (18c) Criminal law. A judge\u2019s written order authorizing a law-enforcement officer to conduct a search of a\u00a0 \u00a0\u2026Continue Reading Word(s) of the Month \u2013 search warrant Portraits in Massachusetts Law is a regular feature of Massachusetts Law Updates.\u00a0These pages provide links to biographical information abut people who have been particularly important in legal history in Massachusetts, as our government took shape in the cauldron of the American Revolution and grew and\u00a0 \u00a0\u2026Continue Reading Portraits in Massachusetts Law: Lemuel Shaw National Freedom of Information Day\u00a0is observed on March 16, 2018 to recognize the public\u2019s right to information held by government agencies. Freedom of Information Day is an annual event held on the birthday of James Madison, one of our founding fathers. The Freedom of Information\u00a0 \u00a0\u2026Continue Reading Freedom of Information Day Mass. Trial Court Law Libraries  Hours: Monday - Friday from 9:00 a.m. - 4:00 p.m.   Phone: 617-878-0336 Toll Free: 1-800-445-8989 (within Mass. only)TTY: 1-800-281-3683 (within Mass. only) \u00a9 2018 Commonwealth of Massachusetts |\r\n\t\t\t\t\t\tHOME |\r\n\t\t\t\t\t\tMass.Gov\u00ae Blog Portal Site Policies |\r\n\t\t\t\t\t\tLogin\n","time":1525803292,"title":"Fake news was illegal in 17th century colonial Massachusetts","type":"story","url":"http:\/\/blog.mass.gov\/masslawlib\/legal-history\/the-law-against-lying-and-false-news-in-colonial-massachusetts\/"},{"by":"john58","descendants":0,"id":17023183,"kids":"[17025016]","score":22,"text":"\n                            TNW uses cookies to personalize content and ads to\n                            make our site easier for you to use.\n                            We do also share that information with third parties for\n                            advertising & analytics.\n                         \n            by Tristan Greene\n            \u2014 \n                        in Artificial Intelligence\n Kicking off Google I\/O is an announcement that brings six new voices to our favorite digital assistant. Thanks to an overhaul to its Wavenet platform, Android users will soon be able to select new voices aside from its standard \u201cmale\u201d or \u201cfemale\u201d options. The big story: Grammy Award winning artist John Legend\u2019s voice will join the lineup later this year as one of the new voices. Google CEO Sundar Pichai said Assistant won\u2019t be able to answer every question you could possible ask with Legend\u2019s voice, but for fans it\u2019ll be nice to hear him doing the basics like telling you the weather. Google Assistant is getting better, smarter, and soon it\u2019ll have the velvet voice of a legend named Legend, or any of the five other currently unknown voices joining the new lineup. Check out our\u00a0event page\u00a0for more\u00a0Google I\/O\u00a0stories this week, or follow our reporters on the ground until the event wraps on Thursday:\u00a0@bryanclark\u00a0and\u00a0@mrgreene1977. \nRead next:\n\n        Google Assistant puts an end to impolite queries with 'Pretty Please' feature    \n Stay tuned with our weekly recap of what\u2019s hot & cool by our CEO Boris. \n        Join over 260,000 subscribers!\n     \n                Sit back and let the hottest tech news come to you by the magic of electronic mail.\n             \n                Prefer to get the news as it happens? Follow us on social media.\n             \n1.76M followers\n                         \n1M likes\n                         \n                Got two minutes to spare? We'd love to know a bit more about our readers.\nStart!\n \n                All data collected in the survey is anonymous.\n            ","time":1525803119,"title":"Google announces six new voices for Assistant at #IO18 \u2013 including John Legend","type":"story","url":"https:\/\/thenextweb.com\/artificial-intelligence\/2018\/05\/08\/google-announces-six-new-voices-at-io-2018-including-john-legend\/"},{"by":"devhxinc","descendants":56,"id":17023168,"kids":"[17025267, 17025051, 17025770, 17024767, 17028131, 17024916, 17024757, 17026081]","score":71,"text":"\n\n\n\n News In the nearly 30 years since the world wide web launched, more than 2 billion websites have been created. It can feel impossible to keep up with the hundreds of thousands of tweets, tens of thousands of pages, and hundreds of hours of video that come online every single minute. Amid this deluge of information, important new voices are constantly emerging. There\u2019s more diverse content to discover and more great journalism being produced than ever before. In order to make it easier to keep up and make sense of it all, we\u00a0set out to bring our news products into one unified experience.\u00a0\u00a0 Today we\u2019re rolling out an all new Google News, which uses the best of artificial intelligence to find the best of human intelligence\u2014the great reporting done by journalists around the globe.  When we created the original Google News 15 years ago, we simply organized news articles to make it easier to see a range of sources on the same topic.\u00a0\u00a0 The reimagined Google News uses a new set of AI techniques to take a constant flow of information as it hits the web, analyze it in real time and organize it into storylines. This approach means Google News understands the people, places and things involved in a story as it evolves, and connects how they relate to one another. At its core, this technology lets us synthesize information and put it together in a way that helps you make sense of what\u2019s happening, and what the impact or reaction has been.  For many of us, news comes from dozens of different places\u2014sports from a favorite website, politics from TV, and news about your community from your local paper. When you\u2019re in the app, \u201cFor You\u201d makes it easy to stay up to date on everything you care about all in one place. We start with a briefing of five stories that Google News has organized for you\u2014a mix of the most important headlines, local news and the latest developments on the topics you\u2019re interested in. \u00a0 And the more you use the app, the better the app gets. We\u2019ve also built easy-to-use and easy-to-access controls so you can decide if you want to see more or less of a topic or publisher. As we built the app, we focused on letting the stories speak for themselves with great images and videos from YouTube and across the web. To help you quickly get you up to speed, we\u2019re experimenting with a unique visual format called newscasts. Here, the latest developments in natural language understanding bring together a collection of articles, videos and quotes on a single topic. Newscasts make it easy to dive right into perspectives to learn more about a story\u2014plus, it\u2019s easy to read on your phone.  If you want to get a deeper insight into a story, the \u201cFull Coverage\u201d feature provides a complete picture of how that story is reported from a variety of sources. With just a tap you\u2019ll see top headlines from different sources, videos, local news reports, FAQs, social commentary, and a timeline for stories that have played out over time. Having a productive conversation or debate requires everyone to have access to the same information. That\u2019s why content in Full Coverage is the same for everyone\u2014it\u2019s an unpersonalized view of events from a range of trusted news sources. To find out what the world is reading, head over to Headlines for an unfiltered view of news from around the world. Additional sections let you dig into more on technology, business, sports, entertainment and others.  Of course Google News wouldn\u2019t exist without the great journalism being created every day. The Newsstand tab makes it easy to find and follow the sources you trust, as well as browse and discover new ones. You can also access more than 1,000 magazine titles in a mobile-optimized reading format.\u00a0\u00a0   And if you want to support your favorite news sources, we\u2019ve made it simple to subscribe with your Google account. This means no more forms, credit card numbers, or new passwords. And soon, thanks to the new Subscribe with Google platform (launched as a part of the Google News Initiative), you\u2019ll get access to your paid content everywhere\u2014on all platforms and devices, on Google News, Google Search, and on publishers\u2019 own websites.    \n              Follow Us\n            ","time":1525803046,"title":"The new Google News: AI meets human intelligence","type":"story","url":"https:\/\/blog.google\/products\/news\/new-google-news-ai-meets-human-intelligence\/"},{"by":"dEnigma","descendants":175,"id":17023102,"kids":"[17025087, 17029260, 17023472, 17023657, 17023785, 17023479, 17024491, 17029003, 17025738, 17024469, 17028618, 17023624, 17023378, 17026418, 17023508, 17027272, 17023278, 17025497, 17023474, 17024321, 17023357, 17025546, 17027814, 17024497, 17025858, 17026290, 17023719, 17026188, 17024223, 17023646, 17024525]","score":303,"text":"Windows Console, Bash on Ubuntu on Windows, Windows Subsystem for Linux, WSL, Linux For many years, Windows Notepad only supported text documents containing Windows End of Line (EOL) characters - Carriage Return (CR) & Line Feed (LF). This means that Notepad was unable to correctly display the contents of text files created in Unix, Linux and macOS. For example, here\u2019s a screenshot of Notepad trying to display the contents of a Linux .bashrc text file, which only contains Unix LF EOL characters:  As you can see, Notepad is incorrectly displaying the file\u2019s contents, making the file look garbled. This has been a major annoyance for developers, IT Pros, administrators, and end users throughout the community. Today, we\u2019re excited to announce that we have fixed this issue! Starting with the current Windows 10 Insider build, Notepad will support Unix\/Linux line endings (LF), Macintosh line endings (CR), and Windows Line endings (CRLF) as usual. New files created within Notepad will use Windows line ending (CRLF) by default, but it will now be possible to view, edit, and print existing files, correctly maintaining the file\u2019s current line ending format. Here\u2019s a screenshot of the newly updated Notepad displaying the contents of the same Unix\/Linux .bashrc file we saw earlier:  Also note that the status bar indicates the detected EOL format of the currently open file. As with any change to a long-established tool, there\u2019s a chance that this new behavior may not work for your scenarios, or you may prefer to disable this new behavior and return to Notepad\u2019s original behavior. To do this, you can change the following registry keys in the following location to tweak how Notepad handles pasting of text, and which EOL character to use when Enter\/Return is hit: [HKEY_CURRENT_USER\\Software\\Microsoft\\Notepad]  We hope that you find this change useful and look forward to hearing your feedback  Name *  Email *  Website   \n\n   Now if you could also add the ability to enable both Status Bar AND Word Wrap at the same time I\u2019d call Notepad complete \ud83d\ude00 You can now use the Status Bar setting, regardless of the Word Wrap setting.","time":1525802609,"title":"Introducing extended line endings support in Notepad","type":"story","url":"https:\/\/blogs.msdn.microsoft.com\/commandline\/2018\/05\/08\/extended-eol-in-notepad\/"},{"by":"jonbaer","descendants":111,"id":17022215,"kids":"[17023703, 17022985, 17022535, 17026503, 17022907, 17022595, 17028619, 17029044, 17022586, 17027119, 17022923, 17023185, 17022736, 17024376, 17025486, 17024126, 17023566, 17026129, 17026156, 17024208, 17023122, 17023005, 17024642, 17025136, 17022984, 17023976, 17024249]","score":259,"text":"\n        Edmon de Haro for BuzzFeed News\n       \n          \n          A vast web of Amazon review fraud lives online, and it's designed to evade the company\u2019s efforts to thwart it.\n         One morning in late January, Jake picked up the box on his desk, tore through the packing tape, unearthed the iPhone case inside, snapped a picture, and uploaded it to an Amazon review he\u2019d been writing. The review included a sentence about the case\u2019s sleek design and cool, clear volume buttons. He finished off the blurb with a glowing title (\u201cThe perfect case!!\u201d) and rated the product a perfect five stars. Click. Submitted. Jake never tried the case. He doesn\u2019t even have an iPhone. Jake then copied the link to his review and pasted it into an invite-only Slack channel for paid Amazon reviewers. A day later, he received a notification from PayPal, alerting him to a new credit in his account: a $10 refund for the phone case he\u2019ll never use, along with $3 for his trouble \u2014 potentially more, if he can resell the iPhone case. Jake is not his real name. He \u2014 along with the four other reviewers who spoke to BuzzFeed News for this story \u2014 wanted to remain anonymous for fear Amazon would ban their accounts. They are part of an extensive, invisible workforce fueling a review-fraud economy that persists in every corner of the largest marketplace on the internet. Drawn in by easy money and free stuff, they\u2019ve seeded Amazon with fake five-star reviews of LED lights, dog bowls, clothing, and even health items like prenatal vitamins \u2014 all meant to convince you that this product is the best and bolster the sales of profiteers hoping to grab a piece of the Amazon Gold Rush. Meanwhile, sellers trying to play by the rules are struggling to stay afloat amid a sea of fraudulent reviews, and buyers are unwittingly purchasing inferior or downright faulty products. And Amazon is all but powerless to stop it. The systems that create fraudulent reviews are a complicated web of subreddits, invite-only Slack channels, private Discord servers, and closed Facebook groups, but the incentives are simple: Being a five-star product is crucial to selling inventory at scale in Amazon\u2019s intensely competitive marketplace \u2014 so crucial that merchants are willing to pay thousands of people to review their products positively. At just over $760 billion, Amazon is the world\u2019s second most valuable company, behind Apple. CEO Jeff Bezos recently revealed the company counts more than 100 million paying Amazon Prime members globally, the $119-per-year membership that gets subscribers \u2014 the most devoted Amazon customers \u2014 free two-day shipping; music, TV, and movie streaming; access to an e-book library; and more. The company operates 13 third-party seller marketplaces around the world, and rents space to house those sellers\u2019 inventory in more than 150 warehouses. In 2017, third-party merchants brought in $32 billion of revenue, and nearly 300,000 new sellers joined the marketplace last year alone. Reviews are a buyer\u2019s best chance to navigate this dizzyingly crowded market and a seller\u2019s chance to stand out from the crowd. In a 2011 survey, 87% of consumers said a positive review confirmed their decision to purchase a product; online customer reviews are the second most trusted source of product information, behind recommendations from family and friends. But only 3% to 10% of customers leave reviews. The best way to make it on Amazon is with positive reviews, and the best way to get positive reviews is to buy them. In October 2016, Amazon banned free items or steep discounts in exchange for reviews facilitated by third parties. But Tommy Noonan, CEO of ReviewMeta, a site that analyzes Amazon listings, said what he calls \u201cunnatural reviews\u201d \u2014 that is, reviews, that his algorithm indicates might be fake \u2014 have returned to the platform. In June 2017, Noonan noticed an uptick in unnatural reviews along with an increase in the average rating of products, and the rate of growth hasn\u2019t slowed since. Amazon\u2019s ban didn\u2019t stop sellers from recruiting reviewers. It only drove the practice underground. Reviewers are no longer simply incentivized with free stuff \u2014 they\u2019re commissioned specifically for a five-star rating in exchange for cash. The bad reviews are harder to spot, too: They don\u2019t contain any disclosures (because incentivized reviews are banned, and a disclosure would indicate that the review violates Amazon\u2019s terms). Paid reviewers also typically pay for products with their own credit cards on their own Amazon accounts, with which they have spent at least $50, all to meet the criteria for a \u201cverified purchase,\u201d so their reviews are marked as such. Amazon won\u2019t reveal how many reviews \u2014 fraudulent or total \u2014 it has. But based on his analysis of Amazon data, Noonan estimates that Amazon hosts around 250 million reviews. Noonan's website has collected 58.5 million of those reviews, and the ReviewMeta algorithm labeled 9.1%, or 5.3 million of the dataset's reviews, as \u201cunnatural.\u201d An Amazon spokesperson told BuzzFeed News the percentage of inauthentic reviews on the platform is \u201ctiny,\u201d but would not be more specific. In a statement, she wrote, \u201cAmazon is investing heavily to detect and prevent inauthentic reviews. In addition to advance detection, we use a machine-learned algorithm that gives more weight to newer, more helpful reviews, apply strict criteria to qualify for the Amazon verified purchase badge and enforce a significant dollar amount requirement to participate.\u201d Internal investigators also examine reviews and \u201cnon-Amazon forums\u201d used for purchasing reviews, the spokesperson said. Amazon says it blocks or suspends accounts belonging to any of the parties involved. But conversations with sellers, customers, and reviewers reveal that review abuse continues, despite the company\u2019s efforts. An unnatural review doesn\u2019t necessarily mean a product is inferior. But the problem with paid-for reviews is that they make it difficult for consumers \u2014 even savvy ones \u2014 to know if what they\u2019re buying is actually good or bad. In December, Kevin Votaw of Fort Collins, Colorado, ordered a highly rated Samsung Galaxy S8 screen protector for $10 using his girlfriend\u2019s Amazon Prime account. It was, he said, \u201cterrible\u201d: The material was so thick he couldn\u2019t type, making the product completely unusable. Frustrated, Votaw asked Amazon for a refund for the unreturnable product, which has a sticky, adhesive backing and can\u2019t be reused. \u201cI went back to the listing, thinking, \u2018Surely all of these reviews are wrong,\u2019\u201d he said. But the product was unavailable \u2014 \u201clike the company was rolling these protectors out in batches, then taking them off Amazon.\u201d Amazon removed the screen protector listing after a BuzzFeed News inquiry, but two other listings with nearly identical product photography have more than 550 and 150 reviews each, all of which include a five-star rating and are unverified. Votaw has since found a protector with a mediocre 3.5-star rating that he\u2019s happy with: \u201cIt works perfectly,\u201d he said. \u201cI\u2019ll be leaving a great review.\u201d Type in \u201cAmazon Review\u201d into Facebook\u2019s search box, and more than a hundred groups will pop up. Two of the more popular groups, Amazon Review Club and US \u2014 Amazon Review Club, which had 69,000 and 60,000 members, respectively, were recently shut down, but many more groups remain, with tens of thousands of members apiece.  The groups\u2019 posts read like the most random garage sale ever: lawn aerator shoes, lint removers, diaper pads, sex toys. New products are posted every minute. Most sellers are Chinese; in February, group members were warned that lunar holidays might slow down payments. Posts include a photo of the product up for grabs, with a description that says, \u201cPP refund after review,\u201d which means interested parties will receive a PayPal payment after proof they\u2019ve published a review. One product listed in the group, a posture corrector designed to train your back to sit upright, was offering an unusually large commission: a $30 Amazon gift card that included $20 for the product and an extra $10 for the reviewer, who needed to be an Amazon Prime member and write a review that contained images. Meanwhile, the 36,629-member \/r\/slavelabour subreddit, which is dedicated to getting \u201cjobs done well below market rate,\u201d has a formalized process for posting opportunities for would-be Amazon reviewers. Redditors negotiate a fake review. Sellers post \u201ctasks\u201d that include leaving positive reviews on their products \u2014 or one-star reviews on competitors\u2019 products. One listing read, \u201cThe reviews don\u2019t need to be verified or anything, so the task won\u2019t take more than a minute of your time. I will send you the link to the product, you go and leave a brief 1 star review, and that\u2019s it. I will pay $5 to you through Paypal as soon as the review is live on Amazon.\u201d Within a week, 27 users had placed \u201cbids\u201d on the task, expressing their interest. The most active reviewers become headhunters, working to recruit \/r\/slavelabour users into private Discord servers or Slack channels dedicated solely to feeding the Amazon review ecosystem. Sellers typically pay between $4 to $5 per review, plus a refund of the product. Moderators take a cut off the top \u2014 around 20% to 25% for the Discord server I gained access to, but reviewers get to keep the item for free. On Jan. 13, the server\u2019s moderator published a call for reviewers interested in \u201cBefore You Go To The Toilet Poop Spray,\u201d a natural deodorizer carrying the \u201cscent of Australia\u201d by a company called Veil. The poop spray\u2019s listing shows a number of negative reviews, followed by a string of more positive reviews published after Jan. 13. Both positive and negative reviews are \u201cverified purchases,\u201d making it nearly impossible to differentiate between commissioned and genuine reviews. None of the reviews contain a disclosure that the product was received for free or that the review was paid for by the seller. In an email to BuzzFeed News, Greg Doney, a Veil Fragrances representative, acknowledged the company had paid for reviews, \u201cbut you have to as its [sic] really hard to launch a product without them.\u201d When you take a closer look at the poop spray customers\u2019 product review history, a pattern emerges. In addition to the poop spray, Amazon customers \u201cBrian\u201d and \u201cSharon\u201d also gave a floating shelf bracket, which had been posted to the Discord server earlier, high marks. Brian said the product was a \u201creally sturdy shelf\u201d (it\u2019s a bracket, not a stand-alone shelf); and Sharon noted they\u2019re \u201ceasy to mount\u201d and \u201cdurable.\u201d The critical reviews, meanwhile, warn customers \u201cDO NOT BUY!\u201d and \u201cHUGE waste of money,\u201d citing wall damage and poorly made brackets. (The shelf company did not respond to a request for comment sent to its Amazon seller profile from BuzzFeed News.) The same accounts also reviewed \u201cBoric Acid Suppositories\u201d for vaginal health. The supplements are intended to be inserted into the vagina twice daily for two weeks, according to the product\u2019s label. It purports to provide \u201cvaginal health support\u201d and \u201crelief from odor, itchiness, pain, burning, and soreness.\u201d The capsules were posted to the Discord server on Jan. 22 \u2014 and reviews from Brian and Sharon appeared shortly after that. Brian commented that his girlfriend was \u201chaving pain during sex and it was not because of me,\u201d and the supplements cured her. Sharon mentioned it was the \u201cbest and cheapest\u201d option for female hygiene and health. Neither of the reviews were marked as verified purchases. A five-star review by D. Pham even says the boric acid \u201cdoesn\u2019t taste bad\u201d even though the pill is not taken orally. (D. Pham also gave the floating shelf bracket five stars.) Meanwhile, a one-star review said that the product was a \u201cnightmare,\u201d citing how the pill \u201cfeels like a clump of cement mix in my vagina that is just gritty and totally dries it out.\u201d Another said the suppository caused \u201can irritating burning sensation that lasted for hours.\u201d The company did not respond to a request for comment. According to Dr. Jenny Jaque, assistant professor of gynecology at the University of Southern California's Keck School of Medicine, boric acid suppositories should only be used under certain circumstances, under the supervision of a health care provider. \u201cBoric acid is not candy, and you need to be careful,\u201d she said. \u201cIt can cause irritation: Your vagina will hurt; you\u2019d feel pain like your vagina is on fire.\u201d She added that \u201cit is really toxic if ingested by accident.\u201d The Discord server recently posted turmeric curcumin vitamins, as well as myoinositol capsules, made by the same brand, listed in the prenatal vitamin category. The same reviewers \u2014 Sharon and D. Pham \u2014 gave the prenatal vitamins five stars. Both of their reviews were marked as verified purchases. The company did not respond to a request for comment. Amazon said it has applied stricter criteria for leaving verified purchase reviews. US reviewers must have a password-protected account and have made at least $50 in purchases on Amazon with a valid credit card. During a hot summer in 2010, Jamie Whaley discovered a problem with her fitted sheets: They were breaking loose and ending up wrapped around her husband Jimmy\u2019s ankles. Whaley, then a 40-year-old nursing student in Texas, went in search of a solution. The suspenderlike designs on older sheet fasteners were too cumbersome, so Whaley developed her own, using a shock cord to make an easy button-enabled tightening mechanism. She called her new invention BedBand. Jimmy Whaley convinced his wife to start selling BedBands on Amazon. The product worked, and people wanted to buy it: Over the next few years, BedBand became Amazon\u2019s best-selling sheet fastener, with more $700,000 in annual sales. Then, in October 2014, BedBand\u2019s revenue was suddenly cut in half to about $350,000. Whaley, who had given up a nursing career, and Jim, who had also joined the company full time as COO, were devastated. \u201cSomeone was selling an exact replica of our product, and we couldn\u2019t use our patent because it was pending,\u201d said Whaley. Counterfeits, sold in bulk on AliExpress, had flooded Amazon\u2019s sheet fastener market, and many gained dozens of five-star reviews very quickly. Over the next eight months, sales tanked. \u201cThere were tears,\u201d said Whaley. \u201cWe wondered whether it was time to look for different jobs.\u201d She was forced to lay off eight contractors, half her staff at the time. Amazon took down the copycats once BedBand was granted a patent; it was a year after sales started dropping, but it was too late. The patent didn\u2019t stop competitors from leaving negative one-star reviews on BedBand\u2019s listings: \u201cYou start looking a bit deeper...and you can see they\u2019ve left five-star reviews for our competitors. Or you\u2019ll see that two different buyers have been reviewing the same type of products, our competitors\u2019 products,\u201d Whaley said.  BedBand is currently the best-selling fastener, but that may not be for long. \u201cIt\u2019s stressful, knowing that Amazon is our big store,\u201d she said. To diversify revenue income, Whaley started selling BedBands on Walmart.com, Jet.com, Sears.com, and other retailers. Whaley was careful about how she discussed Amazon, which is her primary source of income \u2014\u201cI don\u2019t want to mess where I nest,\u201d she said \u2014 but seemed uneasy about being at the whim of Amazon\u2019s algorithms: \u201cSome days, all of a sudden we\u2019re fifth. When you see a fast shift like that and [our competitors] end up with reviews all of a sudden, it\u2019s frustrating. You just don\u2019t know if tomorrow these competitors will knock our sales down.\u201d Paid review writing is the modern lemonade stand. According to the people who do it, it\u2019s a quick, easy way to earn a few bucks and get free stuff \u2014 but not a career. And because the bidding, writing, and transaction happen online, it can all be done from a laptop in your bedroom. Many reviewers who spoke to BuzzFeed News are men in their late teens or early twenties who viewed the activity as a hobby. All wished to remain anonymous, out of fear of being caught by Amazon, which typically results in revoked reviewing privileges or, in the most severe cases, being banned from reusing the same delivery address or payment method with a new account. Josh, which is not his real name, is fairly new to reviewing; he discovered it through \/r\/slavelabour. He said he\u2019s in it for the stuff: \u201cYou get to keep the product, so that\u2019s a plus. It\u2019s interesting to test out new and unique products in my opinion.\u201d The most industrious paid reviewers become moderators and begin facilitating review deals themselves. Frank, whose name has been changed, manages an Amazon review Slack channel in his spare time. The entrepreneurial 18-year-old scours Amazon for products that aren\u2019t well-rated and offers the product\u2019s seller his Slack channel\u2019s review services. Listings with a small number of reviews and a low-star rating are ideal candidates. \u201cIf [a product listing] has 30 reviews with an average of 2.5 stars, it\u2019s worth it and I\u2019ll reach out,\u201d he said. Frank only earns about $20 from reviews a month, and sometimes a bit extra through seller negotiations. \u201cI get about 30% for every review that one of our reviewers does,\u201d he said. The bulk of Frank\u2019s review income comes from reselling the items he reviews on eBay, where he makes \u201cabout a couple hundred\u201d monthly. Another reviewer, whom we\u2019ll call Evan, is part of a private 10-person Slack channel and makes about $75 a month from reviews. He\u2019s left more than 150 reviews for items like weighted workout vests, 30-day hair growth pills, and car phone chargers. \u201cIt\u2019s great for small investments and savings I\u2019m working on,\u201d he said. To write his commissioned reviews, Evan takes inspiration from existing reviews, \u201cthen I\u2019ll cobble together a few keywords.\u201d One reviewer, Devan, who asked to be identified by his first name only, however, denies any wrongdoing and doesn\u2019t mind being named. The college student swears he provides nothing but his honest opinion and thinks incentivized Amazon reviews aren\u2019t a scam. He did not know incentivized reviews violated Amazon's terms of service until BuzzFeed News told him. He did admit he benefits from incentivized reviews (which he writes daily): He reuses the bubble wrap and other shipping materials from Amazon for his eBay business, through which he resells items bought on clearance. But incentivized reviews on Amazon, he says, are just an evolution of marketing tactics that have been around for a long time. \u201cAt a sporting event, Mountain Dew will hand out soda for free, and if people like it they post on social media or whatever. It\u2019s kind of the same thing, and like at Costco or Walmart, where you get free samples,\u201d Devan said. \u201cSome of these sellers are mom and pop shops, and a lot of companies just want your honest feedback...I know a lot of people who [review] aren\u2019t in it for the money. They\u2019re just trying to find better products for people,\u201d Devan said. Devan's right \u2014 there are \u201cmom and pop shops\u201d on Amazon, like Whaley\u2019s BedBand business. But an increasing number of sellers are folks with little e-commerce experience or product expertise, looking to take advantage of Amazon\u2019s millions of customers \u2014 and they need high ratings to supplant the existing best-seller. Through the \u201cAmazon FBA\u201d or \u201cFulfillment by Amazon\u201d program, anyone can open their own Amazon storefront. It\u2019s easy: Buy products in bulk from an online wholesale supplier, like AliExpress, then send the inventory to one of Amazon\u2019s warehouses, where Amazon will take care of all aspects of distribution, from payment to order fulfillment to shipping.  David, whose name has been changed, is an FBA seller who has considered buying five-star reviews. \u201cIt feels like the people making the most money are those who are violating Amazon\u2019s terms of service,\u201d he said. David didn\u2019t invent anything. He didn\u2019t go to medical school. But he makes about $1,000 a month selling suture training pads for medical professionals on Amazon. \u201cIt\u2019s a hobby, like video games. Plus, Warren Buffett said something like, \u2018If you want to make money, you have to practice making money.\u2019\u201d David got started using a site called Jungle Scout. A subscription, which costs about $350 per year, provides metrics that show what products Amazon customers are buying a lot of \u2014 and features categories where the top seller has a poor or average star rating. That mediocre star rating indicates that there\u2019s an opportunity in the market for another seller to poach some of that low-rated product\u2019s customers. \u201cWhat I found were suture pads, like a simulation skin for medical students. Then I went on Alibaba. All the Chinese suppliers are on there and they fulfill bulk orders.\u201d David \u2014 and other FBA sellers like him \u2014 swarmed the Amazon suture pad market. \u201cThe original guy, the guy whose product was featured on Jungle Scout, started losing a lot of sales because of all the competition,\u201d he said. It became apparent, according to David, that the seller, Your Design Medical, was leaving one- and two-star reviews on competitors\u2019 products. (Amazon said that, after an investigation, it did not find Your Design Medical guilty of reviews abuse. Your Design Medical did not respond to a request for comment sent to its customer support email address from BuzzFeed News.) The only new seller performing well, in spite of the original seller\u2019s bad reviews, was also, in David\u2019s view, \u201ccheating the system.\u201d \u201cThe listing had 33 five-star reviews. There\u2019s no way you can get 33 reviews in two months. That\u2019s unusual for a product like this,\u201d he said. In the end, David didn\u2019t end up buying reviews \u2014 but added that \u201cif I really needed FBA for my income, I would have.\u201d Many compensated reviewers, and the sellers who hire them, don\u2019t see themselves as bad actors. They\u2019re just one of the thousands of other reviewers and sellers doing the exact same thing. Taking shortcuts, they say, is just leveling the playing field. Inside Amazon\u2019s massive marketplace, there are lots of places to hide, to optimize, to cheat \u2014 and, because sellers can\u2019t control the algorithms, they\u2019ll do everything they can to sway them. Amazon has tried to crack down on the review fraud on its platform. The company has sued more than 1,000 people for writing or selling fake reviews. In its 2015 suit against freelancers on the website Fiverr, Amazon said it \u201ctakes the credibility of its customer reviews seriously,\u201d and also asserted, \u201cWhile small in number, these reviews can significantly undermine the trust that consumers and the vast majority of sellers and manufacturers place in Amazon, which in turn tarnishes Amazon\u2019s brand.\u201d In its seller marketplace guidelines, provided to BuzzFeed News by a third-party seller, Amazon says that sellers \u201cmay not offer compensation for a review, and you may not review your own products or your competitors\u2019 products.\u201d Sellers can \u201cask buyers to write a review in a neutral manner,\u201d without asking specifically for positive reviews, or \u201cask reviewers to change or remove their reviews.\u201d And yet all of these behaviors persist. This card, which was shipped to Amazon customer Jeff Axelrod along with his order, requests a five-star review in exchange for a $10 Amazon gift certificate. In this email to another Amazon customer, a seller asks a customer to update his review after initiating a refund. Sam Feldman started selling CardBuddy, a stick-on wallet for phones, on Amazon as a college student. CardBuddy was the first leather product of its kind on Amazon, but Feldman didn\u2019t have a patent. Competitors quickly copied the product, its packaging, and even used CardBuddy\u2019s photos. One seller had gained 500 reviews in two months. According to Feldman, the reviews were \u201cclearly fake.\u201d \u201cOne day my sales were cut in half, and it was so upsetting,\u201d Feldman told BuzzFeed News. \u201cIt stayed like that forever. More competition came, and maybe they had better photos or better titles\u2026but I don\u2019t know,\u201d he said. An Amazon spokesperson said, \u201cWe encourage rights owners who have product authenticity concerns to notify us; we investigate all claims thoroughly. We remove suspected counterfeit items as we become aware of them, and we permanently remove bad actors from selling on Amazon.\u201d Feldman says that the company promptly took down the copycat listing and marked CardBuddy as the copyright holder of its own photos. But according to Feldman, it took a few months for Amazon to remove the hundreds of disingenuous reviews. Feldman thinks Amazon could do more to tackle fraudulence on the platform: \u201cFrom one side, Amazon started this business, and they\u2019re inviting people in to sell on their website. Amazon is looking out for the system as a whole, and not for me, which I understand. But, at the same time, what do you do when someone\u2019s making a living off of it?\u201d Shutting down disingenuous reviews is tricky for Amazon. By doing so, the company risks alienating sellers, a core part of its business. In 2017, more than half of units sold on Amazon globally were from third-party sellers, and more than 140,000 of what Amazon defines as \u201csmall and medium-sized businesses\u201d surpassed $100,000 in sales. The company earns revenue not only from hosting product listings but from each sale made through the site, from fulfillment fees based on weight for each shipping order and use of storage real estate in its fulfillment centers. Revenue from seller services accounted for $23 billion in 2016. Amazon is the place to be for e-commerce sellers and is increasingly seen as a utility. In 2017, Amazon accounted for nearly half of all e-commerce sales in the US (44%) with $196.8 billion in sales. Like entrepreneurs during the dot-com boom, people are rushing to sell on Amazon, and sites like AliExpress make it easy for anyone to acquire massive amounts of inventory. (AliExpress even runs its own fulfillment program.) This rush \u2014 which includes acquiring positive reviews to rise to the top of Amazon\u2019s search algorithms to sell off that inventory as quickly as possible \u2014 can displace sellers, who are less in tune with the velocity and inhumanity of the platform\u2019s algorithms and how punishing they can be as a result. The company, through lawsuits, human moderators, and algorithms, is trying to keep fake reviews off the site, but the review mills that produce those disingenuous ratings may always be one step ahead of Amazon\u2019s ability to moderate them. Like Twitter, Facebook, and Google, Amazon set out to create a neutral platform and invited the internet to come and make something of it. But like Twitter, Facebook, and Google, Amazon allowed its platform to be big and comprehensive \u2014 and grow far beyond its control. But the difference between Amazon and, say, Twitter, is that its users\u2019 livelihoods are dependent on the former. Meanwhile, Amazon\u2019s customers \u2014 left in the dark about the sophisticated mechanics behind the seemingly genuine reviews that guide their purchasing decisions \u2014 continue to buy products of shoddy quality that don\u2019t meet their expectations.  Whaley paused for a while when asked what more Amazon could do to keep reviews off the platform. \u201cThe fake reviews and sales are so intertwined now. I don\u2019t know how they can get rid of it. It seems hopeless. The reviews process was amazing when they started it, but it\u2019s been so corrupted now,\u201d she said. With a heavy sigh, Whaley continued: \u201cAmazon really is\u2014 It is a great site, but as prevalent as fake reviews are over the internet, I don\u2019t know how anybody can get in front of it. Cheaters are always going to cheat.\u201d \u25cf The story has been updated to clarify that there are 58.5 million reviews in ReviewMeta's dataset, of which 9.1% (or 5.3 million) have been identified as \"unnatural.\" An earlier version of this story misstated the number of reviews in ReviewMeta\u2019s dataset. \n  buzzfeed.com\n  \n      Nicole Nguyen covers products and personal technology for BuzzFeed News and is based in San Francisco.\n     \n     Contact Nicole Nguyen at nicole.nguyen@buzzfeed.com.\n     \n     Got a confidential tip? Submit it here.\n     Great! \n        \n          You're almost there! Check your inbox and confirm your subscription now!\n        \n       BuzzFeed HomeSitemap\u00a9 2018 BuzzFeed, Inc.","time":1525797016,"title":"Amazon\u2019s Fake Review Economy","type":"story","url":"https:\/\/www.buzzfeed.com\/nicolenguyen\/amazon-fake-review-problem"},{"by":"simonswords82","descendants":1,"id":17022117,"kids":"[17025631]","score":6,"text":"\nBy\nJessica Webb\non\n\r\n                April\r\n                24,\r\n                2018\r\n            \nin\n\nTrello News\n\n  With over two billion\u00a0cards created to date, Trello users are planning, prioritizing, and producing like never before. If you were to swap those Trello cards for sticky notes, you\u2019d be running out of space. In fact, you\u2019d need a wall 100,000 miles long to hold all of those three-inch pieces of paper next to each other.  Two billion ideas, tasks, and projects are no small feat! From cards for humanitarian aid to cards for camping trips\u2014congratulations and thank you for inspiring all of us to dream, plan, and do. Trello has always been a place to get organized and get stuff done, so why stop there? After hearing from you about what you\u2019d like to see next, we are so excited to launch the biggest Trello refresh yet: a brand spankin' new home view for all of your Trello activities and a better notifications system to help you focus and get even more done! These features will be gradually rolling out over the next week, so hold tight if you don\u2019t see them just yet. Tweet it out:\u00a0Holy moly, 2 billion @trello cards! Let\u2019s celebrate with these majorly productive upgrades:\u00a0bit.ly\/trellohome\u00a0  Imagine a world in which everything that\u2019s most important to you can be accessed from one place. No more searching through layers of boards, tasks, and comments, then trying to prioritize the lot ad hoc\u2014this is a central base of operations for your productivity. Welcome home. Like your own assistant, the new Trello home view is personalized for your priorities, and will give you the high-level perspective you need across your Trello account. By displaying an activity feed from your Trello teams, home automatically surfaces the information you need, when you need it. Let the information come to you and browse at your own pace. Get a shared view of what everyone on your team is working on without having to dig through every individual board.  Learn more about how new sections \"Up Next\u201d and \u201cHighlights\u201d will bring you and your team more clarity on top priorities and must-read updates: Read More Here  When you are constantly bombarded by notifications, it can take all your willpower to not just throw your phone or computer at the wall and walk away. But what if you miss something important? It\u2019s time to start taking control of your notifications\u2014your Trello ones at least! In this major update, notifications have been revamped with your productivity in mind.\u00a0You can now mark individual alerts as \u2018read\u2019 or \u2018unread\u2019 depending on what you want to address. Not only that, you're able to\u00a0change due dates, mark cards as done, and stop watching a card from within the notifications panel. And stay tuned, more is on the way! Engaging with notifications in Trello is now more delightful and useful (the way it should be). Take a tour of your new organizing power in this deep dive: Read More Here Whether you\u2019re planning a family vacation, a company conference\u2014or both at the same time\u2014Trello can give you productivity piece of mind and help you feel at home with everything that\u2019s on your plate. From the big picture down to the nitty-gritty details, you and your team will have the ability to manage it all in one place. So go on, then! Get inspired, get organized, and get your most meaningful work done where you\u2019re most comfortable. Note: These features are gradually rolling out over the next week, so don't worry if you don't see them just yet.\u00a0\ud83d\ude42\u00a0 Good or bad, we'd love to hear your thoughts. Find us on Twitter (@trello) or write in to\u00a0support@trello.com. Trello lets you work more collaboratively and get more done. No goal is too big for Trello. Are you ready to dream big in 2018? \u00a9 Copyright 2017, Trello, Inc. All rights reserved.","time":1525796552,"title":"Trello launches largest user interface overhaul to date","type":"story","url":"https:\/\/blog.trello.com\/2-billion-cards-with-trello-home"},{"by":"eplanit","descendants":5,"id":17021115,"kids":"[17025238, 17022723]","score":14,"text":"Major study suggests Britain could lower its rates of cancer, diabetes and cardiovascular disease by promoting the diets \nIan Sample Science editor \n\nMon 7 May 2018 13.08\u00a0EDT\n\n\nLast modified on Mon 7 May 2018 17.00\u00a0EDT\n\n Britain could lower its rates of cancer, diabetes and cardiovascular disease by embracing Mediterranean- or Nordic-style diets, a major study into the benefits of healthy eating suggests. A review by the World Health Organization found compelling evidence that both diets reduce the risk of the common diseases, but noted that only 15 out of 53 countries in its European region had measures in place to promote the diets. The authors of the report compiled evidence on the health impacts of the two diets from academic journals, conference papers and books, then reviewed government and health ministry websites for national policies and guidelines on healthy eating. Eight countries including Ireland, Spain and Greece promoted the benefits of the Mediterranean-style diet, while seven including Norway, Sweden, Finland and Iceland recommended people adopt a Nordic-style diet to remain healthy. \u201cBoth of these diets are really good in terms of impact on health. That is not in doubt,\u201d said Joa\u0303o Breda from the WHO\u2019s European office for prevention and control of noncommunicable diseases. \u201cWe wanted to know whether countries were using them to inform healthy eating policies.\u201d In England, the government recommends people eat five portions of fruit and vegetables per day on the back of evidence that such a diet can reduce the risk of heart disease and stroke. But ministers have been accused of doing too little to discourage unhealthy eating, despite a rise in childhood obesity rates to 10%. The traditional Mediterranean diet is rich in fruit, vegetables, nuts, cereals and olive oil, includes a moderate amount of fish and poultry, and has very little dairy, red meat, processed meat and sweets. The Nordic diet is similar, focusing on vegetables, berries, pulses, whole grain cereals and fatty fish such as herring, mackerel and salmon. Instead of olive oil, the Nordic diet favours rapeseed oil. According to the report, both diets helped to reduce cases of chronic illnesses, such as heart disease, stroke, diabetes and some cancers. Many of the conditions are driven by obesity. According to Cancer Research UK, more than one in 20 cancers are linked to being overweight or obese. The number of adults and older teens with diabetes has doubled in the past 20 years on the back of rising obesity rates, with 3.7 million people aged 17 or older now living with the disease.  \u201cAll countries need to do more in terms of promoting good diets, because we have an emergency here,\u201d Breda said. \u201cWe are not recommending any particular diet, but when countries think about the improvements they want to make, they might be inspired by these diets. If you adopt them, you save the health system money. There are lots of advantages.\u201d","time":1525789817,"title":"Embrace Mediterranean or Nordic diets to cut disease, WHO says","type":"story","url":"https:\/\/www.theguardian.com\/science\/2018\/may\/07\/embrace-mediterranean-or-nordic-diets-to-cut-disease-who-says"},{"by":"tysone","descendants":18,"id":17021011,"kids":"[17024940, 17023817, 17022887, 17022934, 17023109, 17023496, 17024594]","score":89,"text":"Advertisement Supported by By David Brooks Opinion Columnist This column is about a man who changed the world, at least twice. I want to focus less on the impact of his work, which is all around us, and more on how he did it, because he\u2019s a model of how you do social change. Stewart Brand was born in Rockford, Ill., in 1938, the son of an advertising executive. By the early 1960s, he felt alienated from boring, bourgeois suburbia and concluded that Native Americans had a lot to teach the rest of us about how to lead a more authentic way of life. In 1965, he created a multimedia presentation called \u201cAmerica Needs Indians,\u201d which he performed at the LSD-laced, proto-hippie gatherings he helped organize in California. Brand then had two epiphanies. First, there were no public photos of the entire earth. Second, if people like him were going to return to the land and lead natural lives, they would need tools. He lobbied NASA to release a photograph of the whole earth, which became an iconic image for the environmental movement. Then he slapped the picture on the cover of what he called the \u201cWhole Earth Catalog.\u201d The catalog was an encyclopedia of useful items for people heading to a commune \u2014 home weaving kits, potter\u2019s wheels, outdoor gear. But it was also a bible for what would come to be known as the counterculture, full of reading lists and rich with the ideas of Buckminster Fuller and others. \u201cWhole Earth Catalog\u201d sold 2.5 million copies, won the National Book Award and defined an era. When a culture changes, it\u2019s often because a small group of people on society\u2019s margins find a better way to live, parts of which the mainstream adopts. Brand found a magic circle in the Bay Area counterculture. He celebrated it, publicized it, gave it a coherence it otherwise lacked and encouraged millions to join. The catalog featured an iconic central character, the Cowboy Nomad, who served as symbol and role model. Brand took influences from different parts of America \u2014 the New York art world, farmers, academic visionaries like Marshal McLuhan \u2014 and synthesized them into one ethos. He crowdsourced later editions, asking readers to recommend other cool products to feature. The communes fizzled. But on the other side of the Bay Area, Brand sensed another cultural wave building. Back in the 1960s, computers seemed like the ultimate establishment device \u2014 IBM and the government used them to reduce people to punch cards. But Brand and others imagined them launching a consciousness revolution \u2014 personal tools to build neural communities that would blow the minds of mainstream America. As Fred Turner says in \u201cFrom Counterculture to Cyberculture,\u201d \u201cWhat the communes failed to accomplish, the computers would complete.\u201d Brand played cultural craftsman once again, this time first as a celebratory journalist. In 1972 he wrote a piece for Rolling Stone announcing the emergence of a new outlaw hacker culture. The hackers were another magic circle on the cutting edge of the future, a circle Brand would publicize and inspire others to join. As my Times colleague John Markoff, who is writing a biography of Brand, notes, Brand is a talented community architect. In the 1970s, he was meshing Menlo Park computer geeks with cool hippie types. The tech people were entranced by \u201cWhole Earth,\u201d including Steve Jobs and Frederick Moore, co-creator of the celebrated Homebrew Computer Club. Brand meshed the engineers with the Merry Pranksters and helped give tech a moral ethos, a group identity, a sense of itself as a transformational force for good. In 1985, Brand and Larry Brilliant helped create the Well, an early online platform (like Usenet) where techies could meet and share. He helped Kevin Kelly organize hacker conferences, which attracted media attention. As Silicon Valley became more corporate in the 1980s and 1990s, he also helped form the Learning Conferences, Worldview Meetings, the Global Business Net and other convenings that gathered the multidisciplinary theorists and journalists who would define the wired culture: Kelly, Esther Dyson, Tim Berners-Lee and Nicholas Negroponte. Brand\u2019s gift, Frank Foer writes in \u201cWorld Without Mind,\u201d is \u201cto channel the spiritual longings of his generation and then to explain how they could be fulfilled through technology.\u201d Innovations don\u2019t just proceed by science alone; as Foer continues, \u201cthe culture prods them into existence.\u201d Turner argues that Brand has always craved a sensation of wholeness, a feeling of belonging and authenticity. He has found communities that gave him that sensation and has encouraged millions to love what he has loved. He synthesized a cultural ethos, and then tried to embody and spread that ethos through festivals, conferences and organizations. Brand vehemently disagrees with me, but I\u2019d say that, more recently, the computer has also failed as a source of true community. Social media seems to immiserate people as much as it bonds them. And so there\u2019s a need for future Brands, young cultural craftsmen who identify those who are building the future, synthesizing their work into a common ethos and bringing them together in a way that satisfies the eternal desire for community and wholeness. Follow The New York Times Opinion section on Facebook and Twitter (@NYTopinion), and sign up for the Opinion Today newsletter. Advertisement    Collapse SEE MY OPTIONS","time":1525788936,"title":"Stewart Brand Changed the World, Twice","type":"story","url":"https:\/\/www.nytimes.com\/2018\/05\/07\/opinion\/stewart-brand-hippie-silicon.html"},{"by":"nickjj","descendants":94,"id":17020944,"kids":"[17021061, 17021410, 17021139, 17021843, 17021369, 17021468, 17021419, 17021350, 17026168, 17021354, 17023177, 17021691, 17023775, 17021189, 17024844, 17021721, 17024993, 17021093, 17021188, 17021191, 17026254]","score":241,"text":" Dive into Docker takes you from \"What is Docker?\" to confidently applying Docker to your own projects. It's packed with best practices and examples. Start Learning Docker \u2192 Updated on May 8th, 2018 in  #deployment   Quick Jump:  How Did It Happen? | Fixing the Problem in a Few Seconds | Avoiding the Problem in the Future | Domain Validation Should Be More Strict When people talk about a site being compromised, usually you would think that your server has been compromised. That would be someone gaining access to your server and then doing whatever they please. That didn\u2019t happen here. I take security very seriously. I have SSH locked down to only allow SSH key based logins and even root logins are disabled. My site is static too, which means it\u2019s only being hosted through nginx from a non-root user. The only way someone is going to gain access to my server is if they manage to gain access to my workstation and steal my SSH key pair. The odds of that are remote because my workstation never leaves my office and I have the reflexes of a highly trained ninja. So how did a subdomain of mine end up help distributing 390,000+ PDF books without my server being compromised? Well, that\u2019s easy\u2026  It boils down to this. About 2 years ago I was recording a video course that dealt with setting up HTTPS on a domain name. In all of my courses, I make sure to \u201creally\u201d do it on video so that you can see the entire process from end to end. Back then I used nickjanetakis.com for all of my courses, so I didn\u2019t have a dedicated domain name for the course I was working on, such as diveintodocker.com. I also didn\u2019t have a spare domain name that I wanted to publicly share, so I registered a new DigitalOcean droplet to host an example site on. Then I set up an A record to point ssl.nickjanetakis.com to that droplet\u2019s IP address. Cool, there\u2019s nothing wrong with that. Set up a temporary site for recording the course and then delete it afterwards. Easy peasy, and that\u2019s exactly what I did but I forgot to remove the A record when I was done. So for years, I had ssl.nickjanetakis.com pointing to an IP address that I was no longer in control of. That means the owner of that IP address could host anything and it would automatically be mapped to ssl.nickjanetakis.com without me knowing. I have Google Alerts set up so I get emailed when people link to my site. A few months ago I started to receive an absurd amount of notifications, but I ignored them. I chalked it up to \u201cGoogle is probably on drugs\u201d. Stranger things have happened with Google, so I thought maybe something got mixed up. Now I\u2019ve learned my lesson. While bugs roll out into production all the time, Google Alerts being totally busted is super unlikely. Part of my morning routine is to check emails with intent to answer any questions about my courses that may have happened during the night. I usually skim the subject lines to see which emails to answer first but one of them caught my eye. It read \u201cHi, seems your website has been compromised\u201d. Well you don\u2019t see that every day. I figured it was spam that somehow made it to my inbox but I recognized the email because it was someone who signed up for one of my courses. He sent me a screenshot showing a few PDFs being hosted from ssl.nickjanetakis.com, so I immediately went to Google and searched for site:ssl.nickjanetakis.com.  It was mostly college books but there was a ton of other stuff too. Hopefully by the time you read this most of them have been removed from Google\u2019s index.  Since it was linked to a subdomain I instantly knew what was wrong, especially because I remember using that subdomain a few years ago when I made that course. The fix was really easy. I just hopped over to my domain registrar\u2019s DNS settings and deleted the entry that mapped the IP address to that subdomain. But before deleting it, I copied the IP address so I could open a support ticket on DigitalOcean. I figured they would like to know that someone is illegally distributing content on one of their servers. Now that they know the IP address, they can shut it down.  Always remove unused records from your DNS settings when you\u2019re done using them. DigitalOcean and many other cloud providers have purchased blocks of IP addresses and they provide these IP addresses to people like you and me. When a droplet gets destroyed, the IP address eventually gets put into the public pool of available IP addresses and someone else will get it. This is pretty scary because things like the above can happen if you\u2019re not careful, but it also means if an IP address were blacklisted for doing something questionable, you might end up with that IP address in the future (but that\u2019s a totally different problem).  I think this brings up an interesting question. Right now you can validate you own a domain by putting an HTML snippet on your page. Services like Google Analytics allow for this. Technically the person who took control over ssl.nickjanetakis.com could have proven ownership of that subdomain if they set up a page and hooked it up to Google Analytics. Also, Let\u2019s Encrypt\u2019s web server based challenge would have passed. I know I made a stupid mistake by not removing the A record but this could happen to anyone. I would like to see more services only allow for DNS based authentication by adding TXT records. Although I suppose the bigger problem here is having IP addresses being recycled. Hopefully once IPv6 is fully in use we\u2019ll have a big enough pool so that hosting providers can remove previously used addresses from their pool. That won\u2019t be fool proof, but it\u2019s a start. Has this ever happened to you? Let me know in the comments below! Like you, I'm super protective of my inbox, so don't worry about getting spammed. You can expect a few emails per month (at most), and you can 1-click unsubscribe at any time. See what else you'll get too. \u00a9 2018 Nick Janetakis","time":1525788357,"title":"A Recycled IP Address Caused Me to Pirate Books by Accident","type":"story","url":"https:\/\/nickjanetakis.com\/blog\/a-recycled-ip-address-caused-me-to-pirate-390000-books-by-accident"},{"by":"WhiteSource1","descendants":0,"id":17019939,"kids":"None","score":7,"text":"A monster distributed denial-of-service attack (DDoS) against KrebsOnSecurity.com in 2016 knocked this site offline for nearly four days. The attack was executed through a network of hacked \u201cInternet of Things\u201d (IoT) devices such as Internet routers, security cameras and digital video recorders. A new study that tries to measure the direct cost of that one attack for IoT device users whose machines were swept up in the assault found that it may have cost device owners a total of $323,973.75 in excess power and added bandwidth consumption. My bad. But really, none of it was my fault at all. It was mostly the fault of IoT makers for shipping cheap, poorly designed products (insecure by default), and the fault of customers who bought these IoT things and plugged them onto the Internet without changing the things\u2019 factory settings (passwords at least.)  The botnet that hit my site in Sept. 2016 was powered by the first version of Mirai, a malware strain that wriggles into dozens of IoT devices left exposed to the Internet and running with factory-default settings and passwords. Systems infected with Mirai are forced to scan the Internet for other vulnerable IoT devices, but they\u2019re just as often used to help launch punishing DDoS attacks. By the time of the first Mirai attack on this site, the young masterminds behind Mirai had already enslaved more than 600,000 IoT devices for their DDoS armies. But according to an interview with one of the admitted and convicted co-authors of Mirai, the part of their botnet that pounded my site was a mere slice of firepower they\u2019d sold for a few hundred bucks to a willing buyer. The attack army sold to this ne\u2019er-do-well harnessed the power of just 24,000 Mirai-infected systems (mostly security cameras and DVRs, but some routers, too). These 24,000 Mirai devices clobbered my site for several days with data blasts of up to 620 Gbps. The attack was so bad that my pro-bono DDoS protection provider at the time \u2014 Akamai \u2014 had to let me go because the data firehose pointed at my site was starting to cause real pain for their paying customers. Akamai later estimated that the cost of maintaining protection against my site in the face of that onslaught would have run into the millions of dollars. We\u2019re getting better at figuring out the financial costs of DDoS attacks to the victims (5, 6 or 7 -digit dollar losses) and to the perpetrators (zero to hundreds of dollars). According to a report released this year by DDoS mitigation giant NETSCOUT Arbor, fifty-six percent of organizations last year experienced a financial impact from DDoS attacks for between $10,000 and $100,000, almost double the proportion from 2016. But what if there were also a way to work out the cost of these attacks to the users of the IoT devices which get snared by DDos botnets like Mirai? That\u2019s what researchers at University of California, Berkeley School of Information sought to determine in their new paper, \u201crIoT: Quantifying Consumer Costs of Insecure Internet of Things Devices.\u201d If we accept the UC Berkeley team\u2019s assumptions about costs borne by hacked IoT device users (more on that in a bit), the total cost of added bandwidth and energy consumption from the botnet that hit my site came to $323,973.95. This may sound like a lot of money, but remember that broken down among 24,000 attacking drones the per-device cost comes to just $13.50. So let\u2019s review: The attacker who wanted to clobber my site paid a few hundred dollars to rent a tiny portion of a much bigger Mirai crime machine. That attack would likely have cost millions of dollars to mitigate. The consumers in possession of the IoT devices that did the attacking probably realized a few dollars in losses each, if that. Perhaps forever unmeasured are the many Web sites and Internet users whose connection speeds are often collateral damage in DDoS attacks. Image: UC Berkeley. Anyone noticing a slight asymmetry here in either costs or incentives? IoT security is what\u2019s known as an \u201cexternality,\u201d a term used to describe \u201cpositive or negative consequences to third parties that result from an economic transaction. When one party does not bear the full costs of its actions, it has inadequate incentives to avoid actions that incur those costs.\u201d In many cases negative externalities are synonymous with problems that the free market has a hard time rewarding individuals or companies for fixing or ameliorating, much like environmental pollution. The common theme with externalities is that the pain points to fix the problem are so diffuse and the costs borne by the problem so distributed across international borders that doing something meaningful about it often takes a global effort with many stakeholders \u2014 who can hopefully settle upon concrete steps for action and metrics to measure success. The paper\u2019s authors explain the misaligned incentives on two sides of the IoT security problem: -\u201cOn the manufacturer side, many devices run lightweight Linux-based operating systems that open doors for hackers. Some consumer IoT devices implement minimal security. For example, device manufacturers may use default username and password credentials to access the device. Such design decisions simplify device setup and troubleshooting, but they also leave the device open to exploitation by hackers with access to the publicly-available or guessable credentials.\u201d -\u201cConsumers who expect IoT devices to act like user-friendly \u2018plug-and-play\u2019 conveniences may have sufficient intuition to use the device but insufficient technical knowledge to protect or update it. Externalities may arise out of information asymmetries caused by hidden information or misaligned incentives. Hidden information occurs when consumers cannot discern product characteristics and, thus, are unable to purchase products that reflect their preferences. When consumers are unable to observe the security qualities of software, they instead purchase products based solely on price, and the overall quality of software in the market suffers.\u201d The UC Berkeley researchers concede that their experiments \u2014 in which they measured the power output and bandwidth consumption of various IoT devices they\u2019d infected with a sandboxed version of Mirai \u2014 suggested that the scanning and DDoSsing activity prompted by a Mirai malware infection added almost negligible amounts in power consumption for the infected devices. Thus, most of the loss figures cited for the 2016 attack rely heavily on estimates of how much the excess bandwidth created by a Mirai infection might cost users directly, and as such I suspect the $13.50 per machine estimates are on the high side. No doubt, some Internet users get online via an Internet service provider that includes a daily \u201cbandwidth cap,\u201d such that over-use of the allotted daily bandwidth amount can incur overage fees and\/or relegates the customer to a slower, throttled connection for some period after the daily allotted bandwidth overage. But for a majority of high-speed Internet users, the added bandwidth use from a router or other IoT device on the network being infected with Mirai probably wouldn\u2019t show up as an added line charge on their monthly bills. I asked the researchers about the considerable wiggle factor here: \u201cRegarding bandwidth consumption, the cost may not ever show up on a consumer\u2019s bill, especially if the consumer has no bandwidth cap,\u201d reads an email from the UC Berkeley researchers who wrote the report, including Kim Fong, Kurt Hepler, Rohit Raghavan and Peter Rowland. \u201cWe debated a lot on how to best determine and present bandwidth costs, as it does vary widely among users and ISPs,\u201d they continued. \u201cCosts are more defined in cases where bots cause users to exceed their monthly cap. But even if a consumer doesn\u2019t directly pay a few extra dollars at the end of the month, the infected device is consuming actual bandwidth that must be supplied\/serviced by the ISP. And it\u2019s not unreasonable to assume that ISPs will eventually pass their increased costs onto consumers as higher monthly fees, etc. It\u2019s difficult to quantify the consumer-side costs of unauthorized use \u2014 which is likely why there\u2019s not much existing work \u2014 and our stats are definitely an estimate, but we feel it\u2019s helpful in starting the discussion on how to quantify these costs.\u201d  Measuring bandwidth and energy consumption may turn out to be a useful and accepted tool to help more accurately measure the full costs of DDoS attacks. I\u2019d love to see these tests run against a broader range of IoT devices in a much larger simulated environment. If the Berkeley method is refined enough to become accepted as one of many ways to measure actual losses from a DDoS attack, the reporting of such figures could make these crimes more likely to be prosecuted. Many DDoS attack investigations go nowhere because\u00a0targets of these attacks fail to come forward or press charges, making it difficult for prosecutors to prove any real economic harm was done. Since many of these investigations die on the vine for a lack of financial damages reaching certain law enforcement thresholds to justify a federal prosecution (often $50,000 \u2013 $100,000), factoring in estimates of the cost to hacked machine owners involved in each attack could change that math. But the biggest levers for throttling the DDoS problem are in the hands of the people running the world\u2019s largest ISPs, hosting providers and bandwidth peering points on the Internet today. Some of those levers I detailed in the \u201cShaming the Spoofers\u201d section of The Democraticization of Censorship, the first post I wrote after the attack and after Google had brought this site back online\u00a0under its Project Shield program. By the way, we should probably stop referring to IoT devices as \u201csmart\u201d when they start misbehaving within three minutes of being plugged into an Internet connection. That\u2019s about how long your average cheapo, factory-default security camera plugged into the Internet has before getting successfully taken over by Mirai. In short, dumb IoT devices are those that don\u2019t make it easy for owners to use them safely without being a nuisance or harm to themselves or others. Maybe what we need to fight this onslaught of dumb devices are more network operators turning to ideas like IDIoT, a network policy enforcement architecture for consumer IoT devices that was first proposed in December 2017.\u00a0 The goal of IDIoT is to restrict the network capabilities of IoT devices to only what is essential for regular device operation. For example, it might be okay for network cameras to upload a video file somewhere, but it\u2019s definitely not okay for that camera to then go scanning the Web for other cameras to infect and enlist in DDoS attacks. So what does all this mean to you? That depends on how many IoT things you and your family and friends are plugging into the Internet and your\/their level of knowledge about how to secure and maintain these devices.\u00a0Here\u2019s a primer on minimizing the chances that your orbit of IoT things become a security liability for you or for the Internet at large. \n Tags: Akamai, DDoS, google, IdioT, internet of things, IoT, Kim Fong, Kurt Hepler, mirai, NETSCOUT Arbor, Peter Rowland, Project Shield, Rohit Raghavan, UC Berkeley \n\r\n\t\t\t\t\t\tThis entry was posted on Monday, May 7th, 2018 at 12:47 pm\t\t\t\t\t\tand is filed under DDoS-for-Hire.\r\n\t\t\t\t\t\tYou can follow any comments to this entry through the RSS 2.0 feed.\r\n\r\n\t\t\t\t\t\t\t\t\t\t\t\t\tYou can skip to the end and leave a comment. Pinging is currently not allowed.\r\n\r\n\t\t\t\t\t\t\r\n\t\t\t\t\t\n WRT \u201cWhen one party does not bear the full costs of its actions, it has inadequate incentives to avoid actions that incur those costs.\u201d Nassim Nichols Taleb, author of a number of books including The Black Swan, Antifragile, Skin In the Game; writes extensively on this. He work is very applicable in cyber (crime), and is starting to speak in the cyber arena too.  (http:\/\/www.fooledbyrandomness.com) Some of us are working on\/researching cost figures of cyber (crime) using his work. Pet peeve: \u201c$323,973.75\u201d   Since this is really just a wild assed guess, it would be nice if Berkeley emphasized this by using less precise figures, like \u201cabout $300,000.\u201d That was Krebs\u2019 estimate using their online tool, which outputs a figure based on the data you input. Their papers actually says \u201cthe median cost is close to $300,000\u201d. It seems that we have come a long way some times then not really that far since the first telegraph or semaphore and now with the digital internet and so many digital devices, operating systems and software.  At the beginning of telephone Northern Electric was started to manufacture telephone so there might be uniformity. There is no real uniformity with all the digital devices and those using them are expecting they do everything for them, including protect them. I used to use a user configurable firewall that was very good as it blocked everything in or out without permission, it also showed all attempts on my system. This firewall is now very old but I feel this is what we need on all of our devices, also to educate people like safe sex to protect themselves. Maybe some will listen and others be the same as before. It was Gilfoyl. lmao! You\u2019re a legend, Brian Krebs. Keep up the good work! I find it extremely hard to believe that someone would make an attempt to knock your blog online. Nevertheless; you are a legend, Brian Krebs. Keep up the good work! \u201conline\u201d  \u2013 was there a misspelling?  I can believe it, because many of us couldn\u2019t reach his site for days during this DDOS attack! He was definitely knocked OFFLINE. I do remember being unable to access his site, yet I wouldn\u2019t have guessed any intentional disruption to the blog. Someone with a disliking to Krebs, perhaps? You havent been paying enough attention then, lol.  I believe this site was hit after Brian doxxed the owners of vDOS, which led to their arrest, or after he doxxed the creator of Mirai, which eventually led to his arrest.  Im willing to bet there are quite a few criminals out there who dont like Brian. The externality analogy is okay, but in my view that applies more to situations like Person A taking an action that hurts Person B without intending to do so.  For example, I drive my car, which pollutes your air, hurting you.  Driving my car creates an externality on you, but I am not intending to hurt you, and probably don\u2019t know who you are. I think a better analogy might be that of asymetric or hybrid warfare, where Combatant A (e.g. an insurgency) can attack Combatant B (e.g. an army) at low cost, because it attacks in limited unpredictable locations, uses unexpected strategies or weapons that are hard to counter, etc.  Think of Iraq after the \u201cMission Accomplished\u201d fiasco:  small groups of insurgents with inexpensive weapons caused the American government to spend billions of dollars to defend thousands of US soldiers. Just a thought, calculate the costs and access a treble damage fine on the miscreants.  That would probably include the IoT device makers. Bought a new router the other day, so I could handle the new fiber speeds. The technician thought I was crazy for changing the administrator side login password \u2013 Many of you know the  one \u201cadmin\u201d \u201cpassword\u201d \u2013 talk about idiots, those manufacturers need to make it easier for newbies to setup things like that \u2013 oddly enough, this manufacturer did supply its own user ID and generated password for the wireless but not the LAN Ethernet administration side. My technician just couldn\u2019t believe that malware can take over your router from the user side of the network!!! How many years has this been a problem??!! Sheeze, if he didn\u2019t know this, how is Joe Sixpack going to figure it out??!! Unsuprisingly, many router manufacturers ship their routers with a configuration of the sort you just described; which makes installation \u2018easier\u2019 for the average consumer, but is still a terrible security practice. I\u2019ve had a pretty good experience with the AirPort line of routers, manufactured by Apple; they\u2019re fairly simple to install, but are coupled with considerable in-built security. Many \u2018firmwares\u2019 pre-installed with routers are just down-right horrendous. Just remember to disable WAN side administration in case the criminals find a backdoor or an OEM master key; and change the factory default password for the LAN side access. Unfortunately, Apple has recently discontinued the AirPort line. I read about this, and it\u2019s very sad to me; but, since I\u2019ve never had to repair (or service) one, I don\u2019t plan to \u2018replace\u2019 my AirPort station any time soon. Ne\u2019er-do-well? Don\u2019t you mean \u201cmiscreant?\u201d Seriously, how can owners of the \u201cthings\u201d tell when their thing is misbehaving? Readily moderating network activity. and following his guide on how-to prevent such: https:\/\/krebsonsecurity.com\/2018\/01\/some-basic-rules-for-securing-your-iot-stuff\/ So Akamai provided you with a service until the time that you REALLY need it. They should thank you for allowing them to deal with something new. As it is, it just says their ddos protection is limited. While that may not be completely fair, if they think they won\u2019t have the same problem again with a different client in the future they are probably wrong. But the larger issue to me is that the ISP industry needs to get organized and find ways to deal with large scale problems. If the Mirai attack only used about 1\/24 of the botnet at that time, just imagine what it\u2019s full potential was then and may be now? ISPs need to be able to deal with attacks like this. I see no reason why an attack on a site can\u2019t be identified and then all or some bot traffic be redirected to 127.0.0.1 for a period of time. The traffic generated by the redirection could be a signal to upstream ISPs that there is a problem with local equipment. At the kind of scale we are talking about (500Gbps+), all DDoS mitigation, regardless of company delivering it, is limited. The issue is not the devices for scrubbing data, but the peering points and peering connections between ISPs and network providers. DDoS mitigation providers like to talk about \u201cmitigation capacity\u201d, but this is an aggregated capacity measured over dozens of peering points and many fibre connections. Attack traffic is not always spread evenly over peering points. There are bottlenecks. A Cloud security provider like Akamai has far more peering and greater capacity than most ISPs to try and soak up the impact of a large-scale DDoS attack, but that scale of infrastructure costs money to build and maintain and cannot be built on the principle of offering unlimited mitigation to every customer at the same time, because the cost per customer would be prohibitive. No-one knows how a given DDoS attack will appear across the peering points. There may be geographical bias (eg. infection of Chinese language browsers) or attack blended with legitimate traffic (reflection attacks) \u2013 and so each one will stress a different range of peering points. Many ISPs resort to black-holing target networks to protect their other paying customers, preferring to have one difficult conversation with the victim of a DDoS attack rather than hundreds of difficult conversations with all of their customers. However this is not satisfactory for businesses that cannot any outages at all.  Also relying on on-premise mitigation for first visibility of a DDoS attack can struggle when the connection from that site to the public Internet is flooded or disabled in and of itself. But identifying DDoS attack traffic from legitimate web-site traffic in an application attack, or when traffic is encrypted, might not be possible in the cloud. Although you might not be able to see any reason why certain solutions to DDoS attacks would not be easy to implement, I can assure you that the industry is refining responses to the DDoS threat landscape continually, and that attacks and the defences against them are becoming much more sophisticated. At the moment, some attackers abilities to DDoS exceeds anyone\u2019s ability to mitigate the impact. It\u2019s not a technical or even a political issue, but an economic one. Max \u2013 excellent illustration of the complexity of fighting big attacks. Even if defenders have really big pipes you still need to take into account the infrastructure those big pipes are connected to. How about a federal 1% tax on any internet connected device or platform? The revenue could be held in escrow with some being used to pay huge bug bounties and fund security research\/testing. If a company could provide a clean bill of health for a product after 10 years, they could get their taxes back. Government should never be entrusted with public money, regardless of the purity of intentions. It will always find a way to waste or lose that money, by virtue of the complexity and size of government itself. Great article as always, but I have a few nits to pick based on my two decades of working in IT security. First of all is the assertion that \u201cIt was mostly the fault of  [vendors]\u2026 and the fault of customers who bought these IoT things and plugged them onto the Internet without changing the things\u2019 factory settings (passwords at least.)\u201d This is one of those things where you can be right and wrong at the same time, but even the part that\u2019s right doesn\u2019t matter.  Yes, people should be more IT security conscious. They should also save money, take care of their bodies. protect the environment, etc., etc., etc. These are based on *our* perceptions of what people should do, but different people have different priorities. Whether this is right or wrong or good or bad (even if such things are possible to determine objectively) it wouldn\u2019t matter people people are going to do what they do anyway. Like the old military saying goes, you go to war with the army you have, not the army you want. In this case, we go to fight the security battles with the consumers and vendors we have, not the consumers and vendors we want. Whether we are right or wrong or they are right or wrong is irrelevant \u2013 the situation is what it is and we have to deal with it as it is.  We have about 2-3 generations of consumers taught that anything they buy is at least reasonably safe due to various consumer regulations and nanny-stating (leaving aside the moral and consequentialist arguments of whether this is good or bad or indifferent). This is combined with a fairly stark regression in critical thinking skills over the last two generations. It is unrealistic to expect consumers to develop habits for exercising any sort of security judgement in their purchasing decisions unless the costs of not doing so become both obvious and significant from their perspective. Right now they are neither, and don\u2019t hold your breath waiting for that to change. On the vendor side, we don\u2019t even have a proven theory for how to develop \u201csafe, secure\u201d computing devices. As the IT sector matures and established vendors have had difficulty finding new ways to add value to customers, they have been pushed by private equity and Wall Street to subscription-based services that provide more reliable revenue streams and growth, at least in the short- to mid-term (I suspect this will eventually backfire spectacularly \u2013 it builds too many opportunities to undercut on pricing and purchasing terms). In some cases, vendors have found ways to deliver additional value in this model but many have not. In any case, this has strongly pushed the \u201ccontinuous release\u201d software \/ firmware model which in practice has been reducing software quality control at a time it\u2019s needed most (\u201cclearing minefields with cattle, and your users are the cattle\u201d is the most apt description I\u2019ve found of this). Another vendor factor is that courts have found very little to no liability for most software flaws \u2013 I\u2019m not sure if there\u2019s a productive way to address this; it is what it is and I\u2019m just pointing it out. It\u2019s very expensive to have a good software lifetime management system in place, and not all vendors have the margins and profits to allow this (especially at the low end). Addressing this would significantly increase prices for many IoT devices and probably eliminate many vendors from markets (and, in some cases, entire markets) in the short term. I think that the only practical approach will be to assume that user behavior will not change significantly and that IoT software quality will largely remain a dumpster fire. This means we have to have additional layers and methods (security systems) to deal with these issues, and that these systems will really need to \u201cup their game\u201d both in terms of efficacy and accessibility to non-geeks. One of the biggest problems in the field is that it is difficult for tools to replace protocols. In IT, you warm up a device with a checklist in hand and ensure that each step builds upon the security of the previous state so that you aren\u2019t compromising previous or subsequent steps. In userland, you plug-in a widget and *BOOM* you\u2019re on the internet! Just generating a secure warm-up checklist for a Raspberry Pi Zero (a $5 Linux computer) is a complicated pain-in-the-tuchis. Wouldn\u2019t it be nice if it insisted on having a real firewalled login\/password account before it enabled network interfaces? Erik, I like the way you write sir. Well stated Erik.  I came here to say this but you did a far better job than I could have. My view is that at this time the only way to insure that your network and IoT devices are not enslaved is to not own any! I refuse to subject my environment to these criminals and I will not enrich vendors that do not give a hoot what happens to others as a result of their cr\u2026y products. Keep fighting Brian. Stick it in their eye whenever you can. On a Raspberry Pi, you essentially have all the security tools that Debian has. You can make the little credit-card-sized device nearly as hardened as an international bank. But it doesn\u2019t ship that way. All Pi\u2019s ship with the user \u201cpi\u201d and the password \u201craspberry\u201d \u2014 and a frightening number of users plug-in to the internet without changing this. A part of the problem is default passwords.  What if IoT devices were shipped with no default password, i.e. with binary zeros in the password field in non-volatile storage?  Further, the factory reset button sets that default password back to zeros. If the setup process required each user to set a password, and the device DID NOT WORK until a password was set, then there\u2019d be no more default passwords.  By \u201cnot work\u201d I mean the device should not perform its intended function until a password is set; cameras wouldn\u2019t take pictures, routers wouldn\u2019t route packets, etc. until a password is set. To be sure, there\u2019d be a bunch of \u201cpassword1\u201d and \u201c12345\u201d but there wouldn\u2019t be any more default passwords.  That won\u2019t solve the problem, but it ought to mitigate it somewhat. Back when email was new and exciting, I was taught that senders of spam had to be careful. Because, if someone sent spam, they could get the equivalent of a brick (many many answering messages) back in their own accounts.  Any way to do this now? I sure hope your Insurance Broker recommended Cyber Liability coverage with Bus. Interruption coverage! I fnot, talk to a good Lawyer. Name (required)\n Email (required)\n Website\n Comment   A New York Times Bestseller!  Click image for my skimmer series. Badguy uses for your PC Tools for a Safer PC  Spammers Duke it Out Your email account may be worth far more than you imagine. eBanking Best Practices for Businesses Innovations from the Underground ID Protection Services Examined The reasons for its decline File 'em Before the Bad Guys Can  A crash course in carding.  Sign up, or Be Signed Up!  Finding out is not so easy.  ...For Online Safety.  \r\n\t\t\u00a9 2018 Krebs on Security. \r\n\t\t\u2002Powered by WordPress. \r\n\u2002Privacy Policy\n","time":1525774662,"title":"Study: Attack on KrebsOnSecurity Cost IoT Device Owners $323K","type":"story","url":"https:\/\/krebsonsecurity.com\/2018\/05\/study-attack-on-krebsonsecurity-cost-iot-device-owners-323k\/"},{"by":"emilymainzer88","descendants":3,"id":17019931,"kids":"[17020117, 17020232]","score":4,"text":"Listen to The Verdict Podcast Get the morning email Subscribe: \n\n\n\n\n I agree to the Verdict Privacy Policy Get our eye opening email newsletter delivered to your inbox daily.  \n\nI agree to the Verdict Privacy Policy\n Twitter\u2019s recommendation that all of its 330 million users around the world change their passwords highlights how jumpy and anxious companies have become around data.\n Last night, Twitter urged its millions of users to change their account passwords, just to be on the safe side. The safe side of what? Twitter sent out the communications after discovering what it called a bug, i.e. an internally stored file containing user passwords written in plain text.\n In a blog post, the company\u2019s chief technology officer Parag Agrawal explained the problem and reassured users that it had been both identified and addressed.\n Nevertheless, Agrawal wrote that the company is urging users to consider changing their passwords \u201cout of an abundance of caution\u201d.\n To be clear, there was never any indication that the file of user\u2019s account passwords in question had been misplaced, stolen, or shared with a third-party.\n But the fact that it existed at all triggered the kind of mass security warning most digital communications providers would prefer not to have to deliver at all \u2013 and especially not these days, with the Facebook data privacy scandal still ongoing.\n And then, Twitter bumbled the delivery.\n Agrawal tweeted a message suggesting that the communication and password change recommendation sent out to users was probably surplus to requirement, but was nevertheless \u201cthe right thing to do\u201d.\n He then retracted that in a later Tweet: \u201cI should not have said we didn\u2019t have to share. I have felt strongly that we should. My mistake\u201d.\n I should not have said we didn\u2019t have to share. I have felt strongly that we should. My mistake. https:\/\/t.co\/Cqbs1KiUWd\n \u2014 Parag Agrawal (@paraga) May 3, 2018\n \n Was it, or wasn\u2019t it, a required step?\n Certainly, Twitter has a duty to inform users of all security breaches and leaks, but in this case, we\u2019re talking about a file of plaintext passwords that was discovered somewhere within the bowels of Twitter\u2019s IT systems.\n Agrawal referred to the file as a bug. But what created it? We\u2019ll probably never know.\n What his blog post adds up to is this: We found a security loophole, and shut it down. We investigated it, and found no evidence to suggest a security breach, but all users should change their password, just in case.\n In case, of what?\n In case, of course, Twitter is mistaken. In case the file has already been leaked, and a hacker is teeing up those passwords to launch misinformation and communication on a new dimension: Fake news, spread over stolen but nevertheless real Twitter accounts.\n Social media bot hacks work on the principle that if you put out a piece of information over enough bots, it will, at one point, be picked up by a real person, with a real account, and spread to friends and family members over social media. It\u2019s a numbers game.\n Most social media platforms, notably Twitter, have already made significant steps to identify and shut down tens of thousands of bots, and it\u2019s now recognised that bot-driven public opinion hacking had a hand in the 2016 US Presidential elections.\n With access to millions of real Twitter password accounts, tomorrow\u2019s democracy hackers could have the ultimate follow-up.\n Sure, it\u2019s a digital doomsday scenario. But in this day and age, its one that we all \u2013 including Twitter \u2013 need to take more seriously.\n So, if you wake up tomorrow to discover your Twitter account spewing a string of outrageous, inflammatory and possibly criminal views that you don\u2019t recognise as being your own, remember: you were warned to change your password. Change it now.\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t  \n\t\t\t\t\t\t  \t\n\nComment WireOpinion \n\n \u00a9 copyright 2018 GlobalData PLC. Contact. About. Privacy Policy","time":1525774477,"title":"Twitter\u2019s heavy handed handling of data breach highlights industry fears","type":"story","url":"https:\/\/www.verdict.co.uk\/twitter-password-change-a-jumpy-anxious-digital-communications-industry\/"},{"by":"cfadvan","descendants":230,"id":17016077,"kids":"[17029081, 17016526, 17017090, 17019755, 17017646, 17017396, 17018869, 17025025, 17016534]","score":296,"text":"If a company like Facebook  can\u2019t even understand why its moderation tools work the way they do, then its users certainly don\u2019t have a fighting shot. Anyway, that\u2019s the idea behind what a coalition of digital rights groups are calling The Santa Clara Principles\u00a0(PDF), \u201ca set of minimum standards\u201d aimed at Facebook, Google, Twitter and other tech companies that moderate the content published on their platforms. The suggested guidelines grew out of a set of events addressing \u201cContent Moderation and Removal at Scale,\u201d the second of which is taking place today in Washington, D.C. The group participating in these conversations shared the goal of coming up with a suggested ruleset for how major tech companies should disclose which content is being censored, why it is being censored and how much speech is censored overall. \u201cUsers deserve more transparency and greater accountability from platforms that play an outsized role \u2014 in Myanmar, Australia, Europe, and China, as well as in marginalized communities in the U.S. and elsewhere \u2014 in deciding what can be said on the internet,\u201d Electronic Frontier Foundation (EFF) Director for International Freedom of Expression Jillian C. York said. As the Center for Democracy and Technology explains, The Santa Clara principles (PDF) ask tech companies to disclose three categories of information: \u201cThe Santa Clara Principles are the product of years of effort by privacy advocates to push tech companies to provide users with more disclosure and a better understanding of how content policing works,\u201d EFF Senior Staff Attorney Nate Cardozo added. \u201cFacebook and Google  have taken some steps recently to improve transparency, and we applaud that. But it\u2019s not enough. We hope to see the companies embrace The Santa Clara Principles and move the bar on transparency and accountability even higher.\u201d Participants in drafting The Santa Clara Principles include the ACLU Foundation of Northern California, Center for Democracy and Technology, Electronic Frontier Foundation, New America\u2019s Open Technology Institute and a handful of scholars from departments studying ethics and communications.","time":1525723831,"title":"Tech watchdogs call on Facebook, Google for transparency around censored content","type":"story","url":"https:\/\/techcrunch.com\/2018\/05\/07\/santa-clara-principles-eff-cdt-aclu-facebook-google-twitter\/"},{"by":"cfadvan","descendants":1,"id":17016061,"kids":"[17016604]","score":7,"text":"Uber has discovered the reason why one of the test cars in its fledgling self-driving car fleet struck and killed a pedestrian earlier this year, according to The Information. While the company believes the car\u2019s suite of sensors spotted 49-year-old Elaine Herzberg as she crossed the road in front of the modified Volvo XC90 on March 18th, two sources tell the publication that the software was tuned in such a way that it \u201cdecided\u201d it didn\u2019t need to take evasive action, and possibly flagged the detection as a \u201cfalse positive.\u201d  The reason a system would do this, according to the report, is because there are a number of situations where the computers that power an autonomous car might see something it thinks is a human or some other obstacle. Uber reportedly set that threshold so low, though, that the system saw a person crossing the road with a bicycle and determined that immediate evasive action wasn\u2019t necessary. While Uber had an operator, or \u201csafety driver,\u201d in the car who was supposed to be able to take control in a failure like this, the employee was seen glancing down in the moments before the crash in footage released by the Tempe Police Department.   All of Uber\u2019s self-driving testing efforts have been suspended since the accident, and the company is still working with the National Transportation Safety Board, which has yet to issue a preliminary report on the progress that\u2019s been made in its investigation. When reached for comment, a spokesperson for Uber issued the same statement to The Verge that is found in The Information\u2019s story:  We\u2019re actively cooperating with the NTSB in their investigation. Out of respect for that process and the trust we\u2019ve built with NTSB, we can\u2019t comment on the specifics of the incident. In the meantime, we have initiated a top-to-bottom safety review of our self-driving vehicles program, and we have brought on former NTSB Chair Christopher Hart to advise us on our overall safety culture. Our review is looking at everything from the safety of our system to our training processes for vehicle operators, and we hope to have more to say soon. In the wake of the crash, signs have emerged that Uber\u2019s self-driving program was potentially fraught with risk. For one thing, Uber had reduced the number of \u201csafety drivers\u201d in its test cars from two to one, according to a New York Times report. This explained why the driver who was in the car that killed Herzberg was alone.  Then in late March, Reuters discovered that Uber had reduced the number of LIDAR sensors on its test cars. (LIDAR is considered by most to be critical hardware for autonomous driving.) All this was happening in an environment with little oversight from the government in Arizona. Emails obtained by The Guardian in the weeks after the crash detailed a cozy relationship between Uber and Arizona Governor Doug Ducey that may have allowed the company\u2019s test cars to hit the road even earlier than previously thought.   Many of Uber\u2019s competitors, and even some of its partners, have spoken out since the accident as the company tried to find an answer for what went wrong. Nvidia, which supplies the GPUs that help power Uber\u2019s autonomous tech, distanced itself in late March and said the fault must have been with Uber\u2019s software. Velodyne, which makes the LIDAR sensor that Uber uses, says its tech shouldn\u2019t have been affected by the nighttime conditions. Intel\u2019s Mobileye division published a breakdown of how and why its tech would have recognized Herzberg, though now that doesn\u2019t seem to have been the problem according to The Information\u2019s report.  Despite Herzberg\u2019s death, Uber CEO Dara Khosrowshahi \u2014 who The New York Times recently reported had considered ending the self-driving program when he came on board last August \u2014 said in an April interview with the Today show that the company is \u201cabsolutely committed to self-driving cars.\u201d     Command Line delivers daily updates from the near-future.","time":1525723762,"title":"Uber Thinks Its Self-Driving Car Killed Because It \u2018Decided\u2019 Not to Swerve","type":"story","url":"https:\/\/www.theverge.com\/2018\/5\/7\/17327682\/uber-self-driving-car-decision-kill-swerve"},{"by":"jonbaer","descendants":1,"id":17015910,"kids":"[17018520]","score":7,"text":"\u2018We\u2019ve fallen off a cliff: very little sea ice remains in the Bering Sea\u2019 Almost all the ice covering the\u00a0Bering Sea\u00a0has melted, scientists have confirmed, throwing communities living around its shores into disarray. The region\u2019s ice cover normally persists for at least another month, and this year it has vanished earlier than any other year except 2017. Located in the northern Pacific Ocean between Alaska and Russia, the Bering Sea is experiencing the brunt of climate change and has already drawn attention this year for unprecedented levels of winter melting. In February, soaring Arctic temperatures led to around half the region\u2019s ice disappearing in the space of two weeks. This trend has continued into spring, and scientists have confirmed that by the end of April just 10 per cent of normal ice levels remained. \u201cWe\u2019ve fallen off a cliff: very little sea ice remains in the Bering Sea,\u201d tweeted Dr Rick Thoman, a climatologist at the National Oceanic and Atmospheric Administration,\u00a0who is based in Alaska. A report released by the International Arctic Research Centre at the University of Alaska Fairbanks\u00a0has outlined the real-world effects of these stunning environmental changes on the many communities that inhabit the Bering Sea region. \u201cThe low sea ice is already impacting the lives and livelihoods of people in western Alaska coastal communities by restricting hunting and fishing, which are the mainstays of the economies of these communities,\u201d Dr Thoman told The Washington Post. We\u2019ve fallen off a cliff: very little sea ice remains in the Bering Sea. From @NSIDC data, ice extent fell below 10% of the 1981-2010 average max extent on April 23, four weeks earlier than any other spring except last year. #akwx #Arctic @Climatologist49 @ZLabe @lisashefguy pic.twitter.com\/ShQYDZL5Jf \u201cTravel between communities via boat or snowmachine was difficult and limited due to thin, unstable sea ice,\u201d the report said. \u201cAt times there was not enough ice to harvest marine mammals, fish\u00a0or crabs. As a result of increased open water, storm surf flooded homes and pushed ice rubble onto shore. The lack of sea ice in recent months has exposed these communities to the elements, as it normally acts as a buttress against extreme weather events. A large late February storm devastated Little Diomede Island, leading to a loss of power for inhabitants as ice rubble covered the local helipad and damaged the water treatment plant. A group of emperor penguins face a crack in the sea ice, near McMurdo Station, Antarctica Kira Morris Amid a flood in Islampur, Jamalpur, Bangladesh, a woman on a raft searches for somewhere dry to take shelter. Bangladesh is one of the most vulnerable places in the world to sea level rise, which is expected to make tens of millions of people homeless by 2050. Probal Rashid Hanna Petursdottir examines a cave inside the Svinafellsjokull glacier in Iceland, which she said had been growing rapidly. Since 2000, the size of glaciers on Iceland has reduced by 12 per cent. Tom Schifanella Floods destroyed eight bridges and ruined crops such as wheat, maize and peas in the Karimabad valley in northern Pakistan, a mountainous region with many glaciers. In many parts of the world, glaciers have been in retreat, creating dangerously large lakes that can cause devastating flooding when the banks break. Climate change can also increase rainfall in some areas, while bringing drought to others. Hira Ali   Smoke \u2013 filled with the carbon that is driving climate change \u2013 drifts across a field in Colombia. Sandra Rondon A river once flowed along the depression in the dry earth of this part of Bangladesh, but it has disappeared amid rising temperatures.  Abrar Hossain Sindh province in Pakistan has experienced a grim mix of two consequences of climate change.\r\n\u201cBecause of climate change either we have floods or not enough water to irrigate our crop and feed our animals,\u201d says the photographer. \u201cPicture clearly indicates that the extreme drought makes wide cracks in clay. Crops are very difficult to grow.\u201d Rizwan Dharejo  A shepherd moves his herd as he looks for green pasture near the village of Sirohi in Rajasthan, northern India.\r\nThe region has been badly affected by heatwaves and drought, making local people nervous about further predicted increases in temperature. Riddhima Singh Bhati  A factory in China is shrouded by a haze of air pollution. The World Health Organisation has warned such pollution, much of which is from the fossil fuels that cause climate change, is a \u201cpublic health emergency\u201d. Leung Ka Wa  Water levels in reservoirs, like this one in Gers, France, have been getting perilously low in areas across the world affected by drought, forcing authorities to introduce water restrictions. Mahtuf Ikhsan Following an ice-free February in the town of Savoonga \u2013 located on St Lawrence Island in the Bering Sea \u2013 ice returned at the beginning of May. However, local resident Aqef Waghiyi reported that \u201cit is all broken up ... no flat pieces and it is real rough\u201d.\u00a0 \u201cThere are patches of open water ... biggest open patch in front of town is maybe as big as a football field.\u201d This lack of stability had an impact on animals as well. West of Savoonga in the town of Gambell, the lack of sea ice led to a lack of walrus traditionally found in the area. The drivers behind the premature melting of the Bering Sea\u2019s ice include both long-term global warming and an unfortunate confluence of weather events. According to Dr Brian Brettschneider, a climate scientist with the International Arctic Research Centre, \u201cthe warmed state of the Arctic has primed the region for low ice values\u201d.\u00a0 Readings taken across the region have confirmed that both ocean and air temperatures were well above normal in the months leading up to and during the melting events of this year. These high temperatures have been exacerbated by air currents over the Arctic guiding storms into the region and drawing warmer air from the tropics. The storms prevented ice from forming properly by breaking it up before it became stable. The amount of sea ice in the Bering Sea was lower this winter than any year since whaling vessels began keeping written records in 1850. In their\u00a0report, the International Arctic Research Centre scientists wrote that while not every year will be as bad as this one, ice formation is likely to remain low if the Bering Sea\u2019s waters remain warm.\u00a0 They also warn that communities will need to \u201cprepare for more winters with low sea ice and stormy conditions\u201d. \u201cFellow Americans are suffering from a natural disaster,\u201d said Dr Thoman.\u00a0\u201cWhile low sea ice is not as dramatic as a wildfire or an Interstate 95 snowstorm, the impacts and hardships it produces are just as real.\u201d We use cookies to enhance your visit to our site and to bring you advertisements that might interest you. Read our Privacy and Cookie Policies to find out more. We've noticed that you are using an ad blocker. Advertising helps fund our journalism and keep it truly independent. It helps to build our international editorial team, from war correspondents to investigative reporters, commentators to critics. Click here to view instructions on how to disable your ad blocker, and help us to keep providing you with free-thinking journalism - for free. Thank you for your support. How to disable your ad blocker for independent.co.uk Thank you for supporting independent.co.uk","time":1525722640,"title":"Almost all the ice covering the Bering Sea has melted","type":"story","url":"https:\/\/www.independent.co.uk\/environment\/bering-sea-ice-melt-global-warming-climate-change-alaska-a8338656.html"},{"by":"stouset","descendants":4,"id":17015899,"kids":"[17015900, 17016473]","score":29,"text":"GitHub is home to over 20 million developers working together to host and review code, manage projects, and build software together. \nSign up\n \n              Use Git or checkout with SVN using the web URL.\n             If nothing happens, download GitHub Desktop and try again. Go back If nothing happens, download GitHub Desktop and try again. Go back If nothing happens, download Xcode and try again. Go back If nothing happens, download the GitHub extension for Visual Studio and try again. Go back  sudo_pair is a plugin for sudo that requires another\nhuman to approve and monitor privileged sudo sessions. \n\n sudo is used by engineers daily to run commands as privileged users.\nBut on some sensitive systems, you really want to ensure that no\nindividual can act entirely autonomously. At Square, this includes\napplications that manage our internal access-control systems, store\naccounting ledgers, or even move around real money. This plugin allows\nus to ensure that no user can act entirely on their own authority within\nthese systems. This plugin and its components are still in prerelease, as we want to\nget feedback from the open-source community before officially releasing\n1.0. For now, sudo_pair must be compiled from source. It is a standard\nRust project, and the following should suffice to build it on any recent\nversion of Rust: Once built, the plugin itself will need to be installed in a place where\nsudo can find it. Generally this is under \/usr\/libexec\/sudo (on\nmacOS hosts it's \/usr\/local\/libexec\/sudo). An appropriate approval\nscript must be installed into the PATH. A directory must be created\nfor sudo_pair to manage the sockets it uses for communication between\nplugin and client. And finally, sudo must be configured to load and\nuse the plugin. The plugin can be provided several options to modify its behavior. These\noptions are provided to the plugin by adding them to the end of the\nPlugin line in \/etc\/sudo.conf. Example: The full list of options are as follows: binary_path (default: \/usr\/bin\/sudo_approve) This is the location of the approval binary. The approval command itself needs to run under the privileges of the destination user or group, and this is done so using sudo, so it must be exempted from requiring its own pair approval. user_prompt_path (default: \/etc\/sudo_pair.prompt.user) This is the location of the prompt template to display to the user invoking sudo; if no template is found at this location, an extremely minimal default will be printed. See the Prompts section for more details. pair_prompt_path (default: \/etc\/sudo_pair.prompt.pair) This is the location of the prompt template to display to the user being asked to approve the sudo session; if no template is found at this location, an extremely minimal default will be printed. See the Prompts section for more details. socket_dir (default: \/var\/run\/sudo_pair) This is the path where this plugin will store sockets for sessions that are pending approval. This directory must be owned by root and only writable by root, or the plugin will abort. gids_enforced (default: 0) This is a comma-separated list of gids that sudo_pair will gate access to. If a user is sudoing to a user that is a member of one of these groups, they will be required to have a pair approve their session. gids_exempted (default: none) This is a comma-separated list of gids whose users will be exempted from the requirements of sudo_pair. Note that this is not the opposite of the gids_enforced flag. Whereas gids_enforced gates access to groups, gids_exempted exempts users sudoing from groups. For instance, this setting can be used to ensure that oncall sysadmins can respond to outages without needing to find a pair. Note that root is always exempt. This plugin allows you to configure the prompts that are displayed to\nboth users being asked to find a pair and users being asked to approve\nanother user's sudo session. If prompts aren't\nconfigured (or can't be found on the filesystem),\nextremely minimal ones are provided as a default. The contents of the prompt files are raw bytes that should be printed to\nthe user's terminal. This allows fun things like terminal processing of\nANSI escape codes for coloration, resizing terminals, and setting window\ntitles, all of which are (ab)used in the sample prompts provided. These prompts also implement a simple %-escaped\ntemplating language. Any known directive preceded by a % character is\nreplaced by an expansion, and anything else is treated as a literal\n(e.g., %% is a literal %, and %a is a literal a). Available expansions: The provided approval script is just a small\n(but complete) example. As much functionality as possible has been moved\ninto the plugin, with one (important, temporary) exception: currently,\nthe script must verify that the user approving a sudo session is not\nthe user who is requesting the session. Other than that, the only thing required of the \"protocol\" is to: As it turns out, you can pretty much just do this with socat: The script incldued with this project isn't much more than this. It\nperforms a few extra niceties (implicitly sudos if necessary, turns\noff terminal echo, disables Ctrl-C, and kills the session on Ctrl-D),\nbut not much more. Ctrl-C was disabled so a user who's forgotten that\nthis is terminal is being used to monitor another user's session doesn't\ninstinctively kill it with Ctrl-C. Sessions under sudo_pair can't be used in the middle of a pipe. I'll\nconsider lifting these restrictions, but doing so is inherently\nproblematic. Allowing piped data to standard input, as far as I can tell, likel\nresults in a complete bypass of the security model here. Commands can\noften accept input on stdin, and there's no reasonable way to show\nthis information to the pair. On the other hand, if sudo output is piped to stdout, we could\nsimply log it like we log TTY output. This works, except we print the\nprompt itself on stdout. We could print the prompt to stderr\ninstead. In retrospect, maybe we should do this. Redirecting to stderr\nwould still be problematic, but at least we get some ability to insert\nsudo commands at the front of pipes. I'll consider this. This plugin allows users to sudo -u ${user} to become a user or\nsudo -g ${group} to gain an additional group. When a user does this, a socket is created that is owned and only\nwritable by ${user} (or ${group}). In order to connect to that\nsocket, the approver must be able to write to files as that ${user}\n(or ${group}). In other words, they need to be on the other side of\nthe airtight hatchway. In practical terms, this\nmeans the approver needs to also be able to sudo to that user or\ngroup. To facilitate this, the plugin exempts the approval script from the\nrequirement to have a pair. And the sample approval script automatically\ndetects the user or group you need to become and runs sudo -u ${user}\n(or sudo -g ${group}) implicitly. As a concrete example, these are the sockets opened for sudo -u root,\nsudo -u nobody, and sudo -g sys: The only people who can approve a sudo session to a user or group must\nalso be able to sudo as that user or group. Due to limitations of the POSIX filesystem permission model, a user may\nsudo to a new user (and gain its groups) or sudo to a new group\n(preserving their current user), but not both simultaneously. This project is composed of three Rust crates: Given the security-sensitive nature of this project, it is an explicit\ngoal to have a minimal set of dependencies. Currently, those are: Contributions are welcome! This project should hopefully be small\n(~500loc for the plugin itself, ~1kloc for the wrappers around writing\nplugins) and well-documented enough for others to participate without\ndifficulty. Pick a TODO and get started! Please report non-security issues on the GitHub tracker. Security issues\nare covered by Square's bug bounty program. sudo_pair is  distributed under the terms of the Apache License\n(Version 2.0). See LICENSE-APACHE for details.","time":1525722577,"title":"Show HN: sudo_pair \u2013 dual control for sudo","type":"story","url":"https:\/\/github.com\/square\/sudo_pair"},{"by":"mihaitodor","descendants":0,"id":17015896,"kids":"None","score":19,"text":"Principal Systems Engineer at Nitro. Co-Author of \"Docker: Up and Running\" from O'Reilly Media. Dublin, Ireland.  Twitter  Google+  Github  We needed a specialized load balancer at Nitro. After\nsome study, Mihai Todor and I built a\nsolution that leverages Nginx, the Redis protocol, and a Go-based request\nrouter where Nginx does all the heavy lifting and the router carries no traffic\nitself. This solution has worked great in production for the last year. Here\u2019s\nwhat we did and why we did it. The new service we were building would be behind a pool of load balancers and\nwas going to do some expensive calculations\u2014and therefore do some local\ncaching.  To optimize for the cache, we wanted to try to send requests for the\nsame resources to the same host if it were available. There are a number of off-the-shelf ways to solve this problem. A\nnon-exhaustive list of possibilities includes: Go Gopher by Renee French. This service will be hit several times per page load and so HTTP redirects are\nnot viable for performance reasons. The rest of those solutions all work well\nif all the inbound requests are passing through the same load balancer. If, on\nthe other hand, your frontend is a pool of load balancers, you need to be able\nto either share state between them or implement more sophisticated routing\nlogic. We weren\u2019t interested in the design changes needed to share state\nbetween load balancers at the moment and so opted for more sophisticated\nrouting logic for this service. It probably helps to understand our motiviation a little better to understand a\nbit about our architecture. We have a pool of frontend load balancers and instances of the service are\ndeployed on Mesos so they may come and go depending on scale and resource\navailability. Getting a list of hosts and ports into the load balancer is not\nan issue, that\u2019s already core to our platform. Because everything is running on Mesos, and we have a simple way to define and\ndeploy services, adding any new service is a\ntrivial task. On top of Mesos, we run gossip-based\nSidecar everywhere to manage service\ndiscovery. Our frontend load balancers are Lyft\u2019s\nEnvoy backed by Sidecar\u2019s Envoy integration. For most\nservices that is enough. The Envoy hosts run on dedicated instances but the\nservices all move between hosts as needed, directed by Mesos and the\nSingularity scheduler. The Mesos nodes for the service under consideration here would have disks for local\ncaching. Looking at the problem we decided we really wanted a consistent hash ring. We\ncould have nodes come and go as needed and only the requests being served by\nthose nodes would be re-routed. All the remaining nodes would continue to serve\nany open sessions. We could easily back the consistent hash ring with data from\nSidecar (you could substitute Mesos or K8s here). Sidecar health checks nodes\nand so we could rely on nodes being available if they are alive in Sidecar. We needed to then somehow bolt the consistent hash to something that could\ndirect traffic to the right node. It would need to receive each request,\nidentify the resource in question, and then pass the request to the exact\ninstance of the service that was prepped to handle that resource. Of course, the resource identification is easily handled by a URL and any load\nbalancer can take those apart to handle simple routing. So we just needed to tie\nthat to the consistent hash and we\u2019d have a solution. You could do this in Lua in Nginx, possibly in HAproxy with Lua as well. No one\nat Nitro is a Lua expert and libraries to implement the pieces we needed were\nnot obviously available. Ideally the routing logic would be in Go, which is\nalready a critical language in our stack and well supported. Nginx has a rich ecosystem, though, and a little thinking outside the box\nturned up a couple of interesting Nginx plugins, however. The first of these is\nthe nginx-eval-module by\nValery Kholodkov. This allows you to make a call from Nginx to an endpoint and\nthen evaluate the result into an Nginx variable. Among other possible uses, the\nsignificance of that for us is that it allows you to dynamically decide which\nendpoint should receive a proxy-pass. That\u2019s what we wanted to do. You make a\ncall from Nginx to somewhere, you get a result, and then your make a routing\ndecision based on that value. You could implement the recipient of that request with an HTTP service that\nreturns only a string with the hostname and port of the destination service\nendpoint. That service would maintain the consistent hash and then tell Nginx\nwhere to route the traffic for each request. But making a separate HTTP\nrequest, even if were always contained on the same node, is a bit heavy. The\nwhole expected body of the reply would be something like the string\n10.10.10.5:23453. With HTTP, we\u2019d be passing headers in both directions that\nwould vastly exceed the size of the response. So I started to look at other protocols supported by Nginx. Memcache protocol\nand Redis protocol are both supported. Of those, the best supported from a Go\nservice is Redis. So that was where we turned. There are two Redis modules for Nginx. One of them is suitable for use with the\nnginx-eval-module. The best Go library for Redis is\nRedeo. It implements a really simple handler\nmechanism much like the stdlib http package. Any Redis procotol command will\ninvoke a handler function, and they are really simple to write. Alas, it only\nsupports a newer Redis protocol than the Nginx plugin can handle. So, I dusted\noff my C skills and patched the Nginx\nplugin to use the newest Redis\nprotocol encoding. So the solution we ended up with is: The call comes in from the Internet, hits an Envoy node, then an Nginx node.\nThe Nginx node (1) asks the router where to send it, and then (2) Nginx passes\nthe request to the endpoint. We built a library in Go to manage our consistent hash backed by Sidecar or by Hashicorp\u2019s Memberlist library. We called that library Ringman. We then bolted that libary into a service which serves Redis protocol requests via Redeo. Only two Redis commands are required: GET and SELECT. We chose to implement a few more commands for debugging purposes, including INFO which can reply with any server state you\u2019d like. Of the two required commands, we can safely ignore SELECT, which is for selecting the Redis DB to use for any subsequent calls. We just accept it and do nothing.GET, which does all the work, was easy to implement. Here\u2019s the entire function to serve the Ringman endpoint over Redis with Redeo. Nginx passes the URL it received, and we return the endpoint from the hash ring. That is called by Nginx using the following config: We deploy Nginx and the router in containers and they run on the same hosts\nso we have a very low call overhead between them. We build Nginx like this: We\u2019ve tested the performance of this extensively and in our environment we see\nabout 0.2-0.3ms response times on average for a round trip from Nginx to the Go\nrouter over Redis protocol. Since the median response time from the upstream\nservice is about 70ms, this is a negligeable delay. A more complex Nginx config might be able to do more sophisticated error handling.\nReliability after a year in service is extremly good and performance has been\nconstant. If you have a similar need, you can re-use most of the components. Just follow\nthe links above to actual source code. If you are interested in adding support\nfor K8s or Mesos directly to Ringman, that would be welcome. This solution started out sounding a bit like a hack and in the end has been a\ngreat addition to our infrastructure. Hopefully it helps someone else solve a\nsimilar problem. Principal Systems Engineer at Nitro. Co-Author of \"Docker: Up and Running\" from O'Reilly Media. Dublin, Ireland.  Twitter  Google+  Github Dynamic Nginx Router... in Go! was published on May 07, 2018 by Karl Matthias.","time":1525722562,"title":"Dynamic Nginx Router in Go","type":"story","url":"http:\/\/relistan.com\/dynamic-nginx-router-in-go\/"},{"by":"lainon","descendants":0,"id":17015870,"kids":"None","score":15,"text":"Access every Packt eBook and Video ever published! Opsie devsy. Make no mistake, this software engineering bundle is packed with information! Streamline your processes with ebooks like Automate it!, DevOps for Networking, Mastering Ansible, and Continuous Delivery with Docker and Jenkins. You can also get a library of videos including Mastering DevOps, Mastering Windows PowerShell 5 Administration, and Learning Kubernetes. Pay what you want. All together, these ebooks would cost over $1613. Here at Humble Bundle, you choose the price and increase your contribution to upgrade your bundle! This bundle has a minimum $1 purchase. Read them anywhere. The books in this bundle are available in PDF, ePUB, and MOBI formats, meaning you can read them anywhere at any time. Instructions and a list of recommended reading programs can be found here. The videos in this bundle come in HD MP4 format. Support charity. Choose where the money goes \u2013 between the publisher and the Innocent Lives Foundation via the PayPal Giving Fund. If you like what we do, you can leave us a Humble Tip too! The Humble community has contributed over $126 million to charity since 2010, making an amazing difference to causes all over the world.","time":1525722438,"title":"Humble Book Bundle: DevOps by Packt","type":"story","url":"https:\/\/www.humblebundle.com\/books\/devops-books"},{"by":"clumsysmurf","descendants":14,"id":17015837,"kids":"[17015861]","score":7,"text":"The Future Google\u2019s got our kids Joanna Petrone The video game Interland is part of Google's \u201cBe Internet Awesome\u201d curriculum aimed a \u201chelping kids be safe, confident explorers of the online world.\u201d It\u2019s set in a dreamy, blandly futuristic landscape rendered in the four hues of the Google logo. Numbing music cycles endlessly, like a shopping mall visit on a large dose of Klonopin. A cute avatar called an Internaut \u2014 an Android logo, thinly disguised \u2014 advances when the player correctly answers questions about oversharing, cyberbullying, and phishing scams. The game\u2019s release was met with positive reviews that completely miss the point. Interland may be fun and appealing, and may even serve a pedagogical purpose when it comes to drilling kids to recognize scammy or inappropriate online behavior. But even though there\u2019s nothing to buy, Interland is an ad. It doesn\u2019t hawk junk food or sneakers; rather Interland sells to kids the message that Google is a trustworthy arbiter of online safety and privacy. And Interland is only one of many ways this message has become increasingly embedded in K-12 school classrooms. According to a representative for the company, 25 million students worldwide use Chromebooks at school, which are generally more affordable alternatives to fully-fledged PCs or Macs. More than 80 million people use G Suite for Education, with 30 million teachers and students using Google Classroom, a management app that allows teachers to push out assignments and materials and collect student work. Companies selling products for schools to place in student hands is neither new nor, in itself, cause for concern. There is, however, an important difference between companies in the mold of, say, Houghton-Mifflin as opposed to one like Google. The former, presumably, is not trying to nurture cradle-to-grave consumers of social studies textbooks. The latter has a very strong interest not only in training the workforce of the future in G Suite, but also in forming positive and powerful brand associations in the minds of its littlest consumers. To get a sense of what all this brand exposure looks like, just spend an hour in my middle school classroom. On a typical day, students start class with a warm-up activity posted on Google Classroom. After we go over their answers and I teach a lesson, I might direct my students to open Google Docs and start writing. \u201cRemember to check Google Calendar and start studying for your next quiz! Oh, and don\u2019t forget to turn in your writing on Google Classroom before Thursday!\u201d I holler into the void as they pack up their bags. I\u2019ve learned from experience that I need to specify \u201cGoogle Classroom\u201d every time I give this direction; if I don\u2019t, if I just say \"Classroom,\" some students will submit their work on Classroom, some will stick it in their lowercase-c classroom notebooks, and at least one person will wander around the actual classroom while I am in the middle of an explanation, assignment in hand, wondering aloud where he was supposed to turn it in. \nThe Google Classroom app makes teachers\u2019 and administrations\u2019 lives very easy, but give Google a lot of access to kids who then can\u2019t learn not to trust it.            \n                dennizn \/ Shutterstock Kids learn both explicit and implicit lessons at school. A school can hang a banner to celebrate diversity, for instance, but if students encounter few people of color on the syllabus and in positions of authority in the school, they are likely to learn diversity doesn\u2019t really matter even with its importance spelled out in foot-high letters. Beyond datamining, some parents and privacy advocates have expressed concern that even when kids are explicitly taught how to safeguard their personal information online, school-mandated Chromebooks and Google accounts implicitly train kids to accept surveillance and hand over personal information. At the very least, how Google\u2019s presence and presentation in schools is shaping children\u2019s attitudes towards the company is a topic that deserves more scrutiny than it has received \u00a0in an educational moment that prizes all things STEM and tends to herald technology in the classroom as an unalloyed good. From one vantage point, classrooms like mine look like education technology success stories, with students\u2019 academic learning seamlessly interwoven with the workflow habits and productivity apps of all tomorrow\u2019s office workers. Using Google products, students can work collaboratively on files, use the internet for research, and acquire competency with the basics of personal computing. Districts often save substantial amounts of money by using Google\u2019s services in place of their own email servers and can provide more classroom access to computers using Chromebooks than they could using pricier alternatives. In a country where public education is cruelly underfunded, there\u2019s no mystery as to why teachers and districts are drawn to Google's cheap, often free, education technology and curriculum, but there needs to be an honest reckoning of its real price tag and robust public discussion about whether that is a cost worth paying. As the recent scrutiny of Facebook and Cambridge Analytica reminds us, placing tremendous faith in and few restrictions on powerful technology companies can have consequences that are difficult for users to grapple with until after serious damage is done. This is especially true of companies like Facebook and Google that possess tremendous amounts of our personal data and shape what information we see, all while deriving profit from ads. Google does not serve ads to K-12 student users on core G Suite for Education services, though it does collect and retain their data. If students eventually transfer the contents of their school Drive account to a personal Drive account, as they are often prompted to do before they graduate so they don\u2019t lose all record of their work, the information they created in school as a minor is no longer treated with special protections. Product placement on film, TV, and social media works because it capitalizes on our pre-existing affections and associations. Picture the elementary school classroom you loved best as a child: bulletin boards covered in primary-colored construction paper; displays labeled with the same die-cut, sans-serif paper letters used by every teacher in America. Did it sort of resemble, in a general way, the look of Google\u2019s logo? That logo, the childlike Google Doodles, the bulletin-board like interface of Classroom all share a peppy kindergarten aesthetic that blurs the distinction between the school and the company in a way that is perhaps visually pleasing but also imparts unearned to Google the positive associations that we hope children have for teachers and their school: feelings of safety, trustworthiness, care, and authority. The irony of a curriculum that teaches kids how to safeguard their privacy online yet is produced by a company known for its less-than-transparent use of personal data is a little on the nose, but the explicit lessons in Be Internet Awesome are too basic to be objectionable. The fundamentals of awesomeness, according to the program, include accounting for personal risk and propriety when posting online (\u201cShare with Care\u201d), recognizing scams (\u201cDon\u2019t Fall for Fake\u201d), setting strong passwords (\u201cSecure Your Secrets\u201d), opposing online bullying (\u201cIt\u2019s Cool to Be Kind,\u201d whose Nick Lowe reference is wasted on the young), and recognizing when to go to a trusted adult (\u201cWhen in Doubt, Talk it Out\u201d). Pragmatic as the content is, it also transmits implicit lessons about the Google brand, whose brand colors, icons, and font are slathered over everything from student handouts to classroom posters to, for some reason, paper doll patterns for making your very own Internaut. Be Internet Awesome implicitly signals to students that Google is synonymous with privacy and safety. By focusing solely on personal choices, the program suggests that the power to protect personal information lies entirely within one\u2019s own hands and locates responsibility for doing so with the individual. There\u2019s nothing wrong with telling students not to send money to someone claiming to be a Nigerian prince but for most people, most of the time, there is greater danger in all the usual and perfectly legal ways of persuading us to part with our money, just as the greater threat to our privacy, as anyone compromised in the Experian hack can tell you, comes not from, or not only from, crappy passwords but from numerous \u00a0ways we are tracked without our permission or knowledge. If a goal, ultimately, is not just to prevent kids from downloading viruses onto school devices but to teach them how to protect themselves from larger corporate interests that may use them for their data, classroom materials that subtly advance a particular narrative about the company that made them undermine that end. Interland is especially egregious, meeting the criteria for what Common Sense Media, in its 2014 research paper, terms an \u2018advergame,\u2019 an online game that \u201cinvolves a user playing with branded items. . . or playing in a heavily branded environment.\u201d Advergames are psychologically powerful because they \u201cinvolve the child for a longer period of time than TV ads do, and the experience of playing the game is more immersive and may promote identification with the product.\u201d \u00a0Additionally, \u201cby their very nature, advergames blur the boundaries between entertainment and advertising content. . . [and] the mental state of flow some gamers get into while playing also may contribute to a blurring of boundaries.\u201d Many school children, especially early elementary-school aged ones, are yet to reach the stage of development where they are able to recognize the motivations of other people, let alone understand why an abstract corporate entity might have an interest in portraying itself in a particular way. Young kids can\u2019t recognize ads as such; even adolescents are not attuned to rhetoric and manipulation in the same way as adults and need instruction in this area. This, of course, as any parent who has ever raced a cart down the cereal aisle knows, is what makes kids such a credible, vulnerable, and lucrative audience. As the saying goes, if you are not paying for the service you\u2019re using, the product is you \u2014 your personal information, your attention, or, in this case, your children\u2019s. None of this is to say that Google\u2019s classroom technology is not a useful tool. It can provide new avenues for educators and students to research, collaborate, and make real-world connections. Even the Be Internet Awesome curriculum speaks to a real need schools have to prepare students for life in a digital world though they lack resources, including teacher expertise, to do so. The issue isn\u2019t that Google has nothing of value to offer schools \u2014 clearly, it has \u2014 but rather at what price are we buying it. If it\u2019s too steep we might want to recall lessons from our own educations, not about how to be savvy, polished consumers of technology, but about how to be citizens. The Future","time":1525722235,"title":"Google\u2019s got our kids","type":"story","url":"https:\/\/theoutline.com\/post\/4436\/google-classroom-education-free-software-children-school-tech"},{"by":"amasad","descendants":17,"id":17015055,"kids":"[17016264, 17015147, 17016123, 17017235, 17016364]","score":135,"text":"%PDF-1.4\r%\u00e2\u00e3\u00cf\u00d3\r\n72 0 obj\r<>\rendobj\r               \r\nxref\r\n72 32\r\n0000000016 00000 n\r\n0000001460 00000 n\r\n0000001541 00000 n\r\n0000001721 00000 n\r\n0000001865 00000 n\r\n0000001995 00000 n\r\n0000002130 00000 n\r\n0000002534 00000 n\r\n0000003085 00000 n\r\n0000003383 00000 n\r\n0000003668 00000 n\r\n0000003923 00000 n\r\n0000004172 00000 n\r\n0000004249 00000 n\r\n0000005146 00000 n\r\n0000005850 00000 n\r\n0000006543 00000 n\r\n0000006579 00000 n\r\n0000007247 00000 n\r\n0000008129 00000 n\r\n0000009012 00000 n\r\n0000009814 00000 n\r\n0000010631 00000 n\r\n0000019445 00000 n\r\n0000019692 00000 n\r\n0000019903 00000 n\r\n0000027498 00000 n\r\n0000027751 00000 n\r\n0000027959 00000 n\r\n0000041473 00000 n\r\n0000065106 00000 n\r\n0000000936 00000 n\r\ntrailer\r\n<<5ACC1424ED879C4CB8BA178487FF85DE>]>>\r\nstartxref\r\n0\r\n%%EOF\r\n           \r\n103 0 obj\r<","time":1525717213,"title":"Using Prediction Markets to Track Information Flows:  Evidence from Google [pdf]","type":"story","url":"https:\/\/www.stat.berkeley.edu\/users\/aldous\/157\/Papers\/GooglePredictionMarketPaper.pdf"},{"by":"mathisonian","descendants":116,"id":17015043,"kids":"[17015848, 17015248, 17015869, 17015505, 17015370, 17016460, 17016506, 17016395, 17016876, 17016415, 17015530, 17015814, 17015882, 17016313, 17020398, 17016631, 17016235, 17020805, 17015419, 17017606, 17015740, 17019485, 17021466, 17018391, 17016695, 17015487, 17015702, 17019076, 17017056, 17019067, 17018514, 17015574, 17015524, 17016382, 17017144, 17015286, 17016641]","score":326,"text":"Take a second and strum the guitar. It doesn\u2019t sound\nso good, does it? We\u2019ve just taken it out of storage and it\u2019s all out of tune...\n Tune the guitar using the tuner. Click and drag the tuning\nknobs on the right to tighten and loosen the strings. \nThis doesn\u2019t sound in tune quite yet. Scroll back up and try to get all of the tuning knobs to turn green. Guitars generate noise through the vibration of their strings. On an electric guitar such as this one,\nmagnetic \u201cpick-ups\u201d convert those vibrations into an electrical signal which can then be sent to a tuner or an amplifier. This signal can be visualized as a raw waveform, but\noften we want to visualize the frequency instead. The fourier transform is a mathematical function\nthat reveals the audio frequencies hidden in that wave. Strum the guitar to see the frequency\nvisualized. Now that we\u2019ve tuned the guitar using a tuner, let\u2019s try to tune the guitar by ear.\nThis is more challenging, and it may take you time to master. We\u2019ll start by tuning to a reference note. When you manipulate the tuners on the\nright the current note will be played, as will a reference note. This will be easier with a cleaner sound. Match the two\nsounds to get the guitar in tune. Most of the strings on a guitar are separated by an interval known as a perfect fourth. The perfect fourth is beautifully resonant, but there\u2019s one pair of strings on a guitar which are not separated by a perfect fourth. The interval between the  GGG  and  BBB  strings is a major third. The major third sounds happy and uplifting.  Learning to hear these intervals will help you tune your guitar without a tuner.  \nWhen two strings are played together, they produce a third higher frequency known as an overtone. When the two strings are not perfectly in tune, the overtone is inconsistent over time. This produces a wobbling, a beat, in the overtone which you can hear if you listen carefully. Play notes with a 5.00 Hz difference: As you get a pair of strings closer in tune, the beats will slow down until the overtone is perfecly amplified.\nListening for the slowing of these beats is a helpful cue for tuning. Try tuning the guitar by listening for the relationships between adjacent strings and the beats in the resultant overtone. This page was built using Idyll, a\nmarkup language for interactive documents. The guitar was\ncreated using Sketch Interactive Export,\n D3, and a modified version of Tone.js. Audio samples were\n provided by freesound.org user SpeedY. This project\nis from the Interactive Data Lab at the University of Washington.","time":1525717136,"title":"Show HN: How to Tune a Guitar","type":"story","url":"https:\/\/mathisonian.github.io\/idyll\/how-to-tune-a-guitar\/"},{"by":"monsieurpng","descendants":7,"id":17014885,"kids":"[17015185, 17016104, 17014961, 17015121]","score":33,"text":"Dear friends, Drive.ai will offer a self-driving car service for public use in Frisco, Texas starting in July, 2018. Self-driving cars are no longer a futuristic AI technology. They\u2019re here, and will soon make transportation cheaper and more convenient. The team at Drive.ai has been working closely with local partners to ensure the deployment of our cars is safe and adds real value to its day-to-day users. Providing a public self-driving car service depends on three key elements: Self-driving technology is still challenging. It requires highly skilled AI teams as well as sophisticated software and hardware architectures. Drive.ai has always had a strong technical team; its founders include many AI graduate students from my group at Stanford University as well as Carol Reiley (my spouse). Comprised of deep learning natives, the team has designed a self-driving architecture using modern AI from the ground up. Further, by developing the full software stack for self-driving in-house\u200a\u2014\u200a-perception, motion planning, mapping, localization, fleet management software, mobile app, communications, our \u201ctele-choice\u201d remote assistance system, and more\u200a\u2014\u200athe team is able to move quickly and resolve any dependencies between systems. Self-driving cars should be deployed in geofenced areas in partnership with governments and private parties to ensure safe, smooth operations that add value to its day-to-day users As a skilled AI team, Drive.ai has a clear-eyed view of AI\u2019s limitations. The team knows how to build realistic solutions within the current technology\u2019s limitations. For example, no self-driving team has a realistic roadmap to reliably interpret the hand gestures of a construction worker waving for a car to proceed; computer vision just isn\u2019t good enough yet. Thus, we are partnering with governments and private parties to deploy in geofenced regions, where we can find other ways for construction workers to communicate with our fleet operations team. Drive.ai is particularly grateful to Frisco\u2019s Mayor Jeff Cheney, Frisco TMA, and NCTCOG\u2019s Michael Morris for their partnership. Working together, our initial pilot will be a six month deployment on a driving route from HALL Park to an entertainment\/retail area (The Star), with a planned expansion into Frisco Station. Deploying local on-demand shuttle routes benefits everyone. Office workers can grab lunch without having to drive and look for parking, and local business owners can attract more customers. A self-driving service will boost local commerce, reduce traffic jams, and lessen the need for parking lots. We also aim to unlock access to areas underserved by traditional mass transit and improve connectivity to existing transit lines. Thoughtful self-driving deployments can increase mass transit ridership and reduce individual car usage, thus driving down a city\u2019s transportation costs. The industry must take a human-centered approach to safety\u200a\u2014\u200ataking into account both people inside and outside the car\u200a\u2014\u200aand emphasize communications and community education. Whether a self-driving car is safe depends not only on the behavior of the car itself, but also on the behavior of the people around it. It is unwise to rely exclusively on AI technology to ensure safety. Instead, the self-driving industry also has to think about the people who will be outside the vehicle, which is why we will be undertaking community-wide education and training programs where we operate. It is every self-driving company\u2019s responsibility to ensure safety. We believe the self-driving car industry should adopt these practices: We deliberately prioritized recognizability over beauty, since it is recognizability that enhances safety. In the first phase, Drive.ai will deploy vehicles with safety drivers in Texas. We are also deploying our \u201ctele-choice\u201d technology to provide a high level of safety and ride comfort. For example, say our vehicle wants to execute a tricky maneuver at an intersection. If it determines that it needs human insight for an additional layer of safety, it will first pull to a stop, then seek input from a remote operator to proceed. Over time, our deep learning system learns from these cases and improves automatically. Unlike \u201cremote driving,\u201d where a tele-choice operator controls the car directly, our tele-choice system is designed to be robust to network latency and temporary network outages, taking into account even small edge cases like automatically invalidating stale data or requests lagging by 100 ms. In the second phase, when road tests show it is safe to do so, Drive.ai will operate with \u201cchaperones\u201d (rather than safety drivers) alongside tele-choice operators. The chaperone will sit in a passenger seat and be available to assist passengers and monitor operations, but they will not be expected to take over in a split-second. In the final phase, we will operate with only passengers in the vehicle, assisted remotely by tele-choice operators. One tele-choice operator will be able to monitor multiple vehicles, thus enabling more scalable deployments of self-driving. There is still much work to be done, but the future of self-driving is clear. Self-driving cars have different strengths and weaknesses than human drivers. They are always attentive, have <100 ms reaction times, and have no blind spots. On the flip side, they don\u2019t understand certain complex situations such as a construction worker communicating using hand gestures. By choosing geofenced regions and working with partners, we can take advantage of self-driving cars\u2019 strengths while diminishing their weaknesses. With these strategies, the self-driving industry will be able to deploy safe and valuable transportation services. I remember attending the DARPA Urban Challenge in 2007 and seeing the wonderful work of Stanford University, CMU, and many other pioneering self-driving teams. Our work builds on that rich legacy. It is now over a decade later. I am thrilled that self-driving cars are finally here. To learn more about Drive.ai\u2019s work to advance self-driving, head to drive.ai. Andrew Ng By clapping more or less, you can signal to us which stories really stand out. AI, Machine Learning, Deep learning, Online Education.","time":1525716060,"title":"Drive.ai will offer a self-driving car service for public use in Frisco, Texas","type":"story","url":"https:\/\/medium.com\/@andrewng\/self-driving-cars-are-here-aea1752b1ad0"},{"by":"bdburns","descendants":0,"id":17014825,"kids":"None","score":10,"text":"Microsoft Azure Stack is an extension of Azure\u2014bringing the agility and innovation of cloud computing to your on-premises environment and enabling the only hybrid cloud that allows you to build and deploy hybrid applications anywhere. We bring together the best of the edge and cloud to deliver Azure services anywhere in your environment.  Learn more  Posted on May 7, 2018 With Kubernetes exploding in popularity worldwide, it\u2019s no surprise that Kubernetes usage on Azure has grown more than 10x over the last year. Customers love the agility, reliability, and scalability benefits provided by container orchestrators like Kubernetes. Early reviews of our AKS, our managed Kubernetes service, demonstrate serious interest from customers of all shapes and sizes. For Build 2018, we\u2019re thrilled to announce some big improvements to the Kubernetes experience on Azure. To start, our managed Kubernetes service has been renamed to Azure Kubernetes Service (AKS). AKS is now officially part of the Kubernetes Conformance Program, designed to ensure consistency and portability of Kubernetes across different environments. We want every developer to try Kubernetes on Azure, whether they are familiar with containers or not. We have two new announcements that make AKS easier than ever: Graphical user interfaces and wizard-based application onboarding help democratize Kubernetes and container technology for enterprise software developers, and we\u2019re thrilled to provide these new, simplified experiences for Build. Since we launched the AKS preview, we\u2019ve worked closely with customers to help shape the future of Kubernetes on Azure. We are listening to your feedback and feature requests, and we are happy to share some exciting enhancements to AKS in time for Build. We have many more features planned before we announce the GA of AKS in the next few weeks. Yet while we are passionate about delivering an enterprise-grade Kubernetes service, we also realize Kubernetes and container orchestration is still too tedious for many developers. Imagine you are a new employee trying to fix a bug on a complex microservices application consisting of dozens of components, each with their own configuration and backing services. To get started, you must configure your local development environment so that it can mimic production. Setup your IDE, build tool chain, containerized service dependencies, a local Kubernetes environment, mocks for backing services, and more. With all the time involved setting up your development environment, fixing that first bug could take days. Or you could use Azure.\u00a0 With AKS and our new Dev Spaces capability, all a new developer needs is their IDE and the Azure CLI. The developer simply creates a new Dev Space inside AKS and they can begin working on any component of their microservice environment safely, without impeding production traffic flows. Thanks to innovative use of service mesh technology, a developer can work on any service in isolation by using a simple hostname prefix. Thanks to hot code swapping, developers can remote debug their application quickly, as code is intelligently synchronized from the IDE into live containers running inside AKS. Dev Spaces for AKS, now in private preview, makes developing against a complex microservices environment simple. We are thrilled to see the customers so passionate about using Kubernetes on Azure. At KubeCon last week, we showcased open source developer tooling like Helm, Draft, and Brigade which empower developers working on any Kubernetes environment. Now at \/\/Build we are showcasing enhanced versions these open source technologies \u2013 graphical interfaces, integrated monitoring, enterprise networking, and best-of-breed developer tooling \u2013 making Azure the best Kubernetes experience in the cloud. Try AKS today.  Azure roadmap   Provide feedback  Go Social Microsoft Azure Community Support Account Trust Center Hello from Seattle.","time":1525715690,"title":"Kubernetes on Azure: Industry\u2019s best end-to-end Kubernetes experience","type":"story","url":"https:\/\/azure.microsoft.com\/en-us\/blog\/kubernetes-on-azure\/"},{"by":"mbastress","descendants":6,"id":17014821,"kids":"[17018321, 17014935]","score":18,"text":"Sometimes, the early bird loses the worm \u2026 at least, when it comes to 401(k) savings. Workers with cash to spare may be tempted to front-load their 401(k) retirement account contributions, maxing out their tax-advantaged contributions before the year's end. (For 2016, the IRS limit for tax-advantaged 401(k) contributions is $18,000, and $24,000 for those 50 or older.) This may result in more of your pay making it to your checking account for the year's remaining pay periods, which could come in handy around vacation time or the holidays. But if your employer offers matching contributions, beware: maxing out your 401(k) early could mean you lose out on a portion of your employer's match. Here's how it could happen, in a nutshell: Suppose your employer's 401(k) program provides a certain percentage match to each employee contribution per pay period. If you max out your 401(k) contributions early in the year and subsequently stop making contributions, your employer will also stop making matches, assuming the employer's plan does not provide for \"true up\" contributions. (More on true ups later.) Let\u2019s assume that an employer will match 50 percent of an employee\u2019s contribution per pay period, up to 6 percent of employee compensation. A worker earning $75,000 would be paid $3,125 twice a month. To contribute enough money to reach the IRS's $18,000 contribution limit, she would need to contribute $750 per pay period, or 24 percent of her salary. In that scenario, the employer would contribute $93.75 in matching funds per pay period, since 6 percent of the employee\u2019s pay would be $187.50, and $93.75 is half of that. If, however, the worker decided to contribute $818.18 per pay period instead, she would max out her 401(k) contributions before the end of the year\u2014by the 22nd pay period of the year, to be exact. For the two remaining pay periods of the year, her contribution would be $0\u2014 and her employer's matching contribution would be $0 as well because there would be nothing to match. That would mean she missed out on an extra $187.50 in contributions. \"Whether she had decided to contribute $750 or the $818.18 per pay period, she would have ended up contributing the same $18,000 total during the year to the retirement plan,\" said Anne St. Martin, a manager at the Society for Human Resource Management's Knowledge Center. \"But if she had contributed $818.18 per pay period, she would have missed out on getting the employer match for each of the last two pay periods of the year.\" That $187.50 in matching funds might not seem like much, but it can add up over the years\u2014particularly when you factor in the returns you are missing on that money. And the consequences of 401(k) front-loading could be larger for high earners who max out just months into a new year or employees who decide to max out their contribution with a bonus awarded in the first months of the year, precluding them from several months' of employer matches. You might be in luck, however, because some 401(k) plans include a feature that allows workers to get the maximum employer match even if they've finished contributing to their 401(k) plans early in the year. The feature, called a true up, allows employees to receive employer matches that they would have otherwise missed out on because of 401(k) front-loading or because they spread their 401(k) contributions out unevenly throughout the year. In the example used above, had the worker's 401(k) plan included a true up feature, she would have received $187.50 in employer matching funds at the end of the year in addition to the matching funds she received during the pay periods when she did contribute to her 401(k). Of nearly 400 companies surveyed, 45 percent offered 401(k) true ups, according to a 2015 report on defined contribution plans. Alternatively, your employer may calculate and make matching contributions on an annual basis. According to the 2015 survey, 12 percent of employers provide annual matching contributions. There is at least one case when front-loading 401(k) contributions may make sense, even when it means losing out on some employer matching funds: when you're planning on leaving your company, whether it's because you're joining a different employer or retiring. \"If you're leaving an employer, it may be very smart to frontload,\" said St. Martin. \"A new employer may have a waiting period for a new plan, or maybe you're retiring and you won't have a plan at all.\" Employees, she said, \"may like to front-load to take advantage of the pre-tax savings\" if they won't have access to 401(k) plans later in the year. When you're determining the size and schedule of your 401(k) contributions, consider checking with your company's human resources department to learn more about the structure of your 401(k) plan's employer matches. Here are a few questions to ask: Small differences in retirement savings habits can have a big impact over time, so it\u2019s important to always be on the lookout for ways to maximize the impact of your 401(k) contributions.","time":1525715661,"title":"Too Fast to Match? This 401(k) Misstep Could Hurt Retirement Savings","type":"story","url":"https:\/\/www.finra.org\/investors\/too-fast-match-401k-misstep-could-hurt-retirement-savings"},{"by":"vezycash","descendants":7,"id":17014814,"kids":"[17015035, 17019713, 17015617, 17024797]","score":10,"text":"\n 17 minutes ago\n \n3 hours ago\n \n7 hours ago\n \n7 hours ago\n \n7 hours ago\n \n7 hours ago\n \n8 hours ago\n \n9 hours ago\n \n3 hours ago\n \n12 hours ago\n \n13 hours ago\n \n13 hours ago\n \nMay 7, 2018\n \nMay 4, 2018\n \nMay 4, 2018\n \nMay 3, 2018\n \n3 hours ago\n \n21 hours ago\n \nMay 8, 2018\n \nMay 8, 2018\n \nApr 29, 2018\n \nApr 26, 2018\n \nApr 20, 2018\n \nApr 14, 2018\n \nMay 4, 2018\n \nApr 16, 2018\n \nJan 16, 2018\n \nDec 27, 2017\n \nApr 26, 2018\n \nApr 22, 2018\n \nApr 11, 2018\n \nApr 9, 2018\n \nMay 4, 2018\n \n18 hours ago\n \nMay 7, 2018\n \n7 hours ago\n \n20 hours ago\n \nMay 7, 2018\n \nMay 6, 2018\n \nMay 5, 2018\n \n\n              By\n              \n                Dreyer Smit\n\nNeowin LLC\n@dreyer_smit\n              \n               \u00b7\n            \nMay 7, 2018 12:04 EDT\n\nwith 38 comments\n\n With the Microsoft Build 2018 keynote in full swing, the company preemptively announced an update to its fee structure - which will reportedly be confirmed by Joe Belfiore during the keynote today - for developers who sell applications on its platform. The update, which only applies to apps in the Microsoft Store will increase the revenue share which is paid, further incentivizing developers to target the platform.    According to Microsoft, the revenue share will be upped to 95:5 in favor of the developer on all applications sold through the store on consumer Windows 10 devices - which includes Mobile, PC's, Windows Mixed Reality and the Surface Hub. This is a one-up on both Google and Apple, both of which offer revenue sharing of around 60:40 in favor of the developer. The company noted, however, that these new terms will not apply to games. Furthermore, it noted that if the application was purchased via a referral by the company - be it online advertising or similar methods - the share will drop to 85:15 in favor of the developer. The new fee structure will come into effect later this year through an update to the App Developer Agreement, which will outline its structure in further detail. Source: Windows Blogs \nMay 4, 2018\n\nwith 180 comments\n\n \n18 hours ago\n\nwith 28 comments\n\n \nMay 7, 2018\n\nwith 0 comments\n\n \n7 hours ago\n\nwith 36 comments\n\n \n7 hours ago\n \n8 hours ago\n \n8 hours ago\n \n9 hours ago\n Please enter your reason for reporting this comment. The following codes can be used in comments. \n        thinkpad t480\n       \n        p20 pro\n       \n        april 2018 update\n       \n        keep calm\n       \n        microsoft weekly\n       \n      nvidia\n     \n      xps 15 2-in-1\n     \n      windows 10\n     \n      redstone 5\n     \n\u00a9 Since 2000 Neowin LLC.\n                All trademarks mentioned are the property of their respective owners.\n              ","time":1525715601,"title":"Microsoft ups revenue share for developers in the online Store to 95%","type":"story","url":"https:\/\/www.neowin.net\/news\/microsoft-ups-revenue-share-for-developers-in-the-online-store-to-95"},{"by":"runesoerensen","descendants":415,"id":17014807,"kids":"[17015167, 17015528, 17014954, 17015057, 17015219, 17015377, 17017759, 17015209, 17015325, 17016171, 17015378, 17014881, 17016450, 17016957, 17015468, 17019419, 17016703, 17020278, 17015602, 17015366, 17019463, 17019607, 17017455, 17018394, 17015086, 17019596, 17016767, 17015809, 17018601]","score":331,"text":"The cause of the fatal crash of an Uber  self-driving car appears to have been at the software level, specifically a function that determines which objects to ignore and which to attend to, The Information reported. This puts the fault squarely on Uber\u2019s doorstep, though there was never much reason to think it belonged anywhere else. Given the multiplicity of vision systems and backups on board any given autonomous vehicle, it seemed impossible that any one of them failing could have prevented the car\u2019s systems from perceiving Elaine Herzberg, who was crossing the street directly in front of the lidar and front-facing cameras. Yet the car didn\u2019t even touch the brakes or sound an alarm. Combined with an inattentive safety driver, this failure resulted in Herzberg\u2019s death. Here\u2019s how Uber\u2019s self-driving cars are supposed to detect pedestrians  The only possibilities that made sense were: The sources cited by The Information say that Uber has determined B was the problem. Specifically, it was that the system was set up to ignore objects that it should have attended to; Herzberg seems to have been detected but considered a false positive. This is not good. Autonomous vehicles have superhuman senses: lidar that stretches out hundreds of feet in pitch darkness, object recognition that tracks dozens of cars and pedestrians at once, radar and other systems to watch the road around it unblinkingly. But all these senses are subordinate, like our own, to a \u201cbrain\u201d \u2014 a central processing unit that takes the information from the cameras and other sensors and combines it into a meaningful picture of the world around it, then makes decisions based on that picture in real time. This is by far the hardest part of the car to create, as Uber has shown. It doesn\u2019t matter how good your eyes are if your brain doesn\u2019t know what it\u2019s looking at or how to respond properly. Update: Uber issued the following statement, but did not comment on the claims above: We\u2019re actively cooperating with the NTSB in their investigation. Out of respect for that process and the trust we\u2019ve built with NTSB, we can\u2019t comment on the specifics of the incident. In the meantime, we have initiated a top-to-bottom safety review of our self-driving vehicles program, and we have brought on former NTSB Chair Christopher Hart to advise us on our overall safety culture. Our review is looking at everything from the safety of our system to our training processes for vehicle operators, and we hope to have more to say soon. As this is a situation without precedent, the NTSB and other reports may be particularly difficult to create and slow to issue, and it\u2019s not abnormal for a company or individual to hold off from revealing too much information ahead of publication.","time":1525715563,"title":"Uber vehicle reportedly saw but ignored woman it struck","type":"story","url":"https:\/\/techcrunch.com\/2018\/05\/07\/uber-vehicle-reportedly-saw-but-ignored-woman-it-struck\/"},{"by":"vezycash","descendants":0,"id":17014794,"kids":"None","score":3,"text":"May 7 \n\nFred Lambert\n\n \n\t\t\t\t\t\t\t- May. 7th 2018 6:00 am ET\n\t\t\t\t\t\t\t\t @FredericLambert The idea behind Tesla\u2019s solar roof tiles was driven by Elon Musk seeing a need for more differentiation in solar products, which he thought would be driven by aesthetics. Integrating solar cells into roofing material wasn\u2019t in any way a new idea, but Tesla\u2019s solar roof tiles innovated\u00a0by making the solar cells undetectable\u00a0from a street view while still capturing sunlight. Now a new patent obtained by Tesla and released last week shows how the company made it happen.\n\n(adsbygoogle = window.adsbygoogle || []).push({});\n When unveiling the new product, Musk said that there was\u00a0a shocking amount of technology in the tiles. They are using new\u00a0solar cells developed with Panasonic and they had to develop a new complex connector technology to link all the tiles in an efficient way that wouldn\u2019t take too much time to install. But for the\u00a0aesthetics, they had to find a way to make the tiles look normal from a street view while still leaving the solar cells visible from a birdseye view in order for them to catch the sun. They had to achieve all that without losing too much cell efficiency. Tesla claims to have done it with about 98% of the efficiency of regular solar cells in solar panels. Here\u2019s a look at a street angle (left) versus a birdseye view (right) of the solar roof tiles:  The day before they unveiled the product, Tesla applied for a patent on the technology behind it and the application was made public last week. In short, Tesla developed a new glass with\u00a0louvers that reflect that light in a way that makes it look opaque at a lower angle when combined with a backsheet layer while still remaining transparent for the sunlight above. Here are two figures from the patent application:  Here\u2019s Tesla\u2019s more technical description of the system from the patent application: \u201cA solar panel includes a backsheet layer, a bottom encapsulant layer adjacent the backsheet layer, a plurality of photovoltaic cells adjacent the bottom encapsulant layer, a top encapsulant layer adjacent the plurality of photovoltaic cells having a plurality of louvers constructed therein to block side view of the plurality of photovoltaic cells, and a top layer adjacent the top encapsulant layer.\u201d The patent application also describes different ways that they can use the technology to give different visible colors and textures to the tiles. I am not going to lie,\u00a0a lot of it is extremely technical and went over my\u00a0head, but here\u2019s the patent application in full if you want to take a deep dive: \n Tesla is a transportation and energy company. It sells vehicles under its 'Tesla Motors' division and stationary battery pack for home, commercial and utility-scale projects under its 'Tesla Energy' division. Tesla and SolarCity developed a solar roof system that integrates the solar cells and modules inside the structure of the roof rather than just panels on a roof.  \n@FredericLambert\n Fred is the Editor in Chief and Main Writer at Electrek. You can send tips on Twitter (DMs open) or via email: fred@9to5mac.com If you want to help Fred and Electrek, you can contribute to our Patreon: https:\/\/www.patreon.com\/electrek Tesla updates Model S and Model X interior Watch a Tesla Model 3 set the new quarter-mile\u00a0rec... Tesla is working on a new record-breaking 1 GWh project Norway's fjords are going zero-emission","time":1525715469,"title":"Tesla patent reveals secret behind its solar roof tile\u2019s camouflage capacity","type":"story","url":"https:\/\/electrek.co\/2018\/05\/07\/tesla-patent-secret-solar-roof-tiles-camouflage\/"},{"by":"banderon","descendants":153,"id":17013985,"kids":"[17014783, 17014622, 17017610, 17016763, 17016390, 17017594, 17017177, 17017737, 17017389, 17016989, 17015812, 17016830, 17016950, 17015583, 17018898]","score":180,"text":"Kubernetes, the open source container orchestration tool, came out of Google several years ago and has gained traction amazingly fast. With each step in its growth, it has created opportunities for companies to develop businesses on top of the open source project. The beauty of open source is that when it works, you build a base platform and an economic ecosystem follows in its wake. That\u2019s because a project like Kubernetes (or any successful open source offering) generates new requirements as a natural extension of the growth and development of a project. Those requirements represent opportunities for new projects, of course, but also for startups looking at building companies adjacent that open source community. Before that can happen however, a couple of key pieces have to fall into place. For starters you need the big corporates to get behind it. In the case of Kuberentes, in a 6 week period last year in quick succession between July and the beginning of September, we saw some of the best known enterprise technology companies including\u00a0AWS,\u00a0Oracle,\u00a0Microsoft,\u00a0VMware and Pivotal\u00a0all join the Cloud Native Computing Foundation (CNCF), the professional organization behind the open source project. This was a signal that Kubernetes was becoming a standard of sorts for container orchestration. Surely these big companies would have preferred (and tried) to control the orchestration layer themselves, but they soon found that their customers preferred to use Kubernetes  and they had little choice, but to follow the clear trend that was developing around the project. Photo:\u00a0Georgijevic on Getty Images The second piece that has to come together for an open source community to flourish is that a significant group of developers have to accept it and start building stuff on top of the platform \u2014 and Kubernetes got that too. Consider that according to CNCF, a\u00a0total of 400 projects have been developed on the platform by 771 developers contributing over 19,000 commits since the launch of Kubernetes 1.0 in 2015. Since last August, the last date for which the CNCF has numbers, developer contributions had increased by 385 percent. That\u2019s a ton of momentum. When you have those two ingredients in place \u2014 developers and large vendors \u2014 you can begin to gain velocity. As more companies and more developers come, the community continues to grow, and that\u2019s what we\u2019ve been seeing with Kubernetes. As that happens, it typically doesn\u2019t take long for investors to take notice, and according to CNCF, there has been over $4 billion in investments so far in cloud native companies \u2014 this from a project that didn\u2019t even exist that long ago. Photo: Fitria Ramli \/ EyeEm on Getty Images. That investment has taken the form of venture capital funding startups trying to build something on top of Kubernetes, and we\u2019ve seen some big raises. Earlier this month, Hasura raised a $1.6M seed round for a packaged version Kubernetes designed specially to meet the needs of developers. Just last week, Upbound, a new startup from Seattle got $9 million in its Series A round to help manage multi-cluster and multi-cloud environments in a standard (cloud-native) way. A little further up the maturity curve, Heptio has raised over $33 million with its most recent round being a $25 million Series B\u00a0last September. Finally, there is CoreOS, which raised almost $50 million before being sold to Red Hat for $250 million in January. CoreOS wasn\u2019t alone by any means as we\u2019ve seen other exits coming over the last year or two with organizations scooping up cloud native startups. In particular, when you see the largest organizations like Microsoft, Oracle and Red Hat buying relatively young startups, they are often looking for talent, customers and products to get up to speed more quickly in a growing technology area like Kubernetes.  Kubernetes has grown and developed into an economic powerhouse in short period of time as dozens of side projects have developed around it, creating even more opportunity for companies of all sizes to build products and services to meet an ever-growing set of needs in a virtuous cycle of investment, innovation and economic activity. Cloud Native Computing Foundation projects. Photo: Cloud Native Computing Foundation If this project continues to grow, chances are it will gain even more investment as companies continue to flow toward containers and Kubernetes, and even more startups develop to help create products to meet new needs as a result.","time":1525710137,"title":"As Kubernetes grows, a startup ecosystem develops in its wake","type":"story","url":"https:\/\/techcrunch.com\/2018\/05\/07\/as-kubernetes-grows-a-startup-ecosystem-develops-in-its-wake\/"},{"by":"jph00","descendants":1,"id":17013894,"kids":"[17014038]","score":19,"text":"Making neural nets uncool again \u00a9 fast.ai 2018. All rights reserved. Today we are launching the 2018 edition of Cutting Edge Deep Learning for Coders, part 2 of fast.ai\u2019s free deep learning course. Just as with our part 1 Practical Deep Learning for Coders, there are no pre-requisites beyond high school math and 1 year of coding experience\u2014we teach you everything else you need along the way. This course contains all new material, including new state of the art results in NLP classification (up to 20% better than previously known approaches), and shows how to replicate recent record-breaking performance results on Imagenet and CIFAR10. The main libraries used are PyTorch and fastai (we explain why we use PyTorch and why we created the fastai library in this article). Each of the eight lessons includes a video that\u2019s around two hours long, an interactive Jupyter notebook, and a dedicated discussion thread on the fast.ai forums. The lessons cover many topics, including: multi-object detection with SSD and YOLOv3; how to read academic papers; customizing a pre-trained model with a custom head; more complex data augmentation (for coordinate variables, per-pixel classification, etc); NLP transfer learning; handling very large (billion+ token) text corpuses with the new fastai.text library; running and intepreting ablation studies; state of the art NLP classification; multi-modal learning; multi-task learning; bidirectional LSTM with attention for seq2seq; neural translation; customizing resnet architectures; GANs, WGAN, and CycleGAN; data ethics; super resolution; image segmentation with u-net. Lesson 8 starts with a quick recap of what we learned in part 1, and introduces the new focus of this part of the course: cutting edge research. We talk about how to read papers, and what you\u2019ll need to build your own deep learning box to run your experiments. Even if you\u2019ve never read an academic paper before, we\u2019ll show you how to do so in a way that you don\u2019t get overwhelmed by the notation and writing style. Another difference in this part is that we\u2019ll be digging deeply into the source code of the fastai and Pytorch libraries: in this lesson we\u2019ll show you how to quickly navigate and build an understanding of the code. And we\u2019ll see how to use python\u2019s debugger to deepen your understand of what\u2019s going on, as well as to fix bugs. The main topic of this lesson is object detection, which means getting a model to draw a box around every key object in an image, and label each one correctly. You may be surprised to discover that we can use transfer learning from an Imagenet classifier that was never even trained to do detection! There are two main tasks: find and localize the objects, and classify them; we\u2019ll use a single model to do both these at the same time. Such multi-task learning generally works better than creating different models for each task\u2014which many people find rather counter-intuitive. To create this custom network whilst leveraging a pre-trained model, we\u2019ll use fastai\u2019s flexible custom head architecture. In this lesson we\u2019ll move from single object to multi-object detection. It turns out that this slight difference makes things much more challenging. In fact, most students found this the most challenging lesson in the whole course. Not because any one piece is highly complex, but because there\u2019s a lot of pieces, so it really tests your understanding of the foundations we\u2019ve learnt so far. So don\u2019t worry if a lot of details are unclear on first viewing \u2013 come back to this lesson from time to time as you complete the rest of the course, and you should find more and more of it making sense! Our focus is on the single shot multibox detector (SSD), and the related YOLOv3 detector. These are ways to handle multi-object detection by using a loss function that can combine losses from multiple objects, across both localization and classification. They also use a custom architecture that takes advantage of the difference receptive fields of different layers of a CNN. And we\u2019ll see how to handle data augmentation in situations like this one where the dependent variable requires augmentation too. Finally, we discuss a simple but powerful trick called focal loss which is used to get state of the art results in this field. After reviewing what we\u2019ve learned about object detection, in lesson 10 we jump into NLP, starting with an introduction to the new fastai.text library. This is a replacement for torchtext which is faster and more flexible in many situations. A lot of this class will be very familiar\u2014we\u2019re covering a lot of the same ground as lesson 4. But this lesson will show you how to get much more accurate results, by using transfer learning for NLP. Transfer learning has revolutionized computer vision, but until now it largely has failed to make much of an impact in NLP (and to some extent has been simply ignored). In this class we\u2019ll show how pre-training a full language model can greatly surpass previous approaches based on simple word vectors. We\u2019ll use this language model to show a new state of the art result in text classification. In lesson 11 we\u2019re going to learn to translate French into English! To do so, we\u2019ll learn how to add attention to an LSTM in order to build a sequence to sequence (seq2seq) model. But before we do, we\u2019ll do a review of some key RNN foundations, since a solid understanding of those will be critical to understanding the rest of this lesson. A seq2seq model is one where both the input and the output are sequences, and can be of difference lengths. Translation is a good example of a seq2seq task. Because each translated word can correspond to one or more words that could be anywhere in the source sentence, we learn an attention mechanism to figure out which words to focus on at each time step. We\u2019ll also learn about some other tricks to improve seq2seq results, including teacher forcing and bidirectional models. We finish the lesson by discussing the amazing DeVISE paper, which shows how we can bridge the divide between text and images, using them both in the same model! We start this lesson with a deep dive into the DarkNet architecture used in YOLOv3, and use it to better understand all the details and choices that you can make when implementing a resnet-ish architecture. The basic approach discussed here is what we used to win the DAWNBench competition! Then we\u2019ll learn about Generative Adversarial Networks (GANs). This is, at its heart, a different kind of loss function. GANs have a generator and a discriminator that battle it out, and in the process combine to create a generative model that can create highly realistic outputs. We\u2019ll be looking at the Wasserstein GAN variant, since it\u2019s easier to train and more resilient to a range of hyperparameters. For the start of lesson 13 we\u2019ll cover the CycleGAN, which is a breakthrough idea in GANs that allows us to generate images even where we don\u2019t have direct (paired) training data. We\u2019ll use it to turn horses into zebras, and visa versa; this may not be an application you need right now\u2026 but the basic idea is likely to be transferable to a wide range of very valuable applications. One of our students is already using it to create a new form of visual art. But generative models (and many other techniques we\u2019ve discussed) can cause harm just as easily as they can benefit society. So we spend some time talking about data ethics. It\u2019s a topic that really deserves its own whole course; whilst we can\u2019t go into the detail we\u2019d like in the time available, hopefully you\u2019ll get a taste of some of the key issues, and ideas for where to learn more. We finish the lesson by looking at style transfer, an interesting approach that allows us to change the style of images in whatever way we like. The approach requires us to optimize pixels, instead of weights, which is an interesting different way of looking at optimization. In this final lesson, we do a deep dive into super resolution, an amazing technique that allows us to restore high resolution detail in our images, based on a convolutional neural network. In the process, we\u2019ll look at a few modern techniques for faster and more reliable training of generative convnets. We close with a look at image segmentation, in particular using the Unet architecture, a state of the art technique that has won many Kaggle competitions and is widely used in industry. Image segmentation models allow us to precisely classify every part of an image, right down to pixel level.","time":1525709536,"title":"Cutting Edge Deep Learning for Coders: 2018 Edition","type":"story","url":"http:\/\/www.fast.ai\/2018\/05\/07\/part2-launch\/"},{"by":"dankohn1","descendants":3,"id":17013855,"kids":"[17014004, 17014731, 17014605]","score":47,"text":"Above: Google's Kelsey Hightower speaks at KubeCon. The four years that William Morgan spent as an engineer at Twitter battling the Fail Whale gave him a painful view into what happens when a company\u2019s rickety web infrastructure gets spread too thin. But while Twitter\u2019s instability was highly publicized, Morgan realized that the phenomenon existed to some degree across the web, as companies were building applications in ways that were never intended to handle such scale. The result: Applications and software were becoming too expensive, too hard to manage, and too slow to deploy, and they required too many developers and caused too much downtime. After leaving Twitter in 2014, Morgan wanted to use some of the lessons he had learned to help other companies reimagine the way they build applications for the web. That led to the founding in 2015 of Buoyant, whose application development tools have become part of an insurgent movement to fundamentally transform the way software and services are designed for the web. Referring to what is in some cases dubbed\u00a0\u201cmicroservices\u201d or \u201ccloud native computing,\u201d the development philosophy holds that breaking applications into smaller, self-contained units can significantly reduce costs and time needed to write, deploy, and manage each one. The result should be a web that is faster yet more stable. And just as compelling to proponents, it should deliver a more open web that makes it easier for users to change cloud platforms. While such shifts in development philosophy typically take many years, cloud native computing has caught fire and is having a big moment. Even though it remains small overall, the uptake and enthusiasm has even taken advocates like Morgan by surprise. \u201cIt\u2019s kind of incredible how rapidly this has been growing,\u201d he said. \u201cIt speaks to the fact that people are focused on the right thing, which is solving actual problems. What we are seeing here is just a beginning. But I think this could fundamentally change everything about web development.\u201d That optimism was on display this week at the latest edition of a conference called KubeCon + CloudNativeCon Europe 2018 in Copenhagen, Denmark. The event drew Morgan, along with 4,300 other attendees from around the world. While conferences are never a perfect barometer of an industry, that figure is up from the 500 people who attended the first such gathering in November 2015. The event is organized by the Cloud Native Computing Foundation, an open source organization that operates under the umbrella of the Linux Foundation. CNCF was created just over three years ago to shepherd this new movement.\nThe current momentum around cloud native computing seems to be a function of both the right solution and the right timing. As web development has evolved, there has been a tendency to develop \u201cmonolithic\u201d applications \u2014 that is, software that contains most or all parts of the code for a given company or service. Over time, those code bases have grown to massive sizes and become hugely complex, which has led to a wide array of problems. Developing and maintaining such applications can take an enormous number of developers. Even for companies that have made the necessary investments and hired those developers, making any changes or updates can be cumbersome and take weeks. For others, the resources needed to build the technology can seem like an insurmountable challenge. \u201cSoftware has gotten a lot more complex,\u201d said Ben Sigelman, cofounder and CEO of LightStep, a San Francisco-based startup that makes performance management tools for microservices. \u201cIt\u2019s gotten a lot more powerful, but it crossed a threshold where the complexity of the code to deliver those features requires hundreds and hundreds of developers. And once you have hundreds of developers working on the code, you\u2019re in a dangerous place. It\u2019s an efficiency issue, and it can lead to paralysis.\u201d The solution, according to adherents of cloud native computing, is to break these big slabs of code into self-contained functions or features. This modular approach, particularly if it\u2019s based on open sources tools, would ideally make constructing web services and maintaining them far more efficient. Each piece could be deployed or updated rapidly, by fewer developers, without having to worry that it\u2019s going to blow up the entire code base. This concept of microservices has been floating around for some time. But it got a big boost in 2013 when San Francisco-based Docker released its first product. Docker helped popularize the use of \u201ccontainers,\u201d a technology that places all the necessary pieces for an application to run in one package. That allows the application to be moved across different platforms and operating systems without having to be rewritten. The following year, Google announced a project some of its engineers had been developing to enable the deployment and management of containerized applications called Kubernetes. While Google felt that Kubernetes could provide a powerful boost to cloud-based services, it also recognized that its acceptance would be limited as long as it was seen as a Google project, according to Kelsey Hightower, Google\u2019s Kubernetes community member and co-chair of the KubeCon conference. So Google approached the Linux Foundation about open-sourcing Kubernetes. Those talks led to the creation of CNCF, which also counted Twitter, Huawei, Intel, Cisco, IBM, Docker, Univa, and VMware among its founding members. Rather than being just a Kubernetes project, the foundation decided to take a wider view, positioning itself as a body that would oversee and encourage development of all the pieces needed to build applications using this new model. CNCF says it now has 20 projects \u2014 including Kubernetes \u2014 in some stage of development. Just as critically, CNCF now counts every major cloud service provider as a member. Over the past 12 months, Dan Kohn, executive director of CNCF, said he has been surprised by how quickly industry partners, many of them cloud platform rivals, have bought into the movement and joined the foundation. Microsoft announced it was joining last July. Amazon Web Services joined last August and hosted a networking event for developers at KubeCon. While Docker was already a founding member, it announced it was going to become more deeply involved by donating another of its tools, Containerd, to CNCF last year and doing more to support Kubernetes. \u201cThe aspiration was always to get everyone around the table,\u201d said Kohn. \u201cFrankly, I didn\u2019t expect it to happen so quickly.\u201d Above: Dan Kohn, executive director of Cloud Native Computing Foundation. It wasn\u2019t necessarily an easy decision for the companies. The fight to win in the public cloud space is a fierce one. Tools like Kubernetes and microservices eliminate some competitive advantages because they allow for easier data portability. For companies just moving into the cloud-based world, the ability to avoid the risk of vendor lock-in is another appeal of cloud native computing. \u201cEveryone is so conscious of software coming from one source,\u201d said Gareth Rushgrove, a Docker product manager. \u201cThey are worried they might not be able to get out from under one vendor solution. That\u2019s one of the reasons CNCF and this community have been so useful.\u201d So what was the catalyst? Most likely these companies saw the reality of where the market was heading as use of Kubernetes continued growing quickly. More companies are under pressure to digitize, and they increasingly see cloud native computing as a faster and easier way to get there. \u201cThe users are what is really driving this,\u201d said Abby Kearn, executive director of open source organization\u00a0Cloud Foundry, a CNCF sister group under the Linux Foundation umbrella. \u201cThey need to digitally transform and become technology companies. If you\u2019re a bank, and you\u2019re not transforming and trying to become a technology company, where does that leave you? You\u2019ve got a ton of fintech companies coming for your customers.\u201d At the three-day conference, organizers announced that Chinese internet giant JD.com had 20,000 servers running Kubernetes, making it one of the largest adopters in the world. A report commissioned by LightStep, which surveyed 353 developers from companies around the world, found that 86 percent expect microservices will become the default development architecture within five years. And the three-day KubeCon was packed with participating companies making announcements designed to expand the ecosystem of related products and services. Jason McGee, vice president and CTO of IBM Cloud Platform, said his company is betting big on cloud native solutions because they have the potential to help its customers move faster. Microservices are allowing companies to mix and match containerized, open source solutions so they don\u2019t have to build everything from scratch. \u201cI can build a microservice that you can re-use,\u201d McGee said. \u201cThat will allow the overall industry to go faster. Right now, we spend a lot of time re-solving the same problems.\u201d Naturally, this frenzy has sparked interest from venture capitalists. Buoyant has raised $14 million. And LightStep has raised $27 million over two rounds after Sigelman initially told potential Series A investors to hold off because he wasn\u2019t sure how quickly users might embrace microservices. \u201cI knew that the idea made sense,\u201d said Sigelman, who worked at Google for nine years before striking out on his own. \u201cI didn\u2019t know about the timing. I told Series A investors to wait for it. I knew it was going to happen. I didn\u2019t know when.\u201d For all this optimism, there are still plenty of skeptics who see cloud native computing and microservices as an overhyped development fad. Even CNCF members openly acknowledge that many challenges lie ahead. Speaking on stage to open the conference, Kohn posed the question \u201cIs our software good enough?\u201d and then answered it by declaring, \u201cNo.\u201d Part of the issue is that while there are many potential benefits to making the transition to microservices, older tools for things like communicating between applications and monitoring app performance won\u2019t work in this environment. That same LightStep survey found that 99 percent of developers surveyed reported some \u201cchallenges\u201d in using microservices, with more than half saying it was increasing their operational challenges. This begs the question: Is the move to microservices simply trading an old set of problems for new ones? Put another way, will the promised benefits significantly outweigh the headaches? Sigelman says the answer is yes, noting that the new architecture can potentially reduce the risk of a single failure bringing down someone\u2019s entire system. \u201cThe operational efficiencies will be there regardless,\u201d he said. \u201cYou\u2019re going to get rid of some really profound problems.\u201d Of course, that\u2019s also an opportunity for people like Sigelman, whose company is making tools to solve some of those new issues. And indeed, that was true of many of the startups on hand, as many of the product announcements were aimed at plugging those gaps and bolstering the overall maturity of this approach. Still, conference organizers sought to infuse the gathering with a greater sense of urgency right from the start. Hightower of Google kicked off the conference by issuing a challenge to the audience. The wave of excitement around this market had propelled their movement further and faster than anticipated, he said. But adrenaline wasn\u2019t enough. With more attention and more interest being showered on cloud native computing and microservices, the movement needed to grow up even more quickly and make sure all the pieces are in place to deliver on its hefty promises. \u201cThink of CNCF and those first couple of years being like a startup,\u201d Hightower told attendees. \u201cThe startup phase is over.\u201d (Disclosure: The Linux Foundation paid for VentureBeat\u2019s travel expenses to Copenhagen for the KubeCon + CloudNativeCon Europe 2018 event. Our coverage remains objective.)","time":1525709313,"title":"Kubernetes and microservices: Making the web faster, stable, and more open","type":"story","url":"https:\/\/venturebeat.com\/2018\/05\/06\/kubernetes-and-microservices-a-developers-movement-to-make-the-web-faster-stable-and-more-open\/"},{"by":"stablemap","descendants":43,"id":17013815,"kids":"[17014197, 17013961, 17014445, 17013940, 17015097, 17014015, 17015388, 17015364, 17013916]","score":68,"text":"\u00a0 This Patriots\u2019 Day marks 243 years since farmers, tradesmen, merchants, and sailors fought a bloody war to throw off the yoke of King George and the British monarchy. They established a republic in the place of the monarchy, and sought to make the government accountable to the people. In the years since, the people of most of the Earth\u2019s nations have followed suit and rid their nations of monarchical governments. Among the absolute monarchies still in power, the most egregious is that of the Saud family of Saudi Arabia. We are appalled that the MIT administration agreed to meet and presumably negotiated programs with the Saudi Crown Prince, Mohamed Bin Salman (MBS). This was done without any consultation with faculty or student organizations.  Saudi Arabia, in fact, remains an oppressive absolute monarchy, and the source of great human suffering, most notably from their war on the people of Yemen. Bin Salman was on a U.S. tour, and earlier met with President Trump, who had approved the sale of $billions worth of U.S. missiles and warplanes to the Saudi government. The weapons are among those used in the Saudi-led war on Yemen that has left thousands of civilians dead since 2015. The United States is also assisting the Saudi monarchy in the coalition\u2019s targeting selection for aerial bombings and actively providing midair refueling for Saudi and United Arab Emirates jets that conduct indiscriminate airstrikes \u2013 the leading cause of civilian casualties. Meanwhile, the Saudi coalition is starving millions of Yemenis as a grotesque tactic of war. According to the UN, the blockade of Yemeni ports by the Saudi military has resulted in \u201cthe largest famine the world has seen in decades,\u201d causing a massive cholera epidemic and leaving 400,000 children malnourished. Bin Salman\u2019s extensive public relations campaign directed at Americans has painted him as a \u201creformer\u201d who is supporting, for example, the rights of women to drive, while ignoring the continuing general oppression of women in Saudi Arabia, imprisoning hundreds without trial, and actively opposing democratic movements in other Arab states.  Cambridge City Councilor and MIT alumnus Quinton Zondervan, speaking at the demonstration against Bin Salman\u2019s visit, stated clearly \u201cWe do not need to show respect to an oppressor and a bully and a warmonger.\u201d U.S. Congressmen Rho Khanna, Marc Pocan, and Walter Jones (New York Times, October 10, 2017) have criticized our government for \u201cparticipating in a military coalition led by Saudi Arabia and the United Arab Emirates in a brutal military campaign in Yemen.\u201d  On April 2 the Cambridge City Council went on record in opposition to the oppressive policies of MBS and Saudi Arabia,\u00a0stated its disappointment at the manner in which the visit was hidden by Harvard and MIT, and requested that copies of the resolution be delivered to the Presidents of both MIT and Harvard as well as MBS. The Tech reported on the meeting in their April 5 issue, and published a cogent and critical editorial. Due to the complete lack of candor of the MIT administration, we don\u2019t know the precise nature of the business between the Crown Prince and MIT. According to Grif Peterson and Yarden Katz, of Harvard\u2019s Berkman Klein Center for Internet & Society, writing in the Guardian (Friday, March 30, 2018) \u201c. . . Bin Salman\u2019s foundation, MiSK, was accepted as a \u2018member company\u2019 to MIT\u2019s Media Lab in 2017, which requires a minimum annual contribution of $250,000 (with a three-year commitment) to the lab. In return, MiSK receives access to the lab\u2019s personnel, technology, and intellectual property.\u201d Regardless of the content, MIT should not be entering into an agreement with representatives of the Saudi regime. This recalls the Shah of Irans\u2019s effort to secure nuclear engineering graduate slots for the Shah\u2019s chosen candidates. This was eventually rejected due to opposition from the faculty. At a minimum, President Reif should have reported to the faculty on the visit of Bin Salman. He now needs to ensure that MIT has not entered into any further agreements with the Saudi government or Royal Family that ignore their record of oppression, discrimination, and human rights violations.     \n     Editorial Subcommittee Manduhai Buyandelger\nChristopher Cummins\nJonathan King \nRuth Perry\nNasser Rabbat \n","time":1525709033,"title":"MIT Should Not Be Supporting the Saud Monarchy","type":"story","url":"http:\/\/web.mit.edu\/fnl\/volume\/304\/editorial.html"},{"by":"leahculver","descendants":2,"id":17013799,"kids":"[17014990]","score":66,"text":" Over 600,000 repositories received statuses in January 2018 alone\u2014more than a 50 percent increase from last year\u2014and now statuses will provide you with more information than ever. Today we\u2019re introducing the public beta release of the Checks API, a better way to get feedback from integrations on your code. The Checks API allows you to build sophisticated tools for continuous integration (CI), linting, and acceptance testing on GitHub. This new functionality currently works with the GitHub REST API, with GraphQL support coming soon. Instead of pass\/fail build statuses, your integrations can now report richer results, annotate code with detailed information, and kick off reruns\u2014all within the GitHub user interface.  Build outputs are now accessible with the new \u201cChecks\u201d tab on pull requests. Inline annotations are simple to find, too. They\u2019ll appear right alongside the relevant code in the pull request, so you can identify and address failing checks even faster. Learn more about the Checks API Over the last several weeks, we\u2019ve worked closely with partners on fine-tuning the Checks experience\u2014and we\u2019re excited to share several apps already using the API. Microsoft maintains hundreds of open source projects on GitHub, including Visual Studio Code, which had the most community participants among any project last year, and TypeScript, one of the fastest growing languages in 2017. Now we\u2019re partnering with Microsoft to integrate Azure\u2019s DevOps services with GitHub, starting with Azure\u2019s Mobile CI service. GitHub will detect mobile projects and suggest developers set up mobile CI using any one of our providers, including App Center. With App Center installed, you can automate builds on every commit, test apps on real devices in the cloud, and monitor usage with crash and analytics data. And because the App Center integration uses the Checks API, mobile developers will be able to see the results directly within GitHub\u2019s interface.  To provide you with simple, streamlined experiences for tools you already use, we\u2019re also integrating GitHub with Microsoft Outlook using Adaptive Cards. Over the next several weeks, Outlook users will be able to comment on issues from their inbox\u2014and soon after, be able to merge pull requests, too.  As a leading provider of hosted CI, Travis CI has been helping build and test open source and private projects for more than seven years. Travis CI recently adopted GitHub Apps and now includes Checks as a way for your team to share the results of your project\u2019s branch and pull request builds. View your build\u2019s stages, jobs, and results, including the config associated with them to get a complete picture of the health of your projects directly from GitHub. You can also rerun builds from within the GitHub Checks UI. Learn more about Travis CI integration with the Checks API Speed up your test and development cycle without extra maintenance. Follow your GitHub project from CircleCI, and set up your first build in no time thanks to CircleCI\u2019s automatically generated build and test steps and simple extensibility. Checks API compatibility with CircleCI is on the way. Today\u2019s announcement is just the start. We\u2019ll continue shipping new ways for you to make the most of GitHub and build useful, powerful tools that work seamlessly with our platform. With easy access to an open ecosystem of applications, you can create fast and flexible workflows that help you focus on what matters most. \n\n\n    Changelog\n  \n \n\n\n    Subscribe\n  \n Try Marketplace apps free for 14 days \n        \u00a9 2018\n      ","time":1525708901,"title":"Introducing GitHub Checks for continuous integration","type":"story","url":"https:\/\/blog.github.com\/2018-05-07-introducing-checks-api\/"},{"by":"mcone","descendants":0,"id":17013783,"kids":"None","score":23,"text":"\nMay 3, 2018\n\t\t\t\t\t\tat\n\t\t\t\t\t\t7:58 AM\n By Maggie Koerth-Baker Filed under Technology Randy Pench \/ Sacramento Bee \/ TNS via Getty Images The Golden State Killer, who terrorized Californians from Sacramento to Orange County over the course of a decade, committed his last known murder in 1986, the same year that DNA profiling was used in a criminal investigation for the first time. In that early case, officers convinced thousands of men to voluntarily turn over blood samples, building a genetic dragnet to search for a killer in their midst. The murderer was eventually identified by his attempts to avoid giving up his DNA. In contrast, suspected Golden State Killer Joseph James DeAngelo, who was apprehended just last week, was found through other people\u2019s DNA \u2014 samples taken from the crime scenes were matched to the profiles his distant relatives had uploaded to a publicly accessible genealogy website. You can see the rise of a modern privacy conundrum in the 32 years between the first DNA case and DeAngelo\u2019s arrest. Digital privacy experts say that the way DeAngelo was found has implications reaching far beyond genetics, and the risks of exposure apply to everyone \u2014 not just alleged serial killers. We\u2019re used to thinking about privacy breaches as what happens when we give data about ourselves to a third party, and that data is then stolen from or abused by that third party. It\u2019s bad, sure. But we could have prevented it if we\u2019d only made better choices. Increasingly, though, individuals need to worry about another kind of privacy violation. I think of it as a modern tweak on the tragedy of the commons \u2014 call it \u201cprivacy of the commons.\u201d It\u2019s what happens when one person\u2019s voluntary disclosure of personal information exposes the personal information of others who had no say in the matter. Your choices didn\u2019t cause the breach. Your choices can\u2019t prevent it, either. Welcome to a world where you can\u2019t opt out of sharing, even if you didn\u2019t opt in. Yonatan Zunger, a former Google privacy engineer, noted we\u2019ve known for a long time that one person\u2019s personal information is never just their own to share. It\u2019s the idea behind the old proverb, \u201cThree may keep a secret if two of them are dead.\u201d And as far back as the 1960s, said Jennifer Lynch, senior staff attorney for the Electronic Frontier Foundation, phone companies could help law enforcement collect a list of all the numbers one phone line called and how long the calls lasted. The phone records may help convict a guilty party, but they also likely call police attention to the phone numbers, identities and habits of people who may not have anything to do with the crime being investigated. But the digital economy has changed things, making the privacy of the commons easier to exploit and creating stronger incentives to do so. \u201cOne of the fascinating things we\u2019ve now walked ourselves into is that companies are valued by the market on the basis of how much user data they have,\u201d said Daniel Kahn Gillmor, senior staff technologist with the ACLU\u2019s Speech, Privacy and Technology Project. A company can run along, not making a cent, but if it has a large user base and reams of private information about those users, then it\u2019s valuable \u2014 and can be sold for millions. Companies that collect more data, keep that data, and use it to make connections between users are worth more. Sears, Roebuck and Co. may have been able to infer when you bought a gift from their catalog for a friend who lived in another town, but Amazon has more reason (and more ability) to use that information to build a profile of your friend\u2019s interests. We all saw this in action in the recent Cambridge Analytica scandal. The privacy of the commons is how the 270,000 Facebook users who actually downloaded the \u201cthisisyourdigitallife\u201d app turned into as many as 87 million users whose data ended up in the hands of a political marketing firm. Much of the narrative surrounding that scandal has focused on what individuals should be doing to protect themselves. But that idea that privacy is all about your individual decisions is part of the problem, said Julie Cohen, a technology and law professor at Georgetown University. \u201cThere\u2019s a lot of burden being put on individuals to have an understanding and mastery of something that\u2019s so complex that it would be impossible for them to do what they need to do,\u201d she said. Even if you do your searches from a specialized browser, tape over all your webcams and monitor your privacy settings without fail, your personal data has probably still been collected, stored and used in ways you didn\u2019t intend \u2014 and don\u2019t even know about. Companies can even build a profile of a person from birth based entirely on data-sharing choices made by others, said Salome Viljoen, a lawyer and fellow with the Berkman Klein Center for Internet and Society at Harvard. Imagine new parents signing up for a loyalty card at their local pharmacy and then filling all of their child\u2019s prescriptions there. The information collected every time they scan that loyalty card adds up to something like a medical history, which could later be sold to data brokers or combined with data bought from brokers to paint a fuller picture of a person who never consented to any of this. So does that mean that, in addition to locking down our own privacy choices, we need to police the choices of our friends and family? No, said Cohen, Gillmor and Viljoen. In fact, the privacy of the commons means that, in some cases, your data is collected in ways you cannot reasonably prevent, no matter how carefully you or anyone you know behaves. Take, for instance, Equifax, the credit-rating company that lost control of the data of 143 million people last year. Those people weren\u2019t necessarily members of Equifax. Instead, the company collected data from other companies the people chose to do business with, and much of that business was stuff people can\u2019t get by without, like renting or owning a home. Or, alternately, consider Facebook, again. That company has admitted it tracks the online behavior of people who never intentionally engage with it at all, thanks to partnerships with other websites. (Like many sites, FiveThirtyEight has this kind of partnership with Facebook. Our pages talk to the social network in several ways, including through ads and comments, and because of the embedded \u201cLike\u201d button.) If hounding every person you\u2019ve ever cared about into adopting encryption tools like PGP sounded like fun, you\u2019ll love living in a van down by the river with no internet access.1 Instead, experts say these examples show that we need to think about online privacy less as a personal issue and more as a systemic one. Our digital commons is set up to encourage companies and governments to violate your privacy. If you live in a swamp and an alligator attacks you, do you blame yourself for being a slow swimmer? Or do you blame the swamp for forcing you to hang out with alligators? There isn\u2019t yet a clear answer for what the U.S. should do. Almost all of our privacy law and policy is framed around the idea of privacy as a personal choice, Cohen said. The result: very little regulation addressing what data can be collected, how it should be protected, or what can be done with it. In some ways, Gillmor said, online privacy is where the environmental movement was back in the 1950s, when lots of big, centralized choices were hurting individuals\u2019 health, and individuals had little power to change that. \u201cI don\u2019t even know if we have had our \u2018Silent Spring\u2019 yet,\u201d he said. \u201cMaybe Cambridge Analytica will be our \u2018Silent Spring.\u2019\u201d And I hope you\u2019re prepared to buy the van with cash, because if you need credit, the credit check the dealer runs could hand your information to Equifax again. Maggie Koerth-Baker is a senior science writer for FiveThirtyEight.   @maggiekb1 Filed under Technology (26 posts)\nDNA (5)\nBioethics (1)\n Thanks for subscribing!A confirmation email is headed your way shortly. In the meantime, subscribe to FiveThirtyEight\u2019s other newsletters. \nAll newsletters\n Please enter a valid email address and try again. Thanks for subscribing!A confirmation email is headed your way shortly. In the meantime, subscribe to FiveThirtyEight\u2019s other newsletters. \nAll newsletters\n Please enter a valid email address and try again. Thanks for subscribing!A confirmation email is headed your way shortly. In the meantime, subscribe to FiveThirtyEight\u2019s other newsletters. Please enter a valid email address and try again. Enter the destination URL Or link to existing content","time":1525708764,"title":"You Can\u2019t Opt Out of Sharing Your Data, Even If You Didn\u2019t Opt In","type":"story","url":"https:\/\/fivethirtyeight.com\/features\/you-cant-opt-out-of-sharing-your-data-even-if-you-didnt-opt-in\/"},{"by":"robin_reala","descendants":318,"id":17012995,"kids":"[17013501, 17013446, 17013571, 17014533, 17016443, 17013444, 17017649, 17015042, 17014542, 17013367, 17016462, 17013640]","score":281,"text":"Home Latest news Current projects Technical Section Visit Concorde Concorde Fleet Concorde Passenger operations main menu Engineering Hero's main menu Concorde Development main menu Concorde Livery's and Paint main menu The Demise of Concorde main menu Groups of interest main menu Concorde in the media main menu Concorde Information & Facts Cockpit Tours main menu Concorde return to flight main menu Flight records Gone in 62 Seconds Current materials wish list Easy Page Access Concorde Quiz Blogger More \u00a0 Some of the details on this page are thanks to Gordon Roxburgh of Concordesst The Concorde production sadly ended with airframe number 216 (G-BOAF). \u00a0 This is particularly frustrating as the Concorde \u2018B\u2019 model was already designed and the engines were available for incorporation into the next airframe number 217. \u00a0 This was the aircraft the airlines really needed and the aircraft the manufacturers wanted to build. Unfortunately political pressure intervened and the will to proceed with it simply evaporated. \u00a0 The new engine (the Olympus 610 +25%) had, as its name suggests, more thrust and eliminated noisy, fuel-guzzling afterburners. \u00a0 The wing was redesigned, had leading edge \u2018droop\u2019 and carried more fuel. With better lift\/drag, specific fuel consumption and more fuel the range of the Concorde Model \u2018B\u2019 increased over the original Concorde \u2018A\u2019 Model. Just four months after Concorde began her scheduled services in 1976, a Concorde \u2018B\u2019 model was first discussed and designed with slightly larger fuel capacity and slightly larger wings with leading edge slats to improve aerodynamic performance at all speeds. It featured more powerful engines with sound deadening and without the fuel-hungry and noisy reheat. It was speculated that it was reasonably possible to create an engine with up to 25% gain in efficiency over the Rolls-Royce\/Snecma Olympus 593.This would have given 500\u00a0mi (805 km) additional range even with greater payload, and would have made new commercial routes possible. This was cancelled due in part to poor sales of Concorde, but also to the rising cost of aviation fuel in the 1970s. \u00a0 During 1976 Jacques Mitterrand, the Chairman and Managing Director of Aerospatiale, submitted a proposal to investigate an improved version of Concorde \u2013 the \u201cVersion B\u201d to Mr. Cavaille, French Secretary of State to Transport a similar letter was submitted to the British government at that time. \u00a0 The letter that he sent elaborated on the quality of the work which had been carried out and the know-how that had now been acquired by the four French and British engineering companies (Aerospatiale, BAe, Rolls Royce and SNECMA). In this letter he also stressed the importance of the role that the manufacturers of Concorde could have in the development of a second-generation supersonic aircraft, that would be foreseeable during the 1990\u2019s, could lead to probably in some form of a collaboration between Europe and the United States. \u00a0 An exploratory study was actually already underway during this time, looking into upgrading the capabilities of the current Concorde design for the early 1980\u2019s. The letter submitted also gave the official go ahead for this exploratory study and proposed a full feasibility study for a Concorde \u2018B\u2019 design. \u00a0 Due to the manufactures having great difficulty selling the remaining five Concorde airframes that were built during the initial production run, Concorde 216 (G-BOAF) was to be the last Concorde \u2018A\u2019 built, and 217 was planned to be a Concorde \u2018B\u2019 version. Had Concorde \u2018B\u2019 been built, what type of future would we be living in now? If the additional range and performance had been available then many more airlines might have purchased Concorde and passenger air travel as we know it today might have been completely different. \u00a0 She was planned to have a range approaching and even exceeding 5000 miles. But it is easy to imagine the potential range of Concorde \u2018B\u2019 design, when you consider that the Concorde \u201cA\u201d model used by British Airways had a design specification range of 3690 miles, had to regularly fly 4250 miles on a route between London Heathrow and Barbados. This was made possible due to operational improvements that pushed the range of Concorde \u2018A\u2019 to nearly 4500 miles. The improvements have included small changes to the aerodynamics of the original model\u2019s specifications. One interesting fact is that the take-off weight was made very low and close to the figures estimated for the Concorde \u2018B\u2019 design. \u00a0 The Concorde \u2018B\u2019 design would of also benefited from increased subsonic performance and reduced noise emissions. The cost of the Concorde Project was massive and with the poor sales of Concorde, and cancelled options from airlines, adding to that the rising cost of aviation fuel during the 1970s, the development of the Model \u2018B\u2019 version was considered too expensive and cancelled. Although the study carried out was a pretty comprehensive one and could of given Concorde a real future in during the years to come right into the 1990s and even on into the 2000s, after this time it was generally expected that a new generation SST with a new type of variable cycle engines would enter into service (BAe AST3 or Aerospatiale Alliance) \u00a0 The study into a Concorde \u2018B\u2019 design had two aims: \u00a0 1. To ensure the expansion and future demand for supersonic transport (SST), where the Anglo-French group was now and into the future as the main and only player, \u00a0 2. To maintain the high knowledge level gained by the manufacturers in Britain and France, and to provide a solid position for the participation in a future program of a second-generation SST. \u00a0 \u00a0 This feasibility study, was planned to last 9 months and was estimated to cost 9 million French francs, it was to comprise three areas: \u00a0 1. Engineering \u00a0 2. Development costs \u00a0 3. Markets \u00a0 If this exploratory and feasibility study was to confirmed an economic interest for the manufacturers, and then led to the decision of the launch of an improved version of Concorde, such an improved version (allowing for a 5 year development programme) could be ready by spring 1982 for the 17th production Concorde 217 \u00a0 Civil aviation history shows that almost all new aircraft constituted a base point for the start of improved versions (The Boeing 747-100 evolved into today\u2019s 747-400) and at this stage this was the plan for the Concorde program. \u00a0 The interest in this development process would have been beneficial to both the airlines and the manufacturers of Concorde: \u00a0 1. For the airlines, it would have offered performance improvements (lower direct operation costs, extension of the operating range, and reduction of environmental effects) while conserving the existing investments in crew training, maintenance procedures, etc. \u00a0 2. For the manufacturers, it would have made it possible to carry out these improvements at a minimum capital cost. Indeed the development of the initial production version generally revealed aerodynamic areas where gains could be made along with structural margins, but these could not be exploited due to the time constraints in getting Concorde into passenger service successfully. \u00a0 3. If the decision to build the B model would have been taken, the modifications would have been relatively inexpensive as they were just some minor changes to the existing production process, allowing the majority of the tooling to be maintained. The high level of knowledge that was gained during the certification of the current model would have greatly reduced time and costs during the certification of the B model. \u00a0 These considerations should have applied particularly to the case of Concorde, considering the exceptional degree of innovation obtained and the great amount of technical knowledge accumulated during the twelve years of development of the initial production version. \u00a0 The broad objectives of the Concorde \u2018B\u2019 version were to ensure the expansion of the network of routes that supersonic aircraft could use. \u00a0 The following improvements were considered to be necessary: \u00a0 Although the level of noise produced by Concorde at takeoff and landing is equivalent to that of the first generation long haul aircraft in service (B 707, DC8), only the second generation of long haul aircraft (B747, DC10, L1011) equipped with high-bypass jet engines satisfied the new international noise rules. With the reaction of the United States, which had at the start of scheduled Concorde services not accepted the use of Concorde on their territory, it would be important to reduce the level of noise generated by the aircraft. The operating range of the initial version \u2013 primarily designed for the connection Paris London-New York \u2013 was to be increased to allow connections of the type: \nOther European capital cities \u2013 East Coast of the US in one sector. \nUnited States \u2013 Japan in two sectors. \nEurope \u2013 Australia in three sectors. \u00a0 Concorde\u2019s fuel consumption accounts for a third of the direct operating cost (DOC). A reduction in fuel consumption would mean an improvement in economics for the airlines using the aircraft, making it even more marketable by the manufacturers, and also enable the airlines to reduce ticket prices. \u00a0 The objective of noise reduction implies an increase in the smoothness of flight during takeoff and landing, which also results in an improvement in all subsonic flight modes (climb, subsonic cruise, approach). \u00a0 This would also help in the above objective of increasing the operating range. \u00a0 This modification must respect two constraints: to preserve \u2013 if not improve \u2013 the supersonic smoothness of flight, and to limit the effects from modifications or additions on the central core structure of the wing, in order to re-use the majority of the tooling currently used in manufacture and assembly. A moderate increase in the range could be obtained by aerodynamic tweaks to the current design. These included lengthening the wing tips and mounting droop slats on the leading edges of the wings. These tweaks would reduce the induced drag at supersonic speeds and increase the available lift at slower speeds. \u00a0 The additional lift generated by the leading edge droops would permit the aircraft the fly at a lower angle of attack at slower speeds, therefore requiring less power to be generated by the powerplant, which in turn would reduce noise and increase fuel efficiency. \u00a0 \u00a0 Optimisation of twist and camber of the wing, combined with the increase in the lift coefficient (Cz) along with the increased thrust offered by the supersonic engine also allows improvements of the smoothness of flight at Mach 2. \u00a0 Detailed aerodynamic improvements, (reshaped trailing edge of the control surfaces and thinning of the lower lips of air intake) which were later applied to the current production models before they entered service, were also proposed to be continued on the Concorde\u00a0\u2019B\u2019 \u00a0 The majority of the noise produced by Concorde\u00a0during \u00a0takeoff and landing comes from the areas of strong aerodynamic shearing, which are\u00a0located at the edge of the exhaust system. \u00a0 The powerplant, which is optimised for supersonic cruise rather than subsonic flight would be modified so that gains could be made throughout the whole speed range during flight, and Specific gains could then be made in the fuel consumption in the transonic region, thus then giving an increase in the operating range required. Physically, the modifications would consist of replacing the low-pressure compressor with a compressor with a increased diameter, and the low pressure turbine assembly with a two-stage turbine. \u00a0 Then the installation of a discharge system to increase the margin of air flow through the engine would result in an increase in air flow which reaches 25 % on takeoff and 35 % during approach. The thrust gains obtained at takeoff and at transonic speeds could also make it possible to remove the reheat (afterburner) system with its very heavy fuel consumption and significant addition to the noise generated by the powerplant. \u00a0 The increase of capacity obtained by the enlarging of the external wing and the tank at the front of the wing could be supplemented by the addition of a fuselage tank connected to the latter. \u00a0 The maximum quantity of fuel that can be put on board increases from 95,254 kg to 99,790 kg. \u00a0 Changes would have been incorporated in the autopilot system for the takeoff and approach stages, in order to automatically optimise the aircraft in these key stages of flight and to reduce the noise levels around the airports during takeoff and landing. \u00a0 \u00a0 \u00a0 The additional wing area along with the modifications to the engines and intakes would add to the empty weight of the aircraft: The reductions would have been obtained mainly by the use of carbon fibre in the construction of control surfaces, service doors, etc. \u00a0 The increase in the empty weight and the fuel carrying capability also requires an increase in the various performance characteristics (a payload of 24,800lbs\/11260kg is used). Why not join in with\u00a0discussions on the\u00a0latest Concorde developments Our Facebook forum is where we discuss in detail our current projects, share photo's and where fans of the aircraft can ask questions direct to the engineering team. We are proud to be associated with both Brooklands restoration and the Le Bourget Conservation team so the pool of knowledge is immense. Many of our engineers have years of knowledge of working on the aircraft. So like our site, join our forum and follow us on Twitter. \u00a9 2014 Stephen de Sausmarez & Heritage Concorde.","time":1525703342,"title":"Concorde \u2018B\u2019","type":"story","url":"https:\/\/www.heritageconcorde.com\/concorde-b"},{"by":"beefhash","descendants":1,"id":17012929,"kids":"[17013145]","score":7,"text":"Backdoored Python Library Caught Stealing SSH Credentials Office 365 Zero-Day Used in Real-World Phishing Campaigns Hacker Shuts Down Copenhagen\u2019s Public City Bikes System PoC Developed for CoinHive Mining In Excel Using Custom JavaScript Functions Backdoored Python Library Caught Stealing SSH Credentials Hacker Shuts Down Copenhagen\u2019s Public City Bikes System PoC Developed for CoinHive Mining In Excel Using Custom JavaScript Functions \"Hide and Seek\" Becomes First IoT Botnet Capable of Surviving Device Reboots Skype Classic GPU-Z InsaneCrypt (desuCrypt) Decrypter GIBON Ransomware Decryptor AdwCleaner ComboFix RKill Junkware Removal Tool Remove the FastDataX.exe Trojan DNS Unlocker & DNSUnlocker Ads Removal Guide (2018 Update) Remove the Watch Folder Trojan Downloader Remove the ExpertChange PUP Remove Security Tool and SecurityTool (Uninstall Guide) How to remove Antivirus 2009 (Uninstall Instructions) How to Remove WinFixer \/ Virtumonde \/ Msevents \/ Trojan.vundo How to remove Google Redirects or the TDSS, TDL3, or Alureon rootkit using TDSSKiller Locky Ransomware Information, Help Guide, and FAQ CryptoLocker Ransomware Information Guide and FAQ CryptorBit and HowDecrypt Information Guide and FAQ CryptoDefense and How_Decrypt Ransomware Information Guide and FAQ How to Change Your Twitter Password How to Setup Login Verification in Twitter How to Use Cortana As Your Virtual Assistant in Windows Restrict What Personal Data Is Shared on the Facebook API Platform How to start Windows in Safe Mode How to remove a Trojan, Virus, Worm, or other Malware How to show hidden files in Windows 7 How to see hidden files in Windows eLearning IT Certification Courses Gear + Gadgets Security  A new service called GDPR Shield is making the rounds this week and for all the wrong reasons. The service, advertised as a piece of JavaScript that webmasters embed on their sites, blocks EU-based users from accessing a website, just so the parent company won't have to deal with GDPR compliance. GDPR, or General Data Protection Regulation, is a new user and data privacy regulation slated to come into effect in the EU three weeks from now, on May 25, 2018. The new regulation brings a wealth of protections to user privacy but is a nightmare for companies doing business in Europe. The reasons are plenty, but the humongous fines for failing to meet GDPR standards are at the top of the list for most companies (\u20ac20 million\/$24 million or 4% of a company's annual worldwide revenue \u2014whichever is higher). There's also the 72-hour deadline to reveal data breaches and the necessity of hiring a so-called \"Data Protection Officer.\" Plus, GDPR also mandates that companies must inform users on what data they collected about them, allow them to review the data, and even let users delete the data from the company's servers if they so wish. Any company that has data on EU users is subject to the new GDPR regulation and can be fined, regardless if the company is not based in a EU state. As such, smaller companies that can't afford the exorbitant (consultation, legal, and technical) costs of becoming GDPR compliant, are hoping that nobody notices they're breaking the law or pulling out of the EU market altogether. Examples of companies and services that have withdrawn from the EU market because of GDPR include Verve (online marketing), Ragnarok Online (online game), Super Monday Night Combat (online game), Unroll (email subscription service), Brent Ozar Unlimited (software supplier), Tungle (gaming software provider), and Drawbridge (cross-device identity service) The list is probably bigger, as not all companies have made their decision public. Apart from this, there are also the companies that had no intent on breaking into the EU market but are serving customers regardless, and as such, are also falling under the GDPR umbrella. Here, a new trend has sparked \u2014blocking \"unwanted\" EU customers from accessing their sites in the first place. A company that has openly admitted to such a practice is Boston-based cyber-security firm Steel Root, which has implemented its own system that blocks EU-based users from accessing its service. But running such a system is not an option for companies with no experience in managing IP blacklists. Here's where the makers of GDPR Shield [archived link] have seen a business opportunity. \"Block EU users from accessing your site,\" the GDPR Shield website reads. \"Don't spend thousands on legal fees to make your site GDPR-compliant. If you aren't targeting EU users, simply use GDPR Shield to block all traffic from the EU,\" the company boasts. The GDPR Sheild service is not free, though, and sites that want to use it have to pay monthly fees from $9 upward. Similar services are bound to pop up on the web in the coming days, similar to how tens of websites appeared after the EU passed its infamous Cookie Law that mandated that each website ask users for permission before storing cookies on their devices. That useless EU regulation generated an influx of similarly useless popups all over the web, and the new GDPR regulation might have the unintended consequence of shutting out millions of EU users off of thousands or more websites owned by companies that are not in the mood of spending thousands of dollars to become GDPR compliant. DDoS Attacks Go Down 60% Across Europe Following WebStresser's Takedown Brexit: European Commission Wants to Cancel 317,000 .eu Domains Owned by Brits All fine and dandy as long as you have never had an EU Citizen on your site before or you start a new company now or delete everything out of your logs, databases, big data, IoT, third party feeds, otherwise your still at the mercy of GDPR. Just an FYI. And how will you handle EU Citizens logging on their computers from IP addresses that cannot be determined to be or not to be an EU location? Just curious. I think its a great idea for people going to websites but still has NO impact on those doing business with EU Citizens The question I have is whether or not blocking EU users will actually help spread awareness about how overreaching the law is, or if it will just cause a bunch of people to demand that the EU government \"force\" sites that are blocking EU users to stop doing so and comply with the law. If it's the former, then let the rest of the world IP block Europe until the law is repealed. It'll break the Internet for a little while, but I really can't think of a more effective protest. Well, great tools for all those wh want to collect, steal and abuse the users data. While GDPR requires some actions to be withdrawn, it is a pretty good solution if you want to use their data to have an impact on another US elections without risk of being caught on spying the EU Citizens.\n\nHaving such a tool few days ago, the Cambridge Analytica would not cease activities, just move their files to US. I follow Bleeing Computer because of the focus it have on threats to me and my data, partly in terms of ransomewarem partly in terms of other attacks or substandard intrusion protections. One would think this is a matter of the readers.\n\nYet to my dismay the reaction I see about the European GDPR is that it is bad and a problem when it actually prohibits things like Cambreige Analytica did together with Facebook and enables victims to be able to press charges and therefore should be welcomed. \n\nWhat GDPR does is to secure that I know where my information is, for what purpose it is collected, who else is allowed to know where it is and that the responsible organization keeps it safe. That's the essence. It also give me some rights; I can require an update of faulty information or that my information is deleted. This is not unreasonable demands on those that have a great insight in my private life. \n\nGDPR is for example the reason we now know that PayPall is sharing your information with 600+ companies, a well kept until recently. (ref Bruce Schneier). \n\nGDPR also makes it perfectly clear; while personal information shall be well protected it shall be exchangeable between actors and used to create value. This is from the first paragraph;\n\"The free movement of personal data within the Union shall be neither restricted nor prohibited for reasons connected with the protection of natural persons with regard to the processing of personal data.\"\n\nI my self welcome GDPR and are looking forward to finally get some mandate to require other to keep my personal information safe. This is inline with what I talk about publicly. Of all the crap that comes out from EU, GDPR for one is a great regulation. The market of personal information has been to big to long. \n\nNaturally the change will cost money. Every company in the world with some economical size spend quite a lot of money on a finance department, auditors etc. That is both to secure that own financial assets but also to secure that it is managed within the lawful borders. The very same will now apply to other valuable assets - the information that is stored about customers. \n\nWhat need to be asked now is; do I need to collect this piece of information and for what purpose do I then collect it. \n\nIt is only reasonable to treat my personal information well and keep it safe from eavesdropping. \n\n\nI think it is much more troublesome that US companies need to share their information with US law enforcement regardless where it is located. I now need to find another provider than Google for my companies mail etc.  My company Steel Root is mentioned in this article as blocking EU-based visitors from our website. That is true, but we don't do it explicitly for GDPR as this article suggests.\n\nSee our blog, \"Is blocking European visitors to your website a valid GDPR strategy?\" for further thoughts on the subject: https:\/\/steelroot.us\/is-blocking-european-visitors-to-your-website-a-valid-gdpr-strategy\/\n\nThis article appears to have been sourced from Twitter, where a GDPR thread posted by @mikko went viral over the weekend. There's some good content on that thread - may I suggest this article cite its source? Uh these services are a scam. This treaty follows the CITIZEN not the physical location. \n\nI didn't understand this either until I meet with a lawyer who helped create the law in a conference. As a CISO healthcare company found out if an EU person walks into your US hospital you fall under GDPR once you take their data even though your hospital does not have a footprint in the EU. \n\nSo I would tell any company looking at a service like this, it will only limit both your risk and your business. IT WILL NOT PROTECT you from GDPR. \n\nAlso from the enforcement side the EU is looking at Google, Microsoft, and Facebook. They will be sued on day one and the fallout of those cases will determine how this will affect everyone else.  The scope is even wider than that. It concerns EU citizens alright, but it also concerns US (and other) citizens visiting EU during the stay. If Trump would visit EU information about him would temporary fall under GDPR. \n\nIn general it is a misunderstanding that GDPR is an IT concern. It is as much a Business concern. It is more about what the business decide to do with the information than encryption and intrusion detection. Naturally it is important to know what information is stored in the IT systems and to keep the risks low but that does not have anything to do with the purpose of storing the information in the first place. The purpose is one of the key elements in GDPR.  Not a member yet? Register Now Microsoft Adds Support for JavaScript Functions in Excel Office 365 Zero-Day Used in Real-World Phishing Campaigns To receive periodic updates and news from BleepingComputer, please use the form below.  Malwarebytes Anti-Rootkit Malwarebytes for Mac Malwarebytes Anti-Malware AdwCleaner Windows Repair (All In One) User Agreement -  Privacy Policy Copyright @ 2003 - 2018  Bleeping Computer\u00ae LLC  - All Rights Reserved Not a member yet? Register Now Learn more about what is not allowed to be posted.","time":1525702793,"title":"New Service Blocks EU Users So Companies Can Save on GDPR Compliance","type":"story","url":"https:\/\/www.bleepingcomputer.com\/news\/security\/new-service-blocks-eu-users-so-companies-can-save-thousands-on-gdpr-compliance\/"},{"by":"joebaf","descendants":1,"id":17012823,"kids":"[17019264]","score":10,"text":"C++ and native programming stories.  Let\u2019s take a pair of two types <YourType, bool> - what can you do with such composition? In this article, I\u2019ll describe std:optional - a new helper type added in C++17. It\u2019s a wrapper for your type and a flag that indicates if the value is initialized or not. Let\u2019s see where it can be useful and how you can use it.  By adding the boolean flag to other types, you can achieve a thing called \u201cnullable types\u201d.  As mentioned, the flag is used to indicate whether the value is available or not. Such wrapper represents an object that might be empty in an expressive way (so not via comments :)) While you can achieve \u201cnull-ability\u201d by using unique values (-1, infinity, nullptr), it\u2019s not as clear as the separate wrapper type. Alternatively, you could even use std::unique_ptr<Type> and treat the empty pointer as not initialized - this works, but comes with the cost of allocating memory for the object.  Optional types - that come from functional programming world - bring type safety and expressiveness. Most of other languages have something similar: for example std::option in Rust, Optional<T> in Java, Data.Maybe in Haskell. std::optional was added in C++17 and brings a lot of experience from boost::optional that was available for many years. Since C++17 you can just #include <optional> and use the type. Such wrapper is still a value type (so you can copy it, via deep copy). What\u2019s more,  std::optional doesn\u2019t need to allocate any memory on the free store. std::optional is a part of C++ vocabulary types along with std::any, std::variant and std::string_view. Usually, you can use an optional wrapper in the following scenarios: I like the description from boost optional which summarizes when we should use the type: From the boost::optional documentation: When to use Optional It is recommended to use optional<T> in situations where there is exactly one, clear (to all parties) reason for having no value of type T, and where the lack of value is as natural as having any regular value of T While sometimes the decision to use optional might be blurry, you shouldn\u2019t use it for error handling. As it best suits the cases when the value is empty and it\u2019s a normal state of the program. Here\u2019s a simple example of what you can do with optional: In the above code we define a function that returns optional containing a string. If the user\u2019s nickname is available, then it will return a string. If not, then it returns nullopt. Later we can assign it to an optional and check (it converts to bool) if it contains any value or not. Optional defines operator* so we can easily access the contained value. In the following sections you\u2019ll see how to createstd::optional, operate on it, pass around and even what is the performance cost you might want to consider. This article is part of my series about C++17 Library Utilities. Here\u2019s the list of the other topics that I\u2019ll cover: Resources about C++17 STL: OK, so let\u2019s move to std::optional. There are several ways to create std::optional: As you can see in the above code sample, you have a lot of flexibility with the creation of optional. It\u2019s very simple for primitive types and this simplicity is extended for even complex types. The \u201cin_place\u201d construction is especially interesting, and the tag std::in_place is also supported in other types like any and variant. For example, you can write: This saves the creation of a temporary Point object. I\u2019ll address std::in_place later in a separate post, so stay tuned. If you return an optional from a function, then it\u2019s very convenient to return just std::nullopt or the computed value. In the above example you can see that I return std::string computed from input.asString() and it\u2019s wrapped in optional. If the value is unavailable then you can just return std::nullopt. Of course, you can also declare an empty optional at the beginning of your function and reassign if you have the computed value. So we could rewrite the above example as: It probably depends on the context which version is better. I prefer short functions, so I\u2019d chose the first option (with multiple returns). Probably the most important operation for optional (apart from creation) is the way how you can fetch the contained value. There are several options: To check if the value is present you can use has_value() method or just check if (optional) as optional is automatically converted to bool. Here\u2019s an example: So the most useful way is probably just to check if the value is there and then access it: Let\u2019s see what are other operations on the type: If you have existing optional object, then you can easily change the contained value by using several operations like emplace, reset, swap, assign. If you assign (or reset) with a nullopt then if the optional contains a value its destructor will be called. Here\u2019s a little summary: The code is available here: @Coliru std::optional allows you to compare contained objects almost \u201cnormally\u201d, but with a few exceptions when the operands are nullopt. See below: The above code generates: The code is available here: @Coliru Here are two a few longer examples where std::optional fits nicely. The code is available here: @Coliru The code is available here: @Coliru The above code uses optional to indicate if we performed the conversion or not. Note that we in fact converted exceptions handling into optional, so we skip the errors that might appear. This might be \u201ccontroversial\u201d as usually, we should report errors. When you use std::optional you\u2019ll pay with increased memory footprint. At least one extra byte is needed. Conceptually your version of the standard library might implement optional as: In short optional just wraps your type, prepares a space for it and then adds one boolean parameter. This means it will extend the size of your Type according do the alignment rules. There was one comment about this construction: \"And no standard library can implement optional this way (they need to use a union, because constexpr)\". So the code above is only to show an example, not real implementation. Alignment rules are important as The standard defines: Class template optional [optional.optional]: \n  The contained value shall be allocated in a region of the optional storage suitably aligned for the type T. For example: While bool type usually takes only one byte, the optional type need to obey the alignment rules and thus the whole wrapper is larger than just sizeof(YourType) + 1 byte. For example, if you have a type like: it will take more space than when you use your custom type: In the first case, we\u2019re using 32 bytes! The second version is 24 bytes. Test code using Compiler Explorer Here\u2019s a great description about the performance and memory layout taken from boost documentation: Performance considerations - 1.67.0. And in Efficient optional values | Andrzej\u2019s C++ blog the author discusses how to write a custom optional wrapper that might be a bit faster I wonder if there\u2019s a chance to do some compiler magic and reuse some space and fit this extra \u201cinitialized flag\u201d inside the wrapped type. So no extra space would be needed. std::optional was adapted directly from boost::optional, so you should see the same experience in both versions. Moving from one to another should be easy, but of course, there are little differences. In the paper: N3793 - A proposal to add a utility class to represent optional objects (Revision 4) -  from 2013-10-03 I\u2019ve found the following table (and I tried to correct it when possible with the current state). While you can use optional on any type you need to pay special attention when trying to wrap boolean or pointers. std::optional<bool> ob - what does it model? With such construction you basically have a tri-state bool. So if you really need it, then maybe it\u2019s better to look for a real tri-state bool like boost::tribool. Whet\u2019s more it might be confusing to use such type because ob converts to bool if there\u2019s a value inside and *ob returns that stored value (if available). Similarly you have a similar confusion with pointers: The pointer to int is naturally \u201cnullable\u201d, so wrapping it into optional makes it very hard to use. Uff\u2026 ! it was a lot of text about optional, but still it\u2019s not all :) Yet, we\u2019ve covered the basic usage, creation and operations of this useful wrapper type. I believe we have a lot of cases where optional fits perfectly and much better than using some predefined values to represent nullable types. I\u2019d like to remember the following things about std::optional: In the next article I\u2019ll try to explain error handling and why optional is maybe not the best choice there. I\u2019d like to thank Patrice Roy (@PatriceRoy1), Jacek Galowicz (@jgalowicz) and Andrzej Krzemienski (akrzemi) for finding time do do a quick review of this article! Get my free ebook about C++17! More than 50 pages about the new Language Standard.  For now I don't have my own courses, but I promote others :) (Please note, I'll also get a little commission for every signup. That's a huge support for my work!). \nHave a look my recommended Online Courses at @Pluralsight (more info in my Resource page): \n My name is Bartek, I'm a programmer from Cracow\/Poland. This is my blog about C++ and native coding... more...\n \n\n\n\n\n","time":1525702074,"title":"Using C++17 std::optional","type":"story","url":"https:\/\/www.bfilipek.com\/2018\/05\/using-optional.html"},{"by":"mathieupassenau","descendants":28,"id":17012814,"kids":"[17016143, 17014404, 17013982, 17019864, 17017375, 17018661, 17023827, 17013609, 17013790, 17014984]","score":110,"text":"   Previously I talked about a LED box. I explained how to\noperate a ws2812 led strip. Thoses strips can be connected together in\nserial. \nAfter a first try one year ago, I built this clock from scratch with\n360 leds, divided in 3 parts.   My first try was not a success. I bought some 1cm wide bars.\nThose aluminium bars can be easily bent in circles. However it is\nimpossible to have a perfect circle. If the circle is wide the shape\nseems good. With smaller circles (diameter < 50cm) it looks bad.\n  Back to the basis : wood circles ! With a jigsaw (thanks\n@bluxte) and a simple wire it is the best way for perfect circles. I\nlearned that at the age of 6 :-). I made 3 concentric circles : one\nwith 60 leds, a second with 120 and the last have 180 leds.     There is 60 leds per meter on this strip. I need a 31,8cm\ndiameter circle (100 \/ 3,14). I glued the strip on the edge. Behind I removed some wood where the wires reach. On the final\nresult, no wires are visible. Wood circles are glued together after wiring. Remember for\nnext time : painting will be far easier before gluing leds... ws2812 need a 5 volts power supply, with 20mA consumption per\nLED. 360x0.02 = 7.2 A so 36W ! It may be very bright ! I found a 50w\npower supply on Amazon. I have 3 separated strips. Each strip is powered by 2 points\non each end.\u00a0\nOn my first mount, I soldered 2 wires (+5v and GND) at the begining of\nthe strip. A strip with a length greater than 2 meters need a redundant\npower.\u00a0 The wide circle have LEDs from 1 to 180, the mid 181 to 300\nand the smallest 301 to 360. Signal wire is plugged on a PWM output on a raspberry\npi.\u00a0  Get the library and install it : https:\/\/github.com\/jgarff\/rpi_ws281x Example files written in python are great for testing. Put the\nright configuration :\u00a0  Mounted on the wall :         ","time":1525702052,"title":"A giant 360 LED clock","type":"story","url":"https:\/\/www.mathieupassenaud.fr\/ledclock\/"},{"by":"okket","descendants":37,"id":17011939,"kids":"[17012329, 17028044, 17012601]","score":232,"text":"The Erlang\/OTP team at Ericsson, the implementors and maintainers of Erlang\/OTP. This blog post is the first about the Core Erlang format. In this\nblog post, we introduce the Core Erlang format through examples\nthat compare Erlang code to the corresponding Core Erlang\ncode. I used the following command to translate my example module to\nCore Erlang code: The previous blog post\nexplored the passes from parse_module to expand_records. The\ncore passes translates from the abstract code to Core Erlang. We\nwill talk more about the Core Erlang passes in future blog posts. I have slightly edited the examples to make them somewhat easier to\nread. There will be an unedited example at the very end of this blog post. There\u2019s a lot to cover, so let\u2019s get started! Let start with the simplest possible function, a function with no\narguments returning an atom: In Core Erlang, that will be: From that example, we can work out the following principles: Atoms are always quoted. Naming of the function has been separated from implementation\nof the function. The body of a fun is not followed by an end as in Erlang. Here is as slightly more complicated function: In Core Erlang: Note: All examples were compiled with OTP 20. The name of the\ngenerated variables will be different in the upcoming OTP 21. Essentially, variables are named as in Erlang. In the translation\nto Core Erlang, the compiler generates new variable names for the\narguments in a function head. The following code is also valid\nCore Erlang: Here is a function with more than one clause: In Core Erlang: A fun can only have a single clause. Pattern matching must be done in a case, not in the fun head. Guards are mandatory for each clause in a case. _ is not a valid variable name in Core Erlang. Uninteresting\nvalues must be bound to a new variable. The < and > around the patterns will be explained soon. In Erlang, multiple function clauses can also be written with a\ncase like this: The Core Erlang code will be essentially the same as the Core Erlang\ncode for a\/1: Let\u2019s try multiple arguments: In Core Erlang: < and > denote a value list. The patterns in each clause in\nthe case are always part of a value list. The case expression is\na value list unless there is only one expression. Operators such as + are not part of the Core Erlang language,\nso the compiler has translated the use of + to a call to the\nBIF erlang:'+'\/2. Let\u2019s see how if is implemented: In Core Erlang: In Erlang, a variable can be repeated in a clause or within a\npattern to indicate that the values must be the same: Core Erlang does not allow repeating a variable: This function will fail with a function_clause exception if it is called\nwith any other value than 42: In Core Erlang: A case in Core Erlang must not fall off at the end, that is,\nthere must always be a clause that will match. In this example, the last clause with a variable pattern and\na true guard is guaranteed to match. The body for the last clause calls a primop to generate\na function clause exception. Primops are primitive operations\nprovided by the Erlang implementation, but not specified in the\nCore Erlang language specification. Here is a similar function excepts that is uses case and therefore\nwill generate a case_clause exception if called with any other\nargument than 42: The Core Erlang code is similar to the code for e\/1: Let\u2019s rewrite this function one more time: In Core Erlang: Here is a function that binds the variable I: In Core Erlang: apply calls a fun or local function. The return value of the apply is bound to the variable I. The variable I can only be used in the code that follows the\nin keyword. The variable name is in a value list. That is because let\ncan bind several variables at once. Erlang has essentially no scoping. When a variable has been bound,\nit remains bound to the end of the function. For example, variables bound\nin a case can be used after the case: In Core Erlang: A case in Core Erlang does not export any variables. All variables\nthat are to be used after the case must be explicitly returned. In this example, the first two clauses of the case return a\nvalue list with three values. The first value is the return value\nof the case, which in this case is ignored. The other two values are\nthe values assigned to the X and Y variables, respectively. The values returned from the case is bound in the let. The ignored\nreturn value is bound to a new variable (_@c7), which is never used.\nThe exported values are bound to the X and Y variables. So far all Core Erlang examples have been edited to make the points\nI am trying to make stand out clearer. Let\u2019s have a look at the unedited\nversion of a previous example: The -| associates an annotation with a Core Erlang construct.\nThe meaning of an annotation is not specified in the Core Erlang\nlanguage specification. The compiler_generated annotation associated with the last clause\nis a hint added by the compiler that subsequent optimization passes should\nnot generate a warning if the clause was found to never match and dropped. The comment \u201cLine 33\u201d at the beginning is actually an annotation that\nthe pretty printer has turned into a comment to avoid rendering the\npretty-printed code unreadable. Core Erlang is less complicated than Erlang, and is therefore more\nsuited than the abstract format for code analyzing tools (such as\nDialyzer) and optimizers. All details can be found in Core Erlang 1.0.3 language specification.","time":1525693234,"title":"Core Erlang by Example","type":"story","url":"http:\/\/blog.erlang.org\/core-erlang-by-example\/"},{"by":"cfadvan","descendants":5,"id":17011901,"kids":"[17018621, 17020552, 17016692]","score":69,"text":"May 3, 2018 Olena Shmahalo\/Quanta Magazine Senior Writer May 3, 2018 Almost thirty years ago, a group of physicists noticed some of the most important numbers in mathematics appearing where they didn\u2019t seem to belong. A new proof finally explains why they\u2019re there. The work, which is still unpublished, is by four leading mathematicians in the field of mirror symmetry. It explains why the so-called zeta values \u2014 numbers that have preoccupied mathematicians since the mid-18th century \u2014 are implicated in the numerical mystery at the heart of one of the most active fields in contemporary mathematics. \u201cOur work gives some kind of geometric explanation for the origin of these strange numbers,\u201d said Nick Sheridan, a research fellow at the University of Cambridge and co-author of the work. The zeta values are numbers generated by taking an infinite sum. For example, zeta of 2 is equal to 1 + 1\/22 + 1\/32 + 1\/42 + \u2026 , while zeta of 3 is equal to 1 + 1\/23 + 1\/33 + 1\/43 + \u2026. The zeta values appear in many areas of mathematics, including, most famously, the Riemann hypothesis, which relates to the distribution of prime numbers. As I explained in my recent feature story on the state of mirror symmetry, \u201cMathematicians Explore Mirror Link Between Two Geometric Worlds,\u201d the field was discovered by accident. In the early 1990s, physicists were trying to figure out the details of string theory. They wanted to explain the physical world as a product of tiny, vibrating strings woven through an additional six dimensions of space. They tried to understand what the geometry of those six dimensions might be. The first option came from the mathematical field of algebraic geometry; a second one came from the mathematical field of symplectic geometry. To the trained mathematical eye, the two could hardly have seemed more different. And yet, the physicists noticed some strange similarities between them. In particular, when they performed a calculation on one space, they generated numbers that matched the numbers they generated when they performed a very different type of calculation on the other side. \u201cTwo things that looked, in principle, unrelated, magically were equal,\u201d said Denis Auroux, a mathematician at the University of California, Berkeley. Mathematicians and physicists began excavating the mirror relationship. They soon built increasingly abstracted mathematical entities atop the foundations of the underlying symplectic and complex geometric spaces. You can think of these more abstract mathematical entities as houses whose architecture reflects the foundations they\u2019ve been built on. In the setting of mirror symmetry, points on the house whose coordinate values previously were integers become points whose coordinate values are now multiples of different zeta values. The process effectively rotates the space. \u201cIt\u2019s been rotated, and the amount it\u2019s been rotated by maybe will involve some of these zeta values,\u201d said Sheridan. Mathematicians have noticed the presence of zeta values almost since the beginning of the study of mirror symmetry. \u201cThe arithmetic is fascinating and has been explored in a lot of examples, but it\u2019s missing a conceptual explanation. We\u2019ve been trying to get more of a conceptual explanation,\u201d said Sheel Ganatra, a mathematician at the University of Southern California and co-author of the new work along with Sheridan, Mohammed Abouzaid of Columbia University and Hiroshi Iritani of Kyoto University. This new work explains why the zeta values are there. The explanation has to do with intrinsic geometric features of the two sides of mirror symmetry. A foundational question in mirror symmetry, called the SYZ conjecture, says it should be possible to take one mirror space, break it down into pieces, manipulate those pieces, and then use them to construct the second mirror space. It\u2019s as though you had a big shape made of Legos, took it apart, and used the pieces to build something new. When you break down the first space into Lego-like pieces, most of the pieces will be the same, but there will also be some special blocks \u2014 the odd green or yellow piece in a sea of reds and blues. In their new work, the mathematicians prove that each kind of special piece is associated to a zeta value. Maybe the green blocks are associated to zeta of 2, and therefore if you have five greens when you take apart your first mirror space, the structure atop your rebuilt mirror space will have its coordinates offset by a factor of five times zeta of 2. In this new work, the four mathematicians use techniques from a field called tropical geometry. Using those techniques, they prove that these \u201cspecial pieces\u201d explain why numbers on opposite sides of the mirror differ by exactly a factor of zeta values. So far, their proof holds for many cases of mirror symmetry. The authors are waiting until they\u2019ve been able to prove even more cases before they make the proof public. The work is also emblematic of an overall trend in mirror symmetry. The field began in revelation and is advancing rapidly toward understanding. Instead of simply cataloging mysterious phenomena \u2014 these sets of numbers match! \u2014 mathematicians are beginning to really explain why mirror phenomena occur at all. Get Quanta Magazine delivered to your inbox Senior Writer May 3, 2018 Get Quanta Magazine delivered to your inbox Get highlights of the most important news delivered to your email inbox Quanta Magazine moderates comments to\u00a0facilitate an informed, substantive, civil conversation. Abusive, profane, self-promotional, misleading, incoherent or off-topic comments will be rejected. Moderators are staffed during regular business hours (New York time) and can only accept comments written in English.\u00a0","time":1525692748,"title":"Three Decades Later, Mystery Numbers Explained","type":"story","url":"https:\/\/www.quantamagazine.org\/three-decades-later-mystery-numbers-explained-20180503\/"},{"by":"camtarn","descendants":7,"id":17011849,"kids":"[17015915, 17015329, 17015762]","score":83,"text":"[Make Caows and Shapcho - MeganAnn] [Pitsilised Koekirjad Cushion Sampler Poncho - Maeve] [Lacy 2047\u00a0-\u00a0michaela112358] I use algorithms called neural networks to write humor. What\u2019s fun about neural networks is they learn by example - give them a bunch of some sort of data, and they\u2019ll try to figure out rules that let them imitate it. They power corporate finances, recognize faces, translate text, and more. I, however, like to give them silly datasets. I\u2019ve trained neural networks to generate new\u00a0paint\u00a0colors, new\u00a0Halloween costumes, and new\u00a0candy heart messages. When the problem is tough, the results are mixed (there was that one candy heart that just said HOLE). One of the toughest problems I\u2019ve ever tried? Knitting patterns. I knew almost nothing about knitting when\u00a0@JohannaB@wandering.shop\u00a0sent me the suggestion one day. She sent me to the\u00a0Ravelry knitting site, and to its adults-only, often-indecorous\u00a0LSG forum, who as you will see are amazing people. (When asked how I should describe them, one wrote \u201cdon\u2019t forget the glitter and swearing!\u201d) And so, we embarked upon\u00a0Operation Hilarious Knitting Disaster. The knitters helped me crowdsource a dataset of 500 knitting patterns, ranging from hats to squids to unmentionables. JC Briar exported another 4728 patterns from\u00a0the site\u00a0stitch-maps.com.\u00a0 I gave the knitting patterns to a couple of neural networks that I collectively named \u201cSkyKnit\u201d. Then, not knowing if they had produced anything remotely knittable, I started posting the patterns. Here\u2019s an early example. MrsNoddyNoddy wrote, \u201cit\u2019s difficult to explain why 6395, 71, 70, 77 is so asthma-inducingly funny.\u201d (It seems that a 6000-plus stitch count is, as GloriaHanlon put it,\u00a0\u201coptimism\u201d).\u00a0 As training progressed, and as I tried some higher-performance models, SkyKnit improved. Here\u2019s a later example. Even at its best, SkyKnit had problems. It would sometimes repeat rows, or leave them out entirely. It could count rows fairly reliably up to about 22, but after that would start haphazardly guessing random largish numbers. SkyKnit also had trouble counting stitches, and would confidently declare at the end of certain lines that it contained 12 stitches when it was nothing of the sort. But the knitters began knitting them. This possibly marks one of the few times in history when a computer generated code to be executed by humans. [Mystery lace\u00a0- datasock] [Reverss Shawl\u00a0- citikas] [Frost - Odonata] The knitters didn\u2019t follow SkyKnit\u2019s directions exactly, as it turns out. For most of its patterns, doing them exactly as written would result in the pattern immediately unraveling (due to many dropped stitches), or turning into long whiplike tentacles (due to lots of leftover stitches). Or, to make the row counts match up with one another, they would have had to keep repeating the pattern until they\u2019d reached a multiple of each row count - sometimes this was possible after a few repeats, while other times they would have had to make the pattern tens of thousands of stitches long. And other times, missing rows made the directions just plain impossible.\u00a0 So, the knitters just started fixing SkyKnit\u2019s patterns. Knitters are very good at debugging patterns, as it turns out. Not only are there a lot of knitters who are coders, but debugging is such a regular part of knitting that the complicated math becomes second nature. Notation is not always consistent, some patterns need to be adjusted for size, and some simply have mistakes. The knitters were used to taking these problems in stride. When working with one of SkyKnit\u2019s patterns, GloriaHanlon wrote, \u201cI\u2019m trying not to fudge too much, basically working on the principle that the\u00a0pattern was written by an elderly relative who doesn\u2019t speak much English.\u201d Each pattern required a different debugging approach, and sometimes knitters would each produce their own very different-looking versions. Here are three versions of\u00a0\u201cPaw Not Pointed 2 Stitch 2\u2033. [Top - ActualJellyfish;\u00a0Middle - LadyAurian;\u00a0Bottom (sock version) - ShoelessJane] Once, knitter MeganAnn came across a stitch that didn\u2019t even exist (something SkyKnit called \u2019pbk\u2019). So she had to improvise. \u201cI googled it and went with the first definition I got, which was \u2018place bead and knit\u2019.\u201d The resulting pattern is \u201cRibbed Rib Rib\u201d below (note bead). [Ribbed Rib Rib - MeganAnn] Even debugged, the patterns were weird. Like, really, really nonhumanly weird. \u201cI love how organic it comes out,\u201c wrote Vastra. SylviaTX agreed, loving \u201cthe organic seeming randomness. Like bubbles on water or something,\u201d\u00a0 SkyKnit\u2019s patterns were also a pain.\u00a0Michaela112358 called Row 15 of Mystery Lace (above) \u201ca bit of a head melter\u201d, commenting that it \u201clacked the rhythm that you tend to get with a normal pattern\u201d. Maeve_ish wrote that Shetland Bird Pat \u201cmade my brain hurt so I went to bed.\u201d ShoelessJane asked, \u201cOkay, now who here has read Snow Crash?\u201d [Winder Socks (2 versions) - TotesMyName] \u201cI was laughing a few days ago because I was trying to math a Skyknit pattern and my brain\u2026froze. Like, no longer could number at all. I stared blankly at my scribbles and at the screen wondering what had happened til somehow I rebooted. Yup, Skyknit crashed my brain.\u201d - Rayn63 [Paw chain 2\u00a0-\u00a0HMSChicago] On the pattern SkyKnit called \u201cCherry and Acorns Twisted To\u201d: \u201cCouple notes on the knitting experience, which while funny wasn\u2019t terribly pleasurable: Because there\u2019s no rhythm or symmetry to the pattern, I felt I was white-knuckling it through each line, really having to concentrate. There are also some stitch combinations that aren\u2019t very comfortable to execute physically, YO, SSK in particular. That said, I\u2019m nearly tempted to add a bit of random AI lace to a project, perhaps as cuffs on a sweater or a short-row lace panel in part of a scarf, like\u00a0Sylvia McFadden\u00a0does in many of her shawl designs. As another person in the thread said, it would add a touch of spider-on-LSD.\u201d -SarahScully [cherry and acorns twisted to\u00a0- Sarah Scully] BridgetJ\u2019s comments on\u00a0\u201cButnet Scarf\u201d: \u201cFour repeats in to this oddball, daintily alien-looking 8-row lace pattern, and I have, improbably, begun to internalize it and get in to a rhythm like every other lace pattern. I still have a lingering suspicion that I\u2019m knitting a pattern that could someday communicate to an AI that I want to play a game of Global Thermonuclear War, but I suppose at least I\u2019ll have a scarf at the end of it?\u201d -BridgetJ [butnet scarf\u00a0- BridgetJ] There was also this beauty of a pattern, that SkyKnit called \u201cTiny Baby Whale Soto\u201d. GloriaHanlon managed somehow to knit it and described it as\u00a0\u201ca bona fide eldritch horror. Think Slenderman meets Cthulu and you wouldn\u2019t be far wrong.\u201d [Tiny Baby Whale Soto - GloriaHanlon] Other than being a bit afraid of Tiny Baby Whale Soto, the knitters seem happy to do the bidding of SkyKnit, brain melts and all. \u201cI cast on for a lovely MKAL with a designer I totally trust and became immediately suspicious because the pattern made sense. All rows increase in an orderly manner. There are no \u201chuh?\u201d moments. There are no maths at all\u2026it has all been done for me. I thought I would be happy, yo. Instead, I am kind of missing the brain scrambling and I keep looking for pigs and tentacles. Go figure.\u201d - Rayn63 Check out the rest of the SkyKnit-generated patterns, and the glorious rainbow of weird test-knits at\u00a0SkyKnit: The Collection\u00a0and InfiKnit.\u00a0 There\u2019s also a great article in the Atlantic that talks a bit more about the debugging.\u00a0 If you feel so inspired (and don\u2019t mind the kind-hearted yet vigorous swearing), join the conversation on the\u00a0LSG Ravelry SkyKnit thread\u00a0- many of SkyKnit\u2019s creations have not yet been test-knit at all, and others transform with every new knitter\u2019s interpretation. Compare notes, commiserate, and do SkyKnit\u2019s inscrutable bidding! Heck yeah there is bonus material this week. Have some neural net-generated knitting & crochet titles. Some of them are mixed with metal band names for added creepiness. Enter your email here to get more like these: Chicken ShrugSnuggle FeaturesCartube Party Filled BootiesCorm FullenflopsWomp MittensSocks of DeathTomb of SweaterShawl Ruins Short URL\n  loading tweets\u2026","time":1525692229,"title":"SkyKnit: When knitters teamed up with a neural network","type":"story","url":"http:\/\/aiweirdness.com\/post\/173096796277\/skyknit-when-knitters-teamed-up-with-a-neural"},{"by":"krstffr","descendants":0,"id":17011845,"kids":"None","score":7,"text":"Mozilla\u2019s motto is \u201cinternet for people, not profit,\u201d however the realities of having to fund all of its ventures are forcing the company into adopting one of the web\u2019s less human-friendly aspects: sponsored content. Having acquired read-it-later service Pocket last year, Mozilla has been populating new tabs in Firefox with Pocket reading suggestions \u2014 and those are now going to include links that an advertiser has paid for. If you\u2019re using Firefox\u2019s nightly and beta builds, you might have already seen sponsored links appearing among the Pocket suggestions, and the feature will be making its way into the proper Firefox browser with the release of version 60 this month, as noted by The Register. In a blog post last week, Pocket founder Nate Weiner explained that the online \u201cadvertising model is broken,\u201d citing the loss of privacy, transparency, and control for the user. What he and Mozilla propose as an alternative is to restore all three of those facets to Firefox users while still generating some income by placing paid-for links in front of those users. Mozilla\u2019s promise is to only promote \u201cvaluable content, worthy of your time,\u201d while giving you the option to hide stuff you don\u2019t like or to disable sponsored suggestions altogether. Without the fine-grained targeting that Facebook and Google are able to offer advertisers, Mozilla will surely be making a lot less through its ads, but it seems like the company thinks it will be enough to make the irritation for its users worthwhile. With this new change in approach from Mozilla, the top alternatives to Google\u2019s Chrome browser are either limited in availability \u2014 Safari, which doesn\u2019t run on Windows or Android \u2014 or ad-supported, as in the case of Firefox and Opera. So you\u2019re either sacrificing privacy, device compatibility, or your own attention, depending on which trade-off you choose to make. It may be an annoyance to be confronted with such a choice, but it just goes to show that nothing useful on the internet is ever free. Command Line delivers daily updates from the near-future.","time":1525692156,"title":"Firefox is adding ads","type":"story","url":"https:\/\/www.theverge.com\/2018\/5\/7\/17326184\/firefox-ads-sponsored-content-pocket-suggestions"},{"by":"optimusrex","descendants":4,"id":17011804,"kids":"[17013337, 17013895]","score":18,"text":"There is a common narrative in the world of AI that bigger is better. To train the fastest algorithms, they say, you need the most expansive datasets and the beefiest processors. Just look at Facebook\u2019s announcement last week that it created one of the most accurate object recognition systems in the world using a dataset of 3.5 billion images. (All taken from Instagram, naturally.) This narrative benefits tech giants, helping them attract talent and investment, but a recent AI competition organized by Stanford University shows the conventional wisdom isn\u2019t always true. Fittingly enough for the field of artificial intelligence, it turns out brains can still beat brawn.  The proof comes from the DAWNBench challenge, which was announced by Stanford researchers last November and the winners declared last week. Think of DAWNBench as an athletics meet for AI engineers, with hurdles and long jump replaced by tasks like object recognition and reading comprehension. Teams and individuals from universities, government departments, and industry competed to design the best algorithms, with Stanford\u2019s researchers acting as adjudicators. Each entry had to meet basic accuracy standards (for example, recognizing 93 percent of dogs in a given dataset) and was judged on metrics like how long it took to train an algorithm and how much it cost. These metrics were chosen to reflect the real-world demands of AI, explain Stanford\u2019s Matei Zaharia and Cody Coleman. \u201cBy measuring the cost [...] you can find out if you\u2019re a smaller group if you need Google-level infrastructure to compete,\u201d Zaharia tells The Verge. And by measuring training speed, you know how long it takes to implement an AI solution. In other words, these metrics help us judge whether small teams can take on the tech giants.  The results don\u2019t give a straightforward answer, but they suggest that raw computing power isn\u2019t the be-all and end-all for AI success. Ingenuity in how you design your algorithms counts for at least as much. While big tech companies like Google and Intel had predictably strong showings in a number of tasks, smaller teams (and even individuals) ranked highly by using unusual and little-known techniques.  Take, for example, one of DAWNBench\u2019s object recognition challenges, which required teams to train an algorithm that could identify items in a picture database called CIFAR-10. Databases like this are common in AI, and are used for research and experimentation. CIFAR-10 is a relatively old example, but mirrors the sort of data a real company might expect to deal with. It contains 60,000 small images, just 32 pixels by 32 pixels in size, with each picture falling into one of ten categories such as \u201cdog,\u201d \u201cfrog,\u201d \u201cship,\u201d or \u201ctruck.\u201d  In DAWNBench\u2019s league tables, the top three spots for fastest and cheapest algorithms to train were all taken by researchers affiliated with one group: Fast.AI. Fast.AI isn\u2019t a big research lab, but a non-profit group that creates learning resources and is dedicated to making deep learning \u201caccessible to all.\u201d The institute\u2019s co-founder, entrepreneur and data scientist Jeremy Howard, tells The Verge that his students\u2019 victory was down to thinking creatively, and that this shows that anyone can \u201cget world class results using basic resources.\u201d Howard explains that in order to create an algorithm for solving CIFAR, Fast.AI\u2019s group turned to a relatively unknown technique known as \u201csuper convergence.\u201d This wasn\u2019t developed by a well-funded tech company or published in a big journal, but was created and self-published by a single engineer named Leslie Smith working at the Naval Research Laboratory. Essentially, super convergence works by slowly increasing the flow of data used to train an algorithm. Think of it like this, if you were teaching someone to identify trees, you wouldn\u2019t start by showing them a forest. Instead, you\u2019d introduce information to them slowly, starting by teaching them what individual species and leaves look like. This is a bit of a simplification, but the upshot is that by using super convergence, Fast.ai\u2019s algorithms were considerably speedier than the competition\u2019s. They were able to train an algorithm that could sort CIFAR with the required accuracy in just under three minutes. The next fastest team that didn\u2019t use super convergence took more than half an hour.  It didn\u2019t all go Fast.AI\u2019s way though. In another challenge using object recognition to sort through a database called ImageNet, Google romped home, taking the top three positions in training time, and the first and second in training cost. (Fast.AI took third place in cost and fourth place in time.) However, Google\u2019s algorithms for were all running on the company\u2019s custom AI hardware; chips designed specially for the task known as Tensor Processing Units or TPUs. In fact, for some of the tasks Google used what it calls a TPU \u201cpod,\u201d which is 64 TPU chips running in tandem. . By comparison, Fast.AI\u2019s entries used regular Nvidia GPUs running off a single bog-standard PC; hardware that\u2019s more readily available to all.  \u201cThe fact that Google has a private infrastructure that can train things easily is interesting but perhaps not completely relevant,\u201d says Howard. \u201cWhereas, finding out you can do much the same thing with a single machine in three hours for $25 is extremely relevant.\u201d These ImageNet results are revealing precisely because they\u2019re ambiguous. Yes, Google\u2019s hardware reigned supreme, but is that a surprise when we\u2019re talking about one of the richest tech companies in the world? And yes, while Fast.AI\u2019s students did come up with a creative solution, it\u2019s not that Google\u2019s wasn\u2019t also ingenious. One of the company\u2019s entries made use of what it calls \u201cAutoML\u201d \u2014 a set of algorithms that search for the best algorithm for a given task without human direction. In other words, AI that designs AI.  The challenge of understanding these results is just not a matter of finding out who\u2019s best \u2014 they have clear social and political implications. For example, consider the question of who controls the future of artificial intelligence. Will it be big tech companies like Amazon, Facebook, and Google, who will use AI to increase their power and wealth; or will the benefits be more evenly and democratically available?  For Howard, these are crucial questions. \u201cI don\u2019t want deep learning to remain the exclusive venue of a small number of privileged people,\u201d he says. \u201cIt really bothers me, talking to young practitioners and students, this message that being big is everything. It\u2019s a great message for companies like Google because they get to recruit folks because they believe that unless you go to Google you can\u2019t do good work. But it\u2019s not true.\u201d Sadly, we can\u2019t be AI soothsayers. No one can predict the future of the industry by examining the bones of the DAWNBench challenge. And indeed, if the results of this competition show anything, it\u2019s that this is a field still very much in flux. Will small and nimble algorithms decide the future of AI or will it be raw computing power? Nobody can say, and expecting a simple answer would be unreasonable anyway.  Zaharia and Coleman, two of the DAWNBench organizers, say they\u2019re just happy to see the competition provoke such a range of responses. \u201cThere was a tremendous amount of diversity,\u201d says Coleman. \u201cI\u2019m not too worried about [one company] taking over the industry just based on what\u2019s happened with deep learning. We\u2019re still at a time where there\u2019s an explosion of frameworks going on [and] a lot of sharing of ideas.\u201d The pair point out that although it was not a criteria for the competition, the vast majority of   entries to DAWNBench were open-sourced. That means their underlying code was posted online, and that anyone can examine it, implement it, and learn from it. That way, they say, whoever wins in DAWNBench\u2019s challenges, everybody benefits.  Update May 7th, 10:30AM ET: Updated to clarify that Google\u2019s entry to the ImageNet competition in DAWNBench was done on a TPU pod, not a single TPU.  Command Line delivers daily updates from the near-future.","time":1525691537,"title":"AI speed test shows clever coders can still beat tech giants like Google, Intel","type":"story","url":"https:\/\/www.theverge.com\/2018\/5\/7\/17316010\/fast-ai-speed-test-stanford-dawnbench-google-intel"},{"by":"MiriamWeiner","descendants":21,"id":17011802,"kids":"[17018184, 17018271, 17018796, 17022111, 17020818, 17019579]","score":46,"text":" Syria\u2019s musical traditions show histories and cultures that transcend contemporary politics and war. This is a country that gave the world song. In Syria, music runs deeper into the fabric of the place than anywhere else in the world. Long before the modern state was formed in 1946, Syria had developed rich musical traditions over thousands of years. The diverse religions, sects and ethnicities that inhabited and travelled across the country over the millennia \u2013 Muslims, Christians, Jews, Arabs, Assyrians, Armenians and Kurds, to name but a few \u2013 all contributed to this eclectic musical heritage.  This media cannot be played on your device. Songs of ancient Syria In the 1950s, archaeologists found 29 3,400-year-old clay tablets in a small cubicle \u2013 likely a library \u2013 in the ancient port city of Ugarit on Syria\u2019s Mediterranean coast. They were mostly broken into tiny fragments, but one, which came to be known as H6, remained in larger pieces. Inscribed on it were lyrics, and underneath them is what researchers believe is the earliest example of musical notation anywhere in the world. You may also be interested in: \u2022\u00a0The world\u2019s oldest centre of learning  \u2022\u00a0Where algebra was invented\u2022\u00a0The dessert that\u2019s blocked at borders These shards of clay are the beginnings of an incomparable musical heritage. Academics have spent years literally piecing together the tablets, trying to work out what was written on them, what it meant and how the musical notation might sound were it to be played again. The text is in Babylonian cuneiform script, a system of writing that spread throughout the region several millennia ago.  We could read the script... but we didn\u2019t have any idea what it meant  \u201cThe problem with this tablet is that \u2013 we could read the script because it was written in Babylonian cuneiform, and we know the value of the signs \u2013 but we didn\u2019t have any idea what it meant,\u201d said Richard Dumbrill,\u00a0professor of archaeomusicology at Babylon University in Iraq, who has worked on the Ugarit tablets for more than two decades. Dumbrill described how he attempted on many occasions to reconstruct the Ugarit tablets in order to translate the text and music inscribed on them: \u201cI took photographs and I tried to build them as a puzzle, but some had been damaged beyond reconstruction.\u201d  The translation difficulties were a product of the text being written in a language known as Hurrian from the north-east Caucasus, probably in modern-day Armenia, but which ended up in Syria\u2019s fertile lands. \u201cThese people migrated towards north-west Syria \u2013 it took them a good couple of thousand years \u2013 and decided to use the Babylonian signs to write their text and their music,\u201d Dumbrill said. \u201cSo it was extremely difficult to translate. However, I managed to find out that the text below the two lines were musical names that were Hurrianised \u2013 that is, they were Babylonian but had been transformed on contact with the Hurrian people. And I could find out that it was a melody. It took me about 20 years to translate.\u201d So what does the earliest musical composition tell us about the people who lived at that time? From Dumbrill\u2019s translations, he believes they had catalogues of songs for occasions of all sorts and moods, not just hymns for religious events. One song details a bar girl selling beer to her clients, but the tablet known as H6 details a more sober story. \u201cIt\u2019s about a young girl who cannot have any children; she thinks that the reason is because she misbehaved in some way, which is not mentioned,\u201d Dumbrill said. \u201cAnd from what we can understand of the text, which is quite limited, she goes at night to pray to the goddess Nigal, who was the goddess of the moon. She brings a little pot of tin with sesame seeds or sesame oil in it, which she offers to the goddess, and that\u2019s all we know about the text.\u201d  An ancient musical workshop But Syria did not produce only the earliest melody. Over time, a rich array of musical instruments on which to play them also formed across the region, such as the lyre, a stringed musical instrument with a yoke and a crossbar, and lutes, which evolved into the modern Arabian oud, a teardrop-shaped plucked string instrument that produces one of the most evocative sounds in the region. At Mari, an Early Bronze Age city-state on the banks of the Euphrates river in eastern modern-day Syria, researchers in the 20th Century uncovered a number of records detailing the musical instrument-making business of the time. \u201cThere in the palace [at Mari] we discovered a huge number of tablets which were mainly letters and receipts of material from artisans who were requesting leather, raw hide, wood, gold and silver for making instruments,\u201d Dumbrill said. \u201cTherefore we have a very good idea about the instruments that were made about 4,000 years ago. We knew the names of the artisans, we knew the type of instruments they made. They were already influenced by instruments which were not Syrian,\u201d he added, citing the Iranian parahshitum as an example, a type of lyre that became very popular among the girls of the harem at Mari. Production of musical instruments continued to flourish in Syria over the centuries, and many are preserved in collections open to visitors today.  At the Debban\u00e9 Palace in the Lebanese coastal city of Saida, for example, a collection of Ottoman-era musical instruments, dating from around the 19th Century, gives visitors an insight into the traditions present across both Lebanon and Syria before the formation of the modern states. Pieces from Syria include ouds and bouzouks (a small lute with a long, slim arm) inlaid with wood and ivory. \u201cPeople [visiting] ask, why are there so many musical instruments?\u201d said Ghassan Dimassy, a guide at the Debban\u00e9 Palace. \u201cWe tell them that this is an Ottoman house and the women used to sit and sing.\u201d He mimicked the women playing a musical instrument and the men lying back and relaxing; here, music was the essential backdrop to any leisure occasion. A music in exile Last year, Syrian authorities launched a bid to have Aleppo, Syria\u2019s second city, added\u00a0to Unesco's Creative Cities Network as a \u2018City of Music\u2019 to commemorate its heritage. During the 17th Century, Aleppo was renowned for its muwashshah, a form of music combined with lyrics from Andalusian poetry, classical Arabic poetry, or, later on, Syrian or Egyptian conversational Arabic. Muwashshah are performed by a band playing the oud and qanun (a horizontal board with strings plucked to produce a haunting sound like trickling water), as well as the kamanja (a violin-like instrument), a darabukkah (drum), and a daf (tambourine). The form thrived in the city, where it was embraced by both Muslim and Christian populations. However, significant efforts to preserve Syria\u2019s musical traditions are now also found outside this country, which has entered its eighth year of conflict and where civilians have in large part been forced to focus attention on survival rather than exploring their cultural heritage. Some Syrian youth are making the best of a difficult situation and are bringing Syria's rich musical history into the limelight.  Long an incubator of creative talent, Beirut has become a crucible for preserving Syrian musical heritage. Me'zaf, an organisation founded in the Lebanese capital in 2015, aims to innovate, promote and preserve authentic music from not just Syria, but the Levantine region as a whole, showing how the Middle East\u2019s rich musical traditions precede the modern nation-state borders introduced in the 20th Century. \u201cA lot of forms were created in Damascus or Aleppo and were taken to Cairo, then forms were created in Cairo and performed in the Levant,\u201d explained Ghassan Sahhab, a Me'zaf leader and Lebanese musicology teacher, composer and qanun player. \u201cWe have a rich culture and we have to appreciate it and know our history in order to continue. At the moment, it\u2019s a case of preserving heritage and culture.\u201d Another musical troupe that formed in Beirut is Assa'aleek, which consists of five Syrians and a Norwegian. The band\u2019s name means \u2018the ragamuffins\u2019 or \u2018the vagabonds\u2019 in Arabic, and refers to a group of self-proclaimed Robin Hood-type characters who lived during the pre-Islamic era in the Arabian Gulf and tried to change the ways of the ruling class.  This media cannot be played on your device. \u201cWe are similar to the Assa'aleek: we were forced out of our communities and homeland for many reasons,\u201d said Abodi Jatal, percussion player in Assa'aleek. \u201cIt is important to preserve ancient Syrian music because this is our identity, it is history and it is civilisation, after all. This is what we have. This is what we are,\u201d said Assa'aleek vocalist Mona Al Merstany. \u201cIt\u2019s not just about a normal country \u2013 it\u2019s one of the most ancient countries. It is important to show such things because all people have the right to see beauty.\u201d  It is important to preserve ancient Syrian music because this is our identity  They see music as a way of fighting the injustices faced on a daily basis by people in the region. \u201cOur lyrics and songs, this is what they are built on,\u201d Jatal said. \u201cWe wanted to fight against bad habits, such as harassment against women, and we saw that this is really similar to what the Assa'aleek did, so that\u2019s why we used the name.\u201d As well as new songs, the band has been performing Syrian folk music since 2013, bringing music from across Syria\u2019s diverse landscapes and communities to audiences in Lebanon. Syrian music heritage has come a long way since the melody found on the clay tablets at Ugarit. Today, bands such as Assa'aleek are reinventing the definition of Syrian music, bringing it to new audiences.  Meanwhile, they are developing the sounds that museoarchaeologists of the future might one day find, stored on computers, in files or drawers, in Aleppo, Damascus or Beirut, or even Paris, London or Berlin. Al Merstany sums it up well: \u201cWhen someone asks me what is Syria, this is what I have to say: the music, the art.\u201d Join more than three million BBC Travel fans by liking us on\u00a0Facebook, or follow us on\u00a0Twitter\u00a0and\u00a0Instagram. If you liked this story,\u00a0sign up for the weekly bbc.com features newsletter\u00a0called \"If You Only Read 6 Things This Week\". A handpicked selection of stories from BBC Travel, Capital, Culture, Earth and Future, delivered to your inbox every Friday. \n\n","time":1525691509,"title":"The oldest song in the world","type":"story","url":"http:\/\/www.bbc.com\/travel\/story\/20180424-did-syria-create-the-worlds-first-song"},{"by":"jvardy","descendants":77,"id":17011733,"kids":"[17013137, 17012986, 17013180, 17014101, 17012951, 17013675, 17012762, 17013688, 17013912, 17012973, 17014813, 17013412, 17013119]","score":86,"text":"I built a webhook which transfers \u00a31 from my current account into a Monzo pot every time one of my builds fail. I\u2019m going to explain what I did and why it involved more work than I first thought, this isn\u2019t a tutorial but the code is on GitHub if you want to have a look. I chose a stack that would challenge me to develop new and existing skills. It had been a while since I had written any Go, and it was a good opportunity to try out AWS Fargate. I started off with a simple web server to act as an endpoint to be called by the build system which would accept a POST request and print it to stdout. I bundled the app within a Docker container, opened up the AWS console and within 10 minutes it was deployed. I could now add the callback to my build config so it would be called after every build, however I quickly ran into my first issue; CircleCI doesn\u2019t allow environment variables to be used when defining a callback URL. This was a problem because I have no way of verifying the payload actually came from CircleCI. I devised a solution which involved using the data in the payload to query the CircleCI API. It took some time trying to work out why my request to the API was failing, I now know that the Accept application\/json header is required for their API to function. With the endpoint operating and able to check whether a build has passed or failed, it was time to get to work on the fail jar. Having looked at the Monzo API a few days before, it seemed like it would be nice and simple to transfer money into a pot (money you can\u2019t spend until you transfer it back to your current account). However I\u2019d assumed I could authenticate myself with a long-life API key. Instead I needed to setup an oAuth flow and then refresh the token regularly thereafter. I setup a DynamoDB table to store my users\u2019 access token and expiration, refreshing the token when it had expired. None of this was too difficult, but I certainly hadn\u2019t expected to have to do this when I started. Success! I have money going into a pot every time a build fails. I hear you ask why this is actually costing me money since at the moment the money is mine, but in a separate part of my bank account. Well yeah you\u2019re right. I\u2019m going to run this for a few weeks \/ months and donate the money in the pot to charity. This is not the most economical way of running an API like this. The smallest Fargate instance (0.25vCPU and 0.5gb memory) and provisioned DynamoDB table costs ~$13.43\/month, and that\u2019s before some additional costs such as the load balancer, ECR, and data transfer. This would be much cheaper running as a Lambda. But that\u2019s not the point, this was just for fun. I wanted to work on something interesting, but which I could complete in a day despite not realising I would need to call the CircleCI API or setup an authentication flow with Monzo, this was comfortably a day\u2019s work. Any tech related charities you think I should donate the money to? By clapping more or less, you can signal to us which stories really stand out. Senior Software Engineer at Football Whispers. Blogs from Football Whispers\u2019 engineering and data-science teams.","time":1525690601,"title":"Show HN: When my builds fail I pay money to charity","type":"story","url":"https:\/\/medium.com\/football-whispers-engineering-and-data-sci\/failed-builds-cost-more-than-just-time-4e7c196cc8bc"},{"by":"raleighm","descendants":62,"id":17011723,"kids":"[17015395, 17015477, 17015462, 17015977, 17015731, 17015164, 17015459, 17016112, 17015131, 17015418, 17015673, 17016078, 17017018, 17015107, 17015989, 17015174]","score":55,"text":"Will it work? Religions have long been the dominant suppliers of rituals, gamely stepping in with an answer to every question from How do I celebrate the birth of my baby boy? to How can I transfer my own sins onto a live chicken? But in an age of increasing religious disaffiliation, these rituals now feel hollow to millions of people. And even when they don\u2019t, there\u2019s a wide range of new experiences for which the traditional rituals offer no script: How do I cope with my rage after receiving a parking ticket? How can I keep a smart car from exacerbating my loneliness and narcissism? What can I do to mourn the death of my laptop? Although there is no single agreed-upon definition, a ritual is typically a deliberate action performed in a set sequence that improves our emotional state, by reframing an experience in a way that feels meaningful. At the Ritual Design Lab in Silicon Valley, a small team of \u201cinteraction designers\u201d is working to generate new rituals for modern life, with an eye to user experience. Created by Kursat Ozenc and Margaret Hagan, the lab crafts rituals for both individuals and organizations, including big hitters like Microsoft. The team\u2019s website offers a Ritual Design Hotline with a tantalizing promise: \u201cYou tell us your problem. We will make you a ritual.\u201d Meanwhile, its Ritual Inventory invites you to add any interesting ritual you\u2019ve made or seen to its growing database. And its app, IdeaPop, helps you brainstorm and create your own rituals. Ritual Design Lab has its roots in Stanford\u2019s Institute of Design, where Ozenc and Hagan both teach. In 2015, they proposed a new course on ritual design. To their surprise, more than 100 students signed up. Most were secular. \u201cThe interest was huge\u2014so we thought, we should harness this interest,\u201d Ozenc told me. \u201cThe new generation, they want bite-size spirituality instead of a whole menu of courses. Design thinking can offer this, because the whole premise of design is human-centeredness. It can help people shape their spirituality based on their needs. Institutionalized religions somehow forget this\u2014that at the center of any religion should be the person.\u201d Ozenc, 38, is no stranger to institutionalized religion. Growing up in Turkey, he practiced Sufi Islam\u2014and he still does. \u201cI know the value of spirituality,\u201d he said. To help others access that value, he homes in on what he considers ingredients for a good ritual. One is the bite-sized portion size; whenever possible, a ritual should be quick. Another key ingredient is playfulness. In fact, some of the rituals listed on the website border on silly. The ritual for coping with parking-ticket rage involves saut\u00e9ing and then eating the ticket. \u201cWe intentionally take the stance that we believe in rituals that are lightweight and a bit humorous,\u201d Ozenc told me. \u201cWe\u2019re not interested in heavy, top-bottom, religious, or government rituals.\u201d The importance of play in ritual is backed up by evolutionary biology: It facilitates problem-solving and social bonding among bonobos, as primatologist Isabel Behncke has shown. Ozenc and Hagan take play so seriously that they\u2019ve actually had Behncke co-teach alongside them in Stanford\u2019s ritual-design classes. They\u2019ve also collaborated with neuropsychologist Nick Hobson, who studies ritual\u2019s impact on neural processes and writes about the power of playful rituals\u2014even ones as simple as playing ping-pong during your lunch break at work. Some of Ritual Design Lab\u2019s work has more heft. Ozenc is preparing to roll out a project called Pop-Up Prayer, which aims to give urban young professionals a way to pray when they\u2019re on the go. Here\u2019s how it works: An organization buys a prayer kit, puts it in a room where it\u2019s okay for a visitor to pray, and posts an online listing. You find the building using your smartphone (as with other location-based services), go to the room, take what you need from the kit, and use it to pray. Then you put everything back where you found it. The first kit to be debuted will be geared toward young Muslims\u2014or \u201cMipsters,\u201d as Ozenc calls them\u2014and will contain a prayer rug, a compass, water, and a prayer book. Subsequent models will be geared toward Jews and Christians. The multi-faith aspect of the project makes perfect sense, given that Ozenc didn\u2019t create it by himself: He came up with the idea in collaboration with Gil Steinlauf, a rabbi from Washington, D.C., when the two were brought together as a part of an incubator for \u201cspiritual entrepreneurs\u201d at Columbia University\u2019s business school. \u201cI think people in tech who are creating new rituals really need to be in deep conversation with religious people like me,\u201d Steinlauf said in an interview, adding that it\u2019s all too rare to see a Silicon Valley entrepreneur learning from ancient religions. \u201cI\u2019ve seen people reinventing the wheel, and as a rabbi I kind of laugh sometimes. People say, \u2018Let\u2019s take Tuesday\u2014and basically make it Shabbat.\u2019 It\u2019s just funny. Why are you trying to do that when there are already synagogues and churches and all kinds of things that exist for that?\u201d In the next breath, the rabbi added: \u201cBut I understand it, of course. People are alienated from these structures.\u201d For a person who\u2019s walked away from institutionalized religion, it may be psychologically easier to join the National Day of Unplugging than to observe the Sabbath, the original 24-hour digital detox. On the other hand, turning to new rituals as stand-ins for ancient ones raises the tricky issue of legitimacy. Part of why an ancient ritual seems legitimate or authentic to many of us is because it is, well, ancient. Its validity is sourced from its perceived unchangingness\u2014\u201cMy great-great-grandparents did this the exact same way!\u201d\u2014and the way it binds us to a larger community of people, both dead and alive. Absent that antiquity, what makes a new ritual feel authentic? \u201cIn earlier generations, the more we could objectify religion as something that lives outside of you, the more authentic it was,\u201d Steinlauf said. \u201cNow, if you\u2019re really going to speak Millennial, ritual has to be fundamentally subjective in the sense that it has to be intensely personally meaningful and relevant. As soon as it speaks to my truth, that\u2019s authenticity\u2014that\u2019s how we define authenticity now.\u201d If the bespoke and the legitimate used to be inversely proportional, today they are directly proportional. Although this may be a reality of the 21st century, there are several downsides to it. For one, ancient rituals are technologies that have been debugged, fine-tuned, and time-tested over millennia. They evolved to respond to human needs, and in their crystallized form, they contain deep insights into those needs. By jettisoning the rituals, we also jettison the wisdom they house. \u201cOne of the great critiques of modern Millennial spirituality is that the sense of lineage is being utterly destroyed in this radical democratization of spiritual life that we\u2019re seeing,\u201d Steinlauf said. \u201cYou lose something very precious when you obliterate lineage.\u201d To the rabbi, there\u2019s an even graver risk that comes with separating ritual from religion. \u201cWhen it\u2019s ensconced in religious life,\u201d he said, \u201critual doesn\u2019t just serve to validate your experience or to help you through a difficult moment.\u201d It also situates your experience within a larger framework of moral imperatives, and makes demands of you, including that you be of service to others. \u201cSomeone may say, \u2018I\u2019m just helping somebody who had a bad day at work to process and move on.\u2019 Well, okay, that could be effective\u2014but to what extent are you actually helping the ultimate job of all ritual life, which is to give you the message that it\u2019s not all about you? Rituals that are designed as one-offs for individuals are divorced from that\u2014and that\u2019s very dangerous.\u201d Finally, an endeavor like Ritual Design Lab has a paradox at its heart. If I contact the Ritual Design Hotline and the team solves my problem by creating a ritual for me, I am implicitly buying into the notion that I\u2019m not capable of creating one myself. By outsourcing ritual design, I am, to use Steinlauf\u2019s idiom, objectifying rather than subjectifying it; I\u2019m reinscribing the old notion that we have to look to outside experts for such things. Only now, instead of turning to a rabbi or a priest or a guru, I\u2019m turning to a designer. Ozenc does not necessarily see this as a problem. In the Stanford classes he co-taught with Hagan, he ran two sessions. In the first, each student designed a ritual for herself. In the second, students paired up: One, the designer, was tasked with crafting a ritual for the other, the client. \u201cThe second version is more effective because you might not be seeing the opportunities in your life\u2014maybe someone else can see better,\u201d Ozenc told me. \u201cThere\u2019s value in it if someone you trust comes in, and you give that other person permission to design a ritual for you.\u201d That, of course, is what religious people have been doing for millennia; it\u2019s just that the \u201cother person\u201d might have lived in the year 218, not 2018. Others who work in the ritual design world\u2014a community few in numbers, but growing on both sides of the Atlantic\u2014are vociferously opposed to outsourcing. \u201cOne should never outsource one\u2019s role as a ritual artisan. That is giving away one\u2019s power,\u201d said Jeltje Gordon-Lennox, a psychotherapist and ritual designer in Geneva, Switzerland. She is part of the European Ritual Network, a group that sprang up three years ago to bring together ritual designers in Switzerland, the United Kingdom, Norway, Denmark, and the Netherlands. \u201cWe are all able to craft our own rituals,\u201d she said. \u201cHumankind has always crafted ritual to mark special events, moments, and places. With the advent of urbanization, we became removed from this creative process as institutions took over. Consumerism reinforced our role as end-users.\u201d And consumerism is still very much at play. Gordon-Lennox offers a service that she calls \u201critual accompaniment.\u201d You can hire her to help you design a bespoke ceremony, like a funeral, but expect the process to be both expensive and collaborative. \u201cI charge a hefty rate for what I do,\u201d she told me bluntly. \u201cAnd I\u2019ve said this to clients: \u2018You\u2019re going to pay me rather a lot. And you\u2019re going to work really hard.\u2019\u201d Ritual Design Lab does not currently charge individuals when creating a ritual for them. \u201cMy intention isn\u2019t really to make this a business,\u201d Ozenc said. \u201cIt\u2019s more a statement\u2014that people need spirituality even if they don\u2019t necessarily want to be connected to any institutional religion.\u201d Nevertheless, asked if he plans to charge a fee one day, he said, \u201cNot for individuals, but maybe for rituals in organizations, we are thinking about that.\u201d For Steinlauf, the problem isn\u2019t so much with ritual designers making a living off people\u2019s spiritual needs\u2014rabbis do that too\u2014but with what happens to our ritual life in the process. Customization risks stripping ritual of lineage, and unbundling ritual from religion can produce a self-centered mentality instead of one in tune with broader moral imperatives. \u201cWe need to take a breath,\u201d the rabbi said, \u201cand think about the wider implications of commodifying our spiritual life this way.\u201d \n    Jeff VanderMeer discusses how writing fiction about environmental crises may jolt readers out of complacency.\n Kanye West wants freedom\u2014white freedom. I could only have seen it there, on the waxed hardwood floor of my elementary-school auditorium, because I was young then, barely 7 years old, and cable had not yet come to the city, and if it had, my father would not have believed in it. Yes, it had to have happened like this, like folk wisdom, because when I think of that era, I do not think of MTV, but of the futile attempt to stay awake and navigate the yawning whiteness of Friday Night Videos, and I remember that there were no VCRs among us then, and so it would have had to have been there that I saw it, in the auditorium that adjoined the cafeteria, where after the daily serving of tater tots and chocolate milk, a curtain divider was pulled back and all the kids stormed the stage. And I would have been there among them, awkwardly uprocking, or worming in place, or stiffly snaking, or back-spinning like a broken rotor, and I would have looked up and seen a kid, slightly older, facing me, smiling to himself, then moving across the floor by popping up alternating heels, gliding in reverse, walking on the moon. The new music video from Childish Gambino weaponizes the viewer\u2019s instinctive bodily empathy. \u201cThis Is America\u201d isn\u2019t the first time that Donald Glover, as his musical alter ego Childish Gambino, has harnessed dance in service of surrealism. But the art form has a conspicuous symbolic significance in the artist\u2019s latest single, which Glover debuted on Saturday Night Live: The song\u2019s emphasis on dance was apparent in his live performance on the show, in the cover art for the track, and in the remarkable music video itself, which has more than 36 million views on YouTube as of publication. In the video, a grinning, shirtless Glover dances through a giant warehouse, occasionally accompanied by black school children in uniform, as chaotic scenes of violence unfold behind him\u2014and are sometimes enacted by him. Are the Gulf countries ready? During the Obama years, Saudi Arabia and its Middle East allies were enraged by Washington\u2019s perceived indifference to their security concerns over Iran. They couldn\u2019t seem to convince the president that Tehran\u2019s ambitions posed the greatest security threat to the region. Then came Donald Trump, who seemed eager to adopt their view of Iran as the single most malignant threat to the region\u2014the world, even. Tuesday, Trump delivered, announcing that the United States would pull out of the landmark nuclear deal negotiated by the Obama administration and five other world powers, and reimpose harsh sanctions that badly damaged Iran\u2019s economy. But Riyadh, along with the six-member Gulf Cooperation Council and its Arab allies, may find the Trump administration\u2019s scuttling of the deal, known as the Joint Comprehensive Plan of Action, only initiates a fresh period of uncertainty and instability in the region. That instability may drive up oil prices, much to the delight of Saudi Arabia. But it could also raise new security, diplomatic, and economic concerns. If the deal fully collapses, Iran\u2019s neighbors who opposed it may also one day be challenged by a country\u00a0 with a nuclear program that is no longer under the 24-hour scrutiny of international inspectors. Stormy Daniels\u2019s lawyer is attempting to connect the dots between the Russia probe and the Michael Cohen investigation. Stormy Daniels\u2019s lawyer is attempting to connect the dots between the Russia probe and the Michael Cohen investigation. The question is less whether a dress or an idea is borrowed, than the uses to which it\u2019s then put. Meet the Death Metal Cowboys of Botswana. In black leather decorated with metal studs, they play a pounding style of music that people who know more than me trace to the British band \u201cVenom\u201d and its 1981 album Welcome to Hell. Question: Is this cultural appropriation? Why or why not? The question is inspired by a spasm of social-media cruelty that caught wide attention last week. A young woman in Utah bought a Chinese-style dress to wear to her high school formal. She posted some photographs of herself on her personal Instagram page\u2014and suddenly found herself the target of virulent online abuse. For once, the story has a happy ending. Good sense and kindness prevailed, and instead of her prom being ruined, the young woman exited the dance buoyed by worldwide support and affirmation, most of all from within China. Why did AT&T pay the same company used to funnel hush money to Stormy Daniels? Among the details in a document released by Stormy Daniels\u2019s lawyer Michael Avenatti on Tuesday evening is the description of a series of $50,000 payments by AT&T to Essential Consultants, a shell company owned by Michael Cohen. And although Avenatti would not detail the source of the information in the dossier in an interview with my colleague Natasha Bertrand, AT&T confirmed that it contracted with the company in a statement, and The New York Times says it reviewed documents that support Avenatti\u2019s claims. \u201cEssential Consulting [sic] was one of several firms we engaged in early 2017 to provide insights into understanding the new administration,\u201d AT&T said. \u201cThey did no legal or lobbying work for us, and the contract ended in December 2017.\u201d The seriousness of the problems caused by the president's abrupt exit will be impossible for him to ignore. President Trump has just pushed the plunger on a sequence of crises. The first will be a crisis with allies and other partners. Will they agree to reimpose their sanctions on Iran? It\u2019s not just NATO countries that will have to be cajoled or coerced. Complying with UN-voted sanctions, India reduced its dependence on Iranian crude oil from 13 percent of its imports in 2009\u20132010 to 5 percent in 2014\u20132015. Iran, the second-largest oil supplier to the world\u2019s third-biggest oil importer before the sanctions hit, is rapidly recovering its market share\u2014and India plans to double its imports in the coming year. What\u2019s the plan for getting India back on board? China has emerged as Iran\u2019s largest trading partner. Its trade with Iran jumped 30 percent in the first six months of 2017. China has extended credits to Iran totaling some $35 billion, a significant sum for the shaky Iranian economy. Who will make China stop? Seth Meyers on Saturday Night Live, Obama, Oprah 2020, and whether media elites try too hard to feel the pain of Trump voters In 2011, the comedian Seth Meyers, then the head writer for Saturday Night Live and host of the show\u2019s \u201cWeekend Update\u201d news roundup, mocked Donald Trump at the White House Correspondents\u2019 Dinner. \u201cDonald Trump has been saying that he will run for president as a Republican,\u201d Meyers said, as Trump sat stone-faced in the audience, \u201cwhich is surprising, since I just assumed he was running as a joke.\u201d That same evening, President Barack Obama roasted Trump at length. The evening\u2019s jokes\u2014and the idea that they spurred Trump to run in 2016\u2014have become Washington lore. Meyers, who since 2014 has hosted Late Night on NBC, still refuses to pull any punches where Trump is concerned. In January, he hosted the Golden Globes and, in a clear callback to his 2011 mockery of Trump\u2019s presidential ambitions, winkingly berated Oprah Winfrey, telling her that she doesn\u2019t have what it takes to be president. New theories are challenging a long-standing notion that the difficulty of childbirth is simply an evolutionary trade-off. Harvey Karp, the best-selling author of The Happiest Baby on the Block, has some advice on his website for frazzled new parents: \u201cRemember\u2014your baby\u2019s brain was so big that you had to \u2018evict\u2019 her after nine months, even though she was still smushy, mushy, and very immature.\u201d It\u2019s not an idea unique to Karp. Scientists have long struggled to explain the myriad challenges attending human childbirth compared to other primates, from the relative helplessness of human infants, to the very \u201ctight fit,\u201d as some researchers have put it, between the female human pelvis and the typical size of a child that must pass through it. The mystery was the catalyst for what became known as \u201cthe obstetrical dilemma,\u201d a long-debated though widely accepted hypothesis suggesting that the upright gait of Homo sapiens was accompanied by a narrowing of the pelvis\u2014an evolutionary trade-off that resulted in increased risks to pregnant mothers as they struggled to push large-brained babies through ever-slimmer birth canals. Among other things, the dilemma has been used to suggest that the wider, birth-giving hips of women have hindered them locomotively and athletically\u2014and perhaps even evolutionarily\u2014compared to men. Childish Gambino\u2019s sensational \u201cThis Is America\u201d video implicates the viewer in the misuse of black art. If you search for \u201cThis Is America\u201d on Twitter, you find not only a gushing river of well-deserved praise for Donald Glover\u2019s new work, which has quickly become the most talked-about music video of recent memory. You also find Trump supporters using the moment to spread their messages. The hashtag #ThisIsAmerica sits next to a rant about the deep state. It sits next to a sneering meme about Hillary Clinton. It sits next to a picture of white pioneers, shared by a \u201cEuropean rights activist,\u201d who says, \u201cMost of the people who built America looked like this.\u201d Trending hashtags get hijacked by unsympathetic causes as a matter of course, but Glover knew what he was getting into with the name \u201cThis Is America.\u201d The defining of a nation is the essential task of politics, and Glover\u2019s definition has now been made clear. America is a place where black people are chased and gunned down, and it is a place where black people dance and sing to distract\u2014themselves, maybe, but also the country at large\u2014from that carnage. America is a room in which violence and celebration happen together, and the question of which one draws the eye is one of framing, and of what the viewer wants to see. After a lifetime of intestinal problems, biohacker Josiah Zayner declares war on his own body's microbes. Jeff VanderMeer discusses how writing fiction about environmental crises may jolt readers out of complacency. Two young girls escape Syria in an intimate short film, told largely through home movies. Support 160 years of independent journalism.   TheAtlantic.com Copyright (c) 2018 by The Atlantic Monthly Group. All Rights Reserved.","time":1525690357,"title":"A Design Lab Is Making Rituals for Secular People","type":"story","url":"https:\/\/www.theatlantic.com\/technology\/archive\/2018\/05\/ritual-design-lab-secular-atheist\/559535\/?single_page=true"},{"by":"dsr12","descendants":179,"id":17010756,"kids":"[17011262, 17010993, 17011173, 17011570, 17010991, 17010975, 17011079, 17011201, 17011138, 17010982, 17011008, 17011099, 17011137, 17011189, 17011405, 17010970, 17011221, 17020033, 17014896, 17010988, 17015888, 17011225, 17011882, 17011169, 17011264, 17011159, 17013404, 17012594, 17011045, 17010985, 17011238]","score":309,"text":"Advertisement Supported by By Pamela Druckerman Ms.\u00a0Druckerman is a writer in her 40s, living in Paris. If you want to know how old you look, just walk into a French cafe. It\u2019s like a public referendum on your face. When I moved to Paris in my early 30s, waiters called me \u201cmademoiselle.\u201d It was \u201cBonjour, mademoiselle\u201d when I walked into a cafe and \u201cVoil\u00e0, mademoiselle\u201d as they set down a coffee. Around the time I turned 40, however, there was a collective switch, and waiters started calling me \u201cmadame.\u201d These \u201cmadames\u201d were tentative at first, but soon they were coming at me like a hailstorm. Now it\u2019s \u201cBonjour, madame\u201d when I walk in, \u201cMerci, madame\u201d when I pay my bill and \u201cAu revoir, madame\u201d as I leave. Sometimes several waiters shout this at once. On one hand, I\u2019m intrigued by this transition. Do these waiters gather after work for Sancerre and a slide show to decide which female customers to downgrade? (Irritatingly, men are \u201cmonsieur\u201d forever.) The worst part is that they\u2019re trying to be polite. They believe I\u2019m old enough that the title can\u2019t possibly wound. I realize that something has permanently shifted when I walk past a woman begging for money. \u201cBonjour, mademoiselle,\u201d she calls out to the young woman in a miniskirt a few steps ahead of me. \u201cBonjour, madame,\u201d she says when I pass. This has all happened too quickly for me to digest. I still have most of the clothes that I wore as a mademoiselle. There are mademoiselle-era cans of food in my pantry. But the world keeps telling me that I\u2019ve entered a new stage. While studying my face in a well-lit elevator, my daughter describes it bluntly: \u201cMommy, you\u2019re not old, but you\u2019re definitely not young.\u201d What exactly is this not-young age? I hear people in their 20s describe the 40s as a far-off decade of too-late, when they\u2019ll regret things that they haven\u2019t done. But for older people I meet, the 40s are the decade that they would most like to travel back to. \u201cHow could I possibly have thought of myself as old at 40?\u201d asks Stanley Brandes, an anthropologist who wrote a book in 1985 about turning 40. \u201cI sort of look back and think: God, how lucky I was. I see it as the beginning of life, not the beginning of the end.\u201d Forty isn\u2019t even technically middle age anymore. Someone who\u2019s now 40 has a 50 percent chance of living to 95, says the economist Andrew Scott, a co-author of \u201cThe 100-Year Life.\u201d But the number 40 still has symbolic resonance. Jesus fasted for 40 days. Muhammad was 40 when the archangel Gabriel appeared to him. The Israelites wandered the desert for 40 years. Mr. Brandes writes that in some languages, 40 means \u201ca lot.\u201d And age 40 still feels pivotal. \u201cThe 40s are when you become who you are,\u201d a British author in his 70s tells me, adding ominously, \u201cAnd if you don\u2019t know by your 40s, you never will.\u201d I\u2019m starting to see that as a madame, even a newly minted one, I am subject to new rules. When I try to act adorably na\u00efve now, people aren\u2019t charmed \u2014 they\u2019re baffled. Cluelessness no longer goes with my face. I\u2019m expected to wait in the correct line at airports and show up on time for my appointments. And yet brain research shows that in the 40s, some of these tasks are harder: On average we\u2019re more easily distracted than younger people, we digest information more slowly and we\u2019re worse at remembering specific facts. (The ability to remember names peaks in the early 20s.) You know you\u2019re in your 40s when you\u2019ve spent 48 hours trying to think of a word, and that word was \u201chemorrhoids.\u201d But there are upsides, too. What we lack in processing power we make up for in maturity, insight and experience. We\u2019re better than younger people at grasping the essence of situations, controlling our emotions and resolving conflicts. We\u2019re more skilled at managing money and explaining why things happen. We\u2019re more considerate than younger people. And, crucially for our happiness, we\u2019re less neurotic. Indeed, modern neuroscience and psychology confirm what Aristotle said more than 2,000 years ago when he described men in their \u201cprimes\u201d as having \u201cneither that excess of confidence which amounts to rashness, nor too much timidity, but the right amount of each. They neither trust everybody nor distrust everybody, but judge people correctly.\u201d I agree. We\u2019ve actually managed to learn and grow a bit. We see the hidden costs of things. Our parents have stopped trying to change us. We can tell when something is ridiculous. And other minds are finally less opaque. The seminal journey of the 40s is from \u201ceveryone hates me\u201d to \u201cthey don\u2019t really care.\u201d Even so, the decade is confusing. We can finally decode interpersonal dynamics, but we can\u2019t remember a two-digit number. We\u2019re at or approaching our lifetime peak in earnings, but Botox now seems like a reasonable idea. We\u2019re reaching the height of our careers, but we can now see how they will probably end. And this new age is strangely lacking in milestones. Childhood and adolescence are nothing but milestones: You grow taller, advance to new grades, and get your period, your driver\u2019s license and your diploma. Then in your 20s and 30s you romance potential partners, find jobs and learn to support yourself. There may be promotions, babies and weddings. The pings of adrenaline from all these carry you forward and reassure you that you\u2019re building an adult life. In the 40s, we might still acquire degrees, jobs, homes and spouses, but these elicit less wonder now. The mentors and parents who used to rejoice in our achievements are preoccupied with their own declines. If we have kids, we\u2019re supposed to marvel at their milestones. A journalist I know lamented that he\u2019d never again be a prodigy at anything. (Someone younger than both of us had just been nominated to the United States Supreme Court.) \u201cEven five years ago, people I met would be like, \u2018Wow, you\u2019re the boss?\u2019\u201d the 44-year-old head of a TV production company tells me. Now they\u2019re matter-of-fact about his title. \u201cI\u2019ve aged out of wunderkind,\u201d he says. What have we aged into? We\u2019re still capable of action, change and 10K races. But there\u2019s a new immediacy to the 40s \u2014 and an awareness of death \u2014 that didn\u2019t exist before. Our possibilities feel more finite. All choices now plainly exclude others. It\u2019s pointless to keep pretending to be what we\u2019re not. At 40, we\u2019re no longer preparing for an imagined future life. Our real lives are, indisputably, happening right now. We\u2019ve arrived at what Immanuel Kant called the \u201cDing an sich\u201d \u2014 the thing itself.  Indeed, the strangest part of the 40s is that we\u2019re now the ones attending parent-teacher conferences and cooking the turkey on Thanksgiving. These days, when I think, \u201cSomeone should really do something about that,\u201d I realize with alarm that that \u201csomeone\u201d is me. It\u2019s not an easy transition. I\u2019d always been reassured by the idea that there are grown-ups in the world out there curing cancer and issuing subpoenas. Grown-ups fly airplanes, get aerosol into bottles and make sure that television signals are magically transmitted. They know whether a novel is worth reading and which news belongs on the front page. In an emergency, I\u2019ve always trusted that grown-ups \u2014 mysterious, capable and wise \u2014 would appear to rescue me. I\u2019m not thrilled about looking older. But what unsettles me most about the 40s is the implication that I\u2019m now a grown-up myself. I fear I\u2019ve been promoted beyond my competence. What is a grown-up anyway? Do they really exist? If so, what exactly do they know? Will my mind ever catch up with my face? Pamela Druckerman is a contributing opinion writer and the author of the forthcoming \u201cThere Are No Grown-Ups: A Midlife Coming-of-Age Story,\u201d from which this essay is excerpted. Follow The New York Times Opinion section on Facebook and Twitter (@NYTopinion), and sign up for the  Opinion Today newsletter.  Advertisement    Collapse SEE MY OPTIONS","time":1525674812,"title":"Surviving Your 40s","type":"story","url":"https:\/\/www.nytimes.com\/2018\/05\/04\/opinion\/sunday\/how-to-survive-your-40s.html"},{"by":"ggerganov","descendants":13,"id":17010742,"kids":"[17013309, 17019735, 17013213, 17010766, 17013318]","score":49,"text":"GitHub is home to over 20 million developers working together to host and review code, manage projects, and build software together. \nSign up\n \n              Use Git or checkout with SVN using the web URL.\n             If nothing happens, download GitHub Desktop and try again. Go back If nothing happens, download GitHub Desktop and try again. Go back If nothing happens, download Xcode and try again. Go back If nothing happens, download the GitHub extension for Visual Studio and try again. Go back A proof-of-concept for WebRTC signaling using sound. Works with all devices that have microphone + speakers. Runs in the\nbrowser. Nearby devices negotiate the WebRTC connection by exchanging the necessary Session Description Protocol (SDP) data via\na sequence of audio tones. Upon successful negotiation, a local WebRTC connection is established between the browsers allowing data to be exchanged via LAN. See it in action (2min video):  Try it yourself: ggerganov.github.io\/wave-share The WebRTC technology allows two browsers running on different devices to connect with each other and exchange data. There is no need to install plugins or download applications. To initiate the connection, the peers exchange contact information (ip address, network ports, session id, etc.). This process is called \"signaling\". The WebRTC specification does not define any standard for signaling - the contact exchange can be achieved by any protocol or technology. In this project the signaling is performed via sound. The signaling sequence looks like this:  The described signaling sequence does not involve a signaling server. Therefore, an application using signaling through sound can be, for example, served by a static web page. The only requirement is to have control over the audio output\/capture devices. An obvious limitation (feature) of the current approach is that only nearby devices (e.g. within the same room) can establish connection with each other. Moreover, the devices have to be connected in the same local network, because NAT is not available. The data communicated through sound contains the contact information required to initialize the WebRTC connection. This data is stored in the Session Description Protocol (SDP) format. Since data-over-sound has significant limitations in terms of bandwidth and robustness it is desirable to transmit as few data as possible. Therefore, the SDP is stripped from all irrelevant information and only the essential data needed to establish the connection is transmitted. Currently, the sound packet containing the minimum required SDP data has the following format: The total size of the audio packet is 112 bytes. With the current audio encoding algorithm, the SDP packet can be transmitted in 5-10 seconds (depending on the Tx protocol used). Using slower protocols provides more reliable transmission in noisy environments or if the communicating devices are far from each other. The current approach uses a multi-frequency Frequency-Shift Keying (FSK) modulation scheme. The data to be transmitted is first split into 4-bit chunks. At each moment of time, 3 bytes are transmitted using 6 tones - one tone for each 4-bit chunk. The 6 tones are emitted in a 4.5kHz range divided in 96 equally-spaced frequencies: For all protocols: dF = 46.875 Hz. For non-ultrasonic protocols: F0 = 1875.000 Hz. For ultrasonic protocols: F0 = 15000.000 Hz. To build this project you need Emscripten compiler. Additionally, you need FFTW built with Emscripten. Run the compile.sh script.","time":1525674441,"title":"Show HN: Wave-share \u2013 serverless, peer-to-peer, local file sharing through sound","type":"story","url":"https:\/\/github.com\/ggerganov\/wave-share#wave-share"},{"by":"maybeiambatman","descendants":0,"id":17010740,"kids":"None","score":7,"text":"The threat that tech monopolies pose to democracies is about more than the prices they charge: it\u2019s the concentration of power, data and control over the public space \u2014 and their ability to wield this power over a growing number of economic activities, especially in the infrastructure and technologies of the future. The following companies operate as either monopolies or oligopolies in their respective fields: Google, Facebook, Uber, Airbnb, Amazon, Twitter, Instagram, Spotify. Integrated into everything, everywhere, their technology will blanket the world. Perhaps the final stage in the rise of monopolies is when their economic power morphs into what Marxists sometimes call \u201ccultural hegemony.\u201d That is, where domination can be achieved through controlling the ideas and assumptions available to the public. The idea, associated with philosopher and politician Antonio Gramsci and his criticism of capitalism, is worth considering because there\u2019s little doubt that a techno-utopian view of the world has infected society. Tech is just the latest vehicle for very rich people to use well-tested techniques of buying political influence, monopolistic behavior and avoiding regulation. All technology encodes within it certain values and assumptions about how the world works. Gutenberg\u2019s press was more than a mere printing machine \u2014 it popularized the ideal of free information exchange. The telegraph system transformed people\u2019s perceptions of time and distance, while the radio helped invent the concept of a single shared nationality, culture and language. The medium, remember, is the message. And the medium of digital technology, as a sector, is now monopolizing the whole economy. In 1995, left-wing academics Richard Barbrook and Andy Cameron detailed the philosophy and ideas of the new tech wunderkinds, christening it \u201cThe Californian Ideology.\u201d This ideology represented a fusion of the cultural bohemianism of San Francisco and entrepreneurial free market zeal. Barbrook and Cameron thought it was appealing because it offered a way out of the traditional political struggles over wealth distribution or fairness. A profound faith in the emancipatory qualities of technology allowed the techies to paper over any inconsistencies, because they promised that when the revolution arrived everyone would be great and cool and fulfilled and rich. All you needed to get to utopia was a belief in \u201cdisruption,\u201d the idea that progress is achieved through smashing up old industries and institutions and replacing them with something new and digital. This is the secret behind the digital revolution. The reason that startups flock to Silicon Valley is not just the promise of building a better world \u2014 it\u2019s because that\u2019s where the venture capital is. Money and ideas in Silicon Valley have a very complicated relationship. Even start-up visionaries and wide-eyed socially-minded inventors need money to survive, to pay extortionate Bay Area rent and to hire the best programmers. Silicon Valley runs according to a Faustian pact: money in exchange for world-changing ideas. But investment brings with it new responsibilities, and suddenly there are profit margins, quarterlies and growth targets. In some ways, tech is just the latest vehicle for very rich people to use well-tested techniques of buying political influence, monopolistic behavior and regulation avoidance, to help them become even richer. Doing it through tech allows them to add a glossy veneer of progress on top of some very familiar behavior. The iPhone and web browsers have infected us all with the alluring idea that disruption is liberation, total individualism is empowerment and gadgets equal progress. Over the years, the big tech firms have very carefully cultivated the Californian Ideology. Even though they are massive multi-billion-dollar corporations with huge PR teams, they pitch themselves as anti-establishment; even though they are built on a model of data extraction and surveillance capitalism, they purport to be promoting exciting and liberating technology; even though they are dominated by rich white guys, they talk of social justice and equality. I sometimes think it must be very confusing to be Mark Zuckerberg. In 2014, only 2 percent of Facebook staff were black and less than a third were women. They were also caught providing inaccurate information about user data matching to the European Commission during their acquisition of WhatsApp. And yet, later that year, Zuckerberg said that \u201cour philosophy is that we care about people first.\u201d The worse these companies behave and the richer they become, the more they spend on looking cool and talking about fairness and community. This cannot be a coincidence. Wealthy corporations cultivate the popular ideas of the day not just by direct pressure, but also by funnelling money towards individuals and ideas that see the world as they do. And through their funding of think tanks and, increasingly, academia, the public imagination about technology is rebalanced in a subtle but definite way; the pervasive influence of Google is one significant example. But it\u2019s much more than that. The iPhone and web browsers we use have carried the Californian Ideology around the world, infecting us all with the alluring idea that disruption is liberation, total individualism is empowerment and gadgets equal progress. Sometimes these things are true, though they are hardly iron laws of social change. But believing it means the tech firms march off into the future and then come back and hand us a map to guide us through it. It is hard to imagine the coming years without schools full of iPads (Apple), VR headsets (the Facebook-owned Oculus) and coding classes (run by Google). One UK MP suggested running the National Health Service like Uber, while another pitched the idea of Airbnb-style room rentals for overnight patients. Heaven help us all. Research from the NSPCC found that almost half of all children want to pursue a career in tech. An even more depressing statistic is that 30 percent hope to become the one-in-a-million YouTuber who actually makes a career of it. Every country wants to build their own Silicon Valley, and every city has ambitions to be a tech hub. Read any political manifesto from across the spectrum, and you\u2019ll find yourself lost in a world of smart cities, lean governments and flexible workers. And to whom do we look in order to solve our collective social problems? It\u2019s no longer the state, but the modern tech-geek superhero. Space travel and climate change has fallen to Elon Musk. We look to Google to solve health problems and sort out ageing. Facebook gets to decide what free speech is and battle against fake news, while Amazon\u2019s Jeff Bezos saves the Washington Post from bankruptcy and funds scholarships. One UK MP suggested we might run the National Health Service like Uber, while another pitched the idea of Airbnb-style room rentals for patients who needed to stay overnight. Heaven help us all. Total victory for the monopoly is not over economics or politics. It\u2019s over assumptions, ideas and possible futures. Because when that happens, Big Tech won\u2019t need to lobby or buy out competitors. They will have so insinuated themselves in our lives and minds, that we won\u2019t be able to imagine a world without them. Excerpted from the new book The People vs. Tech: How the Internet is Killing Democracy (and How We Can Save It) by Jamie Bartlett. Published by Dutton, an imprint and division of Penguin Random House LLC, New York. Copyright \u00a9 2018 by Jamie Bartlett. \u00a0 Jamie Bartlett  is the bestselling author of \"The Dark Net\" and \"Radicals Chasing Utopia: Inside the Rogue Movements Trying to Change the World.\" He is the Director of the Centre for the Analysis of Social Media at the thinktank Demos. He also writes on technology for the Spectator, the Telegraph and other publications.","time":1525674395,"title":"Dangers that Facebook, Google and the other tech monopolies pose to our society","type":"story","url":"https:\/\/ideas.ted.com\/heres-the-real-danger-that-facebook-google-and-the-other-tech-monopolies-pose-to-our-society\/"},{"by":"eatonphil","descendants":32,"id":17009875,"kids":"[17010031, 17010055, 17010531, 17013950, 17009899, 17009932]","score":150,"text":"\n\n\n\n\n\n\n\n The last couple of months have been tremendously exciting for everyone working\non Cilium and BPF. We have witnessed a fast growing community of\nCilium users as well as the rapid increase of BPF usage and development with\ncompanies such as Google joining the existing already strong BPF community of\nengineers from Facebook, Netflix, Red Hat and many more. Possibly the strongest\nsignal on the success of BPF has been the decisions of the Linux kernel\ncommunity to replace the in-kernel implementation of iptables with BPF. All of this has allowed us to advance BPF quickly and mature the Cilium project\nvery effectively. Our warmest\nshoutouts go to everyone who has joined us on this incredible\njourney since we initially announced Cilium at DockerCon\n2017. Your support in the form of\ncontributing code, providing feedback and spreading the word has been\nincredible. Today, we mark the release of Cilium 1.0 and assign the first ever stable\nrelease number. Starting with this release, we will also provide all of the\nguarantees and processes required to run Cilium in production environments: This blog post focuses on the functionality provided by the Cilium 1.0 release.\nWe have published a separate post that provides additional background and use\ncases as well as a preview of the service mesh\/sidecar acceleration work. Cilium - Rethinking Linux Networking and Security for the Age of Microservices The following list describes the functionality that Cilium provides as of 1.0.\nYou can find more detailed descriptions in the functionality overview\nsection of the Cilium documentation. \n\n\n\n\n\n\n\n Highly efficient BPF datapath:\nBPF is the underlying Linux superpower doing the heavy lifting on the\ndatapath by providing sandboxed programmability of the Linux kernel with\nincredible performance. Read more about the powers of BPF in this\nblog\nor in the BPF reference guide. Fully Distributed: All datapath elements are fully distributed\nacross the cluster and run at the most efficient layer in the operating\nsystem on each cluster node. Service Mesh datapath: BPF allows us to build the ideal dataplane for\nthe fast growing service mesh space. Cilium 1.0 already provides\ntransparent injection of proxies such as Envoy. Future versions of Cilium\nwill provide acceleration of sidecar proxies. We have published a set of\nearly sidecar proxy performance benchmarks CNI and CMM plugins:\nThe CNI and CMM plugins enable integration with\nKubernetes,\nMesos, and\nDocker to provide networking,\nload balancing and security for containers. Network Security on both the Packet and API level:\nCilium combines packet\nbased network security and\nsegmentation with transparent API aware\nauthorization\nto provide security for both traditional deployments and evolving\nmicroservices architectures. Identity Based:\nInstead of relying on source IP addresses to identify workloads, Cilium\nencodes the workload identity in every packet to provide highly scalable\nsecurity. This portable design allows the identity to be encoded in any IP\nbased protocol and is aligned with upcoming concepts such as\nSPIFFEE or Kubernetes' Container\nIdentity Working\nGroup. IP\/CIDR Based:\nIf identity based enforcement is not applicable, IP\/CIDR based security can\nbe used to control access. Whenever possible, Cilium offers abstractions to\navoid hardcoding IP addresses in security policies.  An example of this is\nthe ability to define policy based on Kubernetes service\nnames. API Aware Security:\nThe increasing usage of protocols such as HTTP\/REST, gRPC and Kafka renders\nIP and port based security insufficient.  The built-in awareness of a\ngrowing list of API and data store relevant protocols allows enforcing\nleast privilege security at the right granularity. Distributed and Scalable Load Balancing:\nHigh performance Layer 3-4 load balancer using BPF for service to service\nconnectivity with support for flow hashing and weighted round-robin. The BPF\nhashtable based implementation provides O(1) performance which means that the\nperformance will not drop as you increase the number of services. The load\nbalancer can be configured in two ways: Simplified Networking Model:\nDecoupling security from addressing simplifies the networking model\ndramatically: A single layer 3 network space provides the connectivity\nfor all endpoints which are then segmented and secured using the\npolicy layer on top. This simplicity tremendously helps scaling and\ntroubleshooting. Networking can be configured in two modes: Visibility\/Telemetry: Similar to policy, visibility is provided on both\nthe network packet and API call level. All visibility information includes\nrich workload level metadata such as container\/pod labels and service names,\ninstead of just IP addresses and port numbers. Troubleshooting: Cilium is simple to install and use, in particular on Kubernetes: xterm  The above example is a summary of the hands-on minikube\ntutorial that walks\nthrough applying a HTTP aware network policy step by step. More tutorials\ncan be found in the getting started\nsection. For further information on installing Cilium, see the Kubernetes Quick\nInstallation Guide\nor refer to the full list of installation\nguides Cilium 1.0 is an exciting milestone for all of us but we are already deep into\nthe planning of Cilium 1.1. So what is on the roadmap for 1.1 and beyond? Multi Cluster Service Routing: The simplicity of Cilium\u2019s networking model\nand the decoupling of addressing and policy allows for easy expansion across\nclusters. With this expansion, Cilium will start supporting Kubernetes\nservice routing across multiple clusters without requiring complex proxy or\nIngress solutions while providing the full set of identity based and API\naware security. Integration with OpenTracing, Jaeger and Zipkin: The minimal overhead of\nBPF makes it the ideal technology to provide tracing and telemetry\nfunctionality without imposing additional system load. Policy support for additional API protocols: We already have several\nadditional application protocols in mind that we will support in future\nreleases to further improve security. CRI support: Repeatedly requested by various members of the community, we are\nlooking forward to supporting CRI to properly abstract the container runtime. Non container workloads: The BPF datapath is not limited to container\nabstractions, it just happened to be the first use case we focused on. Future\nversions will provide APIs and documentation on how to integrate with native\nLinux tasks, VMs and how to bridge the identity based security space to\nexisting worlds using IP addresses that cannot be migrated. You can find the details of the 1.1 release planning in this github\nissue. Feel free to comment or\nopen GitHub issues if you would like to see particular functionality in future\nCilium releases.","time":1525658412,"title":"Cilium 1.0: Bringing the BPF Revolution to Kubernetes Networking and Security","type":"story","url":"https:\/\/cilium.io\/blog\/2018\/04\/24\/cilium-10\/"},{"by":"bra-ket","descendants":40,"id":17009771,"kids":"[17011386, 17009887, 17009880, 17013060, 17010086, 17016334, 17010562, 17010583]","score":107,"text":"In retrospect, Richard Neal knows he should have just gone home. It was already nearly 4 a.m. on a sticky June night in 2008, and the LaGuardia Houses on the Lower East Side were crawling with cops. It was the kind of situation Neal normally prefers to avoid. Where police are, he\u2019d rather not be. A trim, soft-spoken 59-year-old, Neal has had his share of problems with the law. More than his share, in fact, as he\u2019ll readily admit. He has spent nearly a quarter of his life in prison. There was a burglary charge in 1978, followed by an assault charge in 1982. A nonviolent drug-distribution charge in 2002 landed him back inside. Today, he acknowledges these incidents with some regret, in a voice that\u2019s incongruously deep and sometimes trails off mournfully. He especially regrets the crimes that involved hurting other people. But he\u2019s a bit old for that kind of thing now. So Neal wasn\u2019t worried when he saw police prowling the grounds of the Lower East Side project that night in 2008. For once, Neal wasn\u2019t doing anything wrong. Even when two police officers approached and began asking questions, Neal was feeling just fine. His life had been inching back toward some semblance of order recently. After months staying with friends and family and bouncing between city homeless shelters \u2014 common way stations for newly released prisoners \u2014 Neal had finally found an apartment. For the first time in a long time, he had a place of his own. And the fact that his new home was near the LaGuardia Houses, where his ailing mother lived, was just a bonus. Besides, he\u2019d been out of trouble for a good long while, and he certainly wasn\u2019t up to anything that night. He and a friend were just milling around outside the building, watching the action. In court testimony, a police officer would later describe Neal as \u201cvery calm,\u201d \u201cjust talking [and] walking\u201d with his friend. Not making a scene. And when one of the officers, glancing down at Neal\u2019s baggy jeans, asked what he had in his pocket, Neal was honest. \u201cI told him, \u2018It\u2019s a knife,\u2019 \u201d Neal says today. There was no use in hiding it. It was clipped to the side of his jeans, for anyone to see. He\u2019d been using the knife earlier that day, he said, at one of the odd maintenance jobs he\u2019d been working in the years since he\u2019d left prison. Because of the life he\u2019d led, Neal says, he \u201cknew a little law\u201d by the time he found himself \u2014 at age 53 \u2014 talking to police once again. He knew that the blade on his knife wasn\u2019t longer than four inches, the limit under New York City\u2019s administrative code. And aside from the length restriction, there\u2019s no law against carrying a folding knife in New York. It wasn\u2019t a butterfly knife or a brass-knuckle knife, not some exotic weapon from the movies. The Sheffield utility knife Neal had in his pocket is the kind of thing sold at hardware and sporting-goods stores all over the city. At the time, that model and ones more or less identical to it were stocked at Auto Zone, Pep Boys, Home Depot, Paragon Sports, and several other reputable hardware and outdoor-gear shops in the five boroughs. It\u2019s the kind of thing your outdoorsy uncle might carry. Today you can buy one on Amazon for less than 15 bucks. Neal says he didn\u2019t start worrying that night until the officer used the term \u201cgravity knife.\u201d He\u2019d never heard that phrase before. And he really started to worry when the officer explained that his little Sheffield could land him in prison \u2014 for years. Neal ended that night in a squad car. There was only one problem: The knife he was carrying was not a gravity knife. At least, not by most of the world\u2019s definition. According to the vast majority of police departments and district attorneys in New York State \u2014 not to mention knife manufacturers, labor unions, and almost everyone else who knows a thing about knives \u2014 what Neal was carrying was a perfectly legal folding knife. When gravity knives were banned under New York State law in the 1950s, the legislature actually had a very specific style of weapon in mind \u2014 a foot-long terror that bears no resemblance to a knife like the one Neal had. True gravity knives, for all intents and purposes, have been extinct for the better part of a century; today they\u2019re relegated mostly to the antiques section on eBay. Nonetheless, under the department\u2019s unique interpretation of Penal Code 265.01, almost every pocketknife on the market today can be considered a gravity knife. It\u2019s as if authorities in New York City were using an antiquated law against flintlock muskets to prosecute BB-gun owners. And the prohibition is as strict as it is all-encompassing. A knife that can be shoehorned into that definition is not only illegal to carry, it\u2019s illegal to possess at all, even within one\u2019s home. The only narrow exceptions apply to those \u201cactively engaged\u201d in hunting and fishing, and are essentially meaningless in New York City. The penalties are severe, too, as Neal would learn. As a prior offender, he was eligible for a felony \u201cbump up,\u201d rendering the pocketknife Neal possessed the legal equivalent of an unlicensed, unloaded pistol. Though the court said he likely had no idea his knife was illegal, and he wasn\u2019t accused of using it toward any nefarious end, he was convicted nonetheless. After a series of appeals, he was sentenced to six years in prison. These days, Neal is circumspect. \u201cIf I knew that knife had the capabilities of a gravity knife,\u201d he says, \u201cI would have never had it in my pocket.\u201d The police in his neighborhood knew him. Why would he have given them an excuse to engage? It\u2019s now June of this year, and Neal\u2019s seated on a couch in his daughter\u2019s apartment, at the Polo Grounds housing project in East Harlem, hands clasped atop his lap. He\u2019s been out of prison a few weeks, having served his maximum sentence. He\u2019s missed a lot in that time \u2014 not least the birth of his grandchild, cooing just a few feet away, and the death of his mother, who succumbed to heart disease while he was gone. Through tears, he recalls being released just long enough to attend her wake. Neal believes he was treated unfairly, and perhaps that\u2019s not surprising. But what may be surprising is how many people agree with him [Single page] [ For years, New York\u2019s gravity-knife law has been formally opposed by a broad swath of the legal community. Elected officials call the statute \u201cflawed\u201d and \u201cunfair.\u201d Defense attorneys call it \u201coutrageous\u201d and \u201cridiculous\u201d \u2014 or worse. Labor unions, which have seen a parade of members arrested for tools they use on the job, say the law is woefully outdated. Even the Office of Court Administration \u2014 the official body of the New York State judiciary \u2014 says the law is unjustly enforced and needs to change. They\u2019ve petitioned the legislature to do just that. But despite significant pushback from many legal experts, the half-century-old statute is the same as it ever was. In fact, it\u2019s been enforced with increasing frequency in recent years. Neal didn\u2019t know it at the time, but on that summer evening in 2008, he became part of a remarkable surge in gravity-knife arrests in New York City over the past 10 years. Law enforcement agencies don\u2019t track gravity-knife crimes as a class, which may explain why the frequency of those arrests has gone largely unreported in the news media. But a Village Voice analysis of data from several sources suggests there have been as many as 60,000 gravity-knife prosecutions over the past decade, and that the rate has more than doubled in that time. If those estimates are correct, it\u2019s enough to place gravity-knife offenses among the top 10 most prosecuted crimes in New York City. The increase seems to be the result of a confluence of forces. Changes in knife design have played a part, as modern features have nudged the most popular styles closer to the edge of the legal definition. But the NYPD\u2019s stop-and-frisk program also may be one driver. A prime rationale for the policy has always been weapon recovery; former NYPD commissioner Ray Kelly put that goal front and center in a 2013 Wall Street Journal op-ed, pointing out that stop-and-frisk had \u201ctaken tens of thousands of weapons off the street\u201d over the previous decade. But about 80 percent of weapons recovered under stop-and-frisk were knives, according to an analysis of the department\u2019s own statistics. And experts say the vast majority of those were likely misclassified as \u201cgravity knives.\u201d Whether deliberate or not, dramatically expanding the definition of an illegal knife has not only landed thousands of innocent people in jail \u2014 it also had the effect of making stop-and-frisk appear far more effective than it actually was. Darius Charney is a senior staff attorney at the Center for Constitutional Rights (CCR), one of the organizations that brought a landmark lawsuit against New York City, resulting in major reforms to the NYPD\u2019s stop-and-frisk practices. He said the Voice\u2018s analysis illustrates what they\u2019ve always argued: that stop-and-frisk is really about pursuing low-level crimes, not combating violence. \u201cWhen you\u2019re recovering a weapon which is really just a gravity knife, it\u2019s not about violent crime,\u201d Charney says. \u201cIt really calls into question the entire rationale that they\u2019ve been using for years.\u201d Gravity-knife arrests may be popular for another reason. Most, like Neal\u2019s, result from simple observation of a \u201cpocket clip,\u201d often readily visible. All officers need to do is keep their eyes peeled, and they can add another misdemeanor to their tally \u2014 or, if they\u2019re lucky, a felony. Matt Galluzzo, a former assistant district attorney in Manhattan, now a defense attorney in private practice, says that for many officers, a gravity-knife arrest is simply a hard collar to pass up. \u201cYou don\u2019t have to fight the guy, you don\u2019t have to chase him,\u201d Galluzzo says. \u201cIt\u2019s an easy way to make an arrest. And they\u2019re under pressure to make arrests.\u201d A poster on Officer.com, a verified online message board for law enforcement officers, put it bluntly in 2013 when he advised a rookie to be on the lookout for \u201cGKs\u201d: \u201cmake sure they have a prior conviction so you can bump it up to that felony!!!\u201d Most of the D.A.s in the state \u201chave never prosecuted a gravity-knife case, or haven\u2019t prosecuted one in 30 years,\u201d according to a spokesperson for the District Attorneys Association of the State of New York. Even just beyond the city limits, gravity-knife prosecutions are exceedingly rare. While the population of the Bronx is roughly equal to that of Suffolk County on Long Island, the Bronx prosecuted more than 10 times as many likely cases in 2013 as its counterpart across the water. Even worse, critics charge, is that officials have prosecuted knife users aggressively while doing little to address the source of those same knives, which are sold openly at reputable retailers all over the city. New York State assemblyman Dan Quart, a Democrat from Manhattan, says there\u2019s an obvious contradiction at play: \u201cYou can walk in and purchase one of these knives over the counter,\u201d he says, \u201cand then walk out and get arrested.\u201d Cases like Neal\u2019s that result in long prison sentences are unusual. But thousands end up in handcuffs every year. Of the dozens of cases examined by the Voice, few involved instances of violence and most saw individuals arrested for possessing a knife they used for work. Since 2003, knife-carrying maintenance workers, plumbers, coffee-shop employees \u2014 even a Bible-camp counselor \u2014 have landed in jail. The heaviest consequences fall on economically disadvantaged defendants, attorneys say, those who are least able to fight the charge, but the arrests sometimes cut across class lines. A well-known visual artist, John Copeland was arrested in 2010 for a knife he used to cut canvas in his studio. Nate Appleman, a food-world heavyweight and contestant on The Next Iron Chef a few years back, was arrested on account of the pocketknife he uses to open cardboard boxes. Professional photographer Steven Counts had never been in trouble with the law \u2014 not even so much as a speeding ticket \u2014 when he was surrounded by five officers in downtown Manhattan last summer. Counts was on his way to lunch when one of them spotted, on the pocket of his jeans, the clip for a knife he uses to construct studio backdrops. Stagehands are so frequently targeted that the major union representing them started publishing legal advice about pocketknives in its monthly newsletter. The racial breakdown of stops is also striking. Of the thousands of arrests that resulted from stop-and-frisk encounters, 86 percent of the total involved black or Hispanic suspects. And a Voice analysis also shows that white suspects are significantly more likely to be let go, even when they\u2019re caught carrying knives. Only 35 percent of white suspects found with knives \u2014 virtually any of which might meet the NYPD\u2019s ecumenical definition \u2014 are arrested, while 56 percent of black and Hispanic suspects are ultimately booked. Carla Glaser, 47, who served as a juror on a gravity-knife case in Manhattan, calls the situation \u201cludicrous.\u201d She still feels sick about the conviction she was compelled to hand out, to a man who was initially stopped by police for being in a city park after nightfall. Although the law was, in her view, deeply flawed, she felt she had no choice but to vote with the majority. Glaser herself carries a Swiss Army knife on her keychain. \u201cIt just seemed like a trumped-up charge,\u201d she says. \u201cAnd it certainly doesn\u2019t seem like it\u2019s enforced equally across the board.\u201d The original gravity knife \u2014 the type legislators targeted when they banned them half a century ago \u2014 bears no resemblance to the kind that landed Richard Neal and thousands of others in jail over the last decade. Developed by the German military for use by paratroopers during World War II, the idea behind a gravity knife was simple: An unlucky parachutist who found himself in a tight spot \u2014 tangled in a tree, for example \u2014 would be able to access the knife even with injuries or limited mobility. Simply press a button and the blade would literally fall out of the handle and lock in place. The knives were legal through the early 1950s and might have stayed that way, if not for a national backlash against their close cousin, the now-infamous switchblade. Cheap, widely available, and intimidating, with blades up to 12 inches, switchblades had become increasingly common during the early part of the 20th century. By the 1950s they had become the stuff of nightmares, closely associated with inner-city youth gangs, thanks in part to films like Rebel Without a Cause and Blackboard Jungle, which ends in a classroom brawl between a badly outnumbered public school teacher and his crazed, switchblade-wielding students. See also: On Switchblades, \u2018Cheap Dime Store Hoods\u2019 and That Wet End, Lachance Pocketknives were already a commonplace tool in 1950s America, but the legislature saw these new weapons as something different. Many of the cheapest varieties didn\u2019t even have a cutting edge, just a point, and a \u201cknife\u201d like that was not designed for whittling. Some lawmakers argued that they were more dangerous, even, than pistols. Finally, in 1954, New York State became the first to pass a law making them illegal. The legislature didn\u2019t target gravity knives at the time \u2014 they were still rarely seen in the U.S. But after switchblade bans went into effect, the knife industry saw an opportunity. Even though they were nearly identical in design, gravity knives lacked a spring, a key characteristic of the newly illegal switchblades. So manufacturers stuck with warehouses full of worthless knives simply removed the springs and went on selling, calling the new products \u201cgravity knives.\u201d See Also: Meet New York City\u2019s Resident Knife Nerds They weren\u2019t exactly like the original paratrooper knife, but they were close enough, and young people eagerly adapted. The New York Times noted in 1956 that teenage \u201choodlums\u201d had taken to openly taunting police officers with their gravity knives, knowing full well that there was nothing the cops could do. Later that same year, the New York State legislature closed the loophole it had created, designating gravity knives along with switchblades as \u201cdangerous weapons,\u201d and banning their sale or possession: the law that still stands today. Other states soon followed suit. Finally, in 1958, the federal government banned the importation and interstate transport of both switchblades and gravity knives. The prohibition effectively killed the domestic market, and after that, true gravity knives largely vanished from store shelves. When she arrives at a midtown caf\u00e9 in early April, Hara Robrish has a huge stack of manila folders cradled against her chest. Dressed in a dark blazer and knit blouse, she moves quickly. She pulls up a metal stool and sets her folders on a tall round table. The table wobbles slightly. The pile rises almost to her chin. \u201cI\u2019ve been interested in this area [of the law] for a very long time,\u201d Robrish says with a laugh, eyeing the heap of documents. Robrish, a staff attorney at the Legal Aid Society since 2005, has been following gravity-knife cases nearly since her career began. The folders in front of her are filled with newspaper clippings and photographs, purchase receipts and court transcripts from the dozens of cases she\u2019s handled over the years. She found gravity-knife cases troubling from the start. \u201cI was seeing clients who were coming to me with these knives that they were buying at Home Depot and Ace Hardware and True Value,\u201d Robrish says. Many had never been in trouble with the law, and didn\u2019t seem like the kind of defendant who was up to no good. \u201cI just couldn\u2019t fathom that they were being prosecuted,\u201d Robrish says. She peels open one of the folders and, after a moment, pulls out a dog-eared packet of papers and starts reading aloud: \u201cClient was working as a stagehand and was stopped by police at Times Square\u2026.Client was stopped on his way home from work at Starbucks\u2026\u201d Robrish\u2019s clients were continuously baffled by their arrests. They\u2019d never intended to purchase an illegal knife, they said; they\u2019d never even heard of a gravity knife. The ones they owned weren\u2019t marketed or labeled as such. Like so many legal problems, Robrish explains, the crux of the matter comes down to the arcane language of the statute. Under Penal Law 265.01, a gravity knife is defined as any knife that opens with \u201cthe force of gravity or the application of centrifugal force\u201d and has a blade that locks into place by means of a \u201cbutton, spring, lever, or other device.\u201d Courts have interpreted that to mean that any knife that can be opened with a \u201cwrist flick\u201d \u2014 a movement something like what a fan dancer might do \u2014 qualifies as a gravity knife. A long list of court cases have turned on exactly that question, which seems straightforward enough. The problem, Robrish came to realize, is that with enough force, and enough practice, virtually any pocketknife can be flicked open like a \u201cgravity knife,\u201d whether it was designed to operate that way or not. \u201cA person might have one of these knives, and they\u2019ve never in their lives tried to open it that way,\u201d Robrish says. \u201cThey have no idea that it does open that way.\u201d Jim Furgal, a former knife-industry representative who frequently testifies as an expert witness at gravity-knife trials, said the language of the statute is part of the problem. But changes in knife design have also exacerbated the issue. In the 1960s, most pocketknives looked like the classic Swiss Army variety, Furgal explains. They were designed to be opened with two hands, typically by means of a small fingernail indent on the blade. On two-handed knives like those, the spring pressure holding the blade in the closed position is considerable. Even with a vigorous flick, it won\u2019t open. But beginning in the mid-1990s, more and more companies began designing their knives to open with only one hand. Most models of this type have a small \u201cthumb stud\u201d on the blade for just this purpose. It\u2019s a convenience feature, Furgal explains, so the user can keep one hand free for other tasks. But that design change had an unfortunate side effect. For a blade to easily open with one hand, the spring pressure holding the blade in the closed position has to be relatively light. That reduced tension makes such knives far easier to \u201cflick.\u201d Simple wear-and-tear compounds the problem, Robrish found. After years of use, the hinge of a knife has a tendency to loosen up; a knife that was perfectly legal when it was purchased could actually become illegal over time. A quarter-turn of a screw is all it takes for a worn-out knife to become a potential felony. To Robrish, the whole thing seems crazy. The daughter of a longtime defense attorney, Robrish is the kind of passionate public defender who uses words like unjust with earnestness. She finds it unbelievable that her clients\u2019 fate would hang on such an obviously subjective test. It gives far too much discretion to an officer, in Robrish\u2019s view. Other legal experts offer the same criticism. Galluzzo, the former district attorney, recalled a trial in which an officer bluntly testified about his own haphazard enforcement of the gravity-knife statute. \u201cThe judge was just dumbstruck,\u201d Galluzzo says. \u201cThe officer said, \u2018When I find someone with one of these knives, sometimes I arrest him, sometimes I give him a summons, sometimes I just let him go.\u2019 \u201d Galluzzo\u2019s partner, Zachary Johnson, also a former district attorney in Manhattan, adds that such discretion is supposed to be exercised by prosecutors, not cops on the beat. \u201cAn officer should be making an arrest every time or none of the time,\u201d Johnson says. \u201cOtherwise it\u2019s just not fair.\u201d Anecdotally, many defense attorneys report that the suspects most often arrested are black or Hispanic, a hunch supported by our analysis of stop-and-frisk data. If almost every knife out there is a potential crime, the only thing standing between home and jail is the discretion of an officer \u2014 to flick, or not to flick? And in the aggregate, a Voice data analysis shows, officers are nearly twice as likely to arrest non-white suspects, while letting their white counterparts go. Charney, of CCR, says that this, too, comports with the broader picture of policing in New York City, where racial minorities are far more likely to be prosecuted for crimes of all types. When an officer has discretion, Charney says, \u201cthat\u2019s where a lot of these implicit racial and ethnic biases come into play.\u201d Robrish wasn\u2019t the only one in her office who\u2019d taken note of the gravity-knife problem. Colleagues had their own accounts; the electricians and building supers; the plumber stopped on a subway platform, in his work uniform, still carrying his tool belt. Others had noticed too. Daniel Gilloon, a representative with the International Alliance of Theatrical Stage Employees, a trade union, says arrests of its members have become so routine that the leadership had to get involved. Now, several times a month, IATSE\u2019s president sits down to send form letters to local D.A.s, on the behalf of this or that member, explaining what the knife is for. In his industry, Gilloon adds, pocketknives aren\u2019t just common but, in fact, mandatory equipment. Stagehands who show up without a knife can actually be disciplined for coming to work unprepared. \u201cIt happens all the time,\u201d he says of the arrests. See Also: So What Knives ARE Legal in New York City, Anyway? The Answer Might Surprise You Defense attorneys say that D.A.s will often reduce or even drop charges if a suspect can prove the knife is used for work. But for people in informal jobs \u2014 or people whose supervisors aren\u2019t attuned to the problem \u2014 that\u2019s sometimes easier said than done. And an arrest, even an unjustified one, isn\u2019t always something you want to share with your employer. In 2008, Robrish started collecting stories from her colleagues and compiling the folders that are now bulging at their seams on the caf\u00e9 table. She wasn\u2019t sure exactly what she was going to do with them. But she felt like she needed to do something. Almost every word of the gravity-knife statute has been litigated at some point in New York\u2019s courts. Many of the challenges that make it to appeal have to do with the propriety of a search. Since so many arrests stem from that ubiquitous pocket clip, attorneys have tried, repeatedly, to argue that the clip itself shouldn\u2019t constitute probable cause. A wide variety of tools have pocket clips, after all, and there\u2019s no way to tell what\u2019s attached to the other end, but the courts have so far rejected that defense. The \u201cflick\u201d itself is another heavily litigated issue. Robrish says she routinely has clients arrested for possession of supposedly \u201cflickable\u201d knives that prove far less flickable when she herself inspects them. In one of her earlier cases, when she examined the recovered knife in the Manhattan prosecutor\u2019s office, she found that neither she nor the assistant D.A. were able to duplicate the flick of the arresting officer. Robrish chalks it up to practice. \u201cThe police have become very adept at opening these knives,\u201d Robrish says \u2014 a sentiment echoed by other attorneys. Yet defendants often report that arresting officers have to make several attempts to flick a knife open during arrests. Steven Counts, the photographer, says it took \u201cthree or four tries\u201d in his case. Clayton Baltzer, the Bible-camp counselor and seminary student who was arrested on a visit to New York in 2007, tells the Voice that two officers tried to flick his knife, unsuccessfully, and only a third, after several energetic attempts, was able to make it snap into place. Defense attorneys say this kind of thing should cast doubt on an arrest. If it takes repeated tries to get a knife to open, maybe it\u2019s not a gravity knife after all, they argue. But the statute doesn\u2019t say a knife has to open easily with a wrist flick, or that it has to be designed to open that way. Even if an officer can\u2019t reproduce the \u201cflick\u201d in court, that\u2019s not always a successful defense. On the witness stand during a trial in 2003, a police officer demonstrating a knife\u2019s \u201cflickability\u201d managed to get it open on only two out of eight attempts. The defense moved to strike the knife as evidence, arguing that the failures were prima facie illustrations that the knife didn\u2019t meet the definition. But the judge denied that motion, ruling instead that the knife had simply \u201cmalfunctioned.\u201d That defendant got six years in prison when he was convicted. The term \u201ccentrifugal force,\u201d contained in the statute, has also been challenged, perhaps for good reason. Strictly speaking, centrifugal force \u2014 which some physics professors call the \u201cfalse force\u201d \u2014 doesn\u2019t exist. Casting your mind back to high school physics class, you might recall learning that the feeling you have while spinning on a merry-go-round is caused by inertia. It\u2019s also inertia, some defense attorneys have argued, that causes a knife to \u201csnap\u201d open with a wrist flick \u2014 in other words, the statute has the science wrong. In 2009, when lawyers for Reginald Herbin tried to introduce a physics expert to explain that fact, the court wouldn\u2019t allow him to testify. The physics testimony would have \u201cconfused\u201d the jury, the court said, by \u201cdefining centrifugal force inconsistently with the statutory definition.\u201d Herbin\u2019s conviction was affirmed, and he ultimately spent four years in prison. The courts have also repeatedly held, as they did in Richard Neal\u2019s case, that a defendant doesn\u2019t have to know a knife is illegal to be charged for possessing it. But the wide availability of alleged gravity knives is a big concern for defense attorneys. An informal Voice survey of several shops in New York City found that knives meeting the statutory definition were common on store shelves as recently as August. In a decision in 2007, the court noted that one specific model of alleged gravity knife had sold 1.7 million units in the previous year alone, more than 60,000 of those in the state of New York. Robrish, for one, thought it was all terribly unfair. If these knives were so extraordinarily dangerous, why didn\u2019t the D.A.s go after the retailers? In 2010, Manhattan District Attorney Cyrus Vance Jr. did just that. Using hidden cameras, his investigators carried out a series of stings on retail giants like Home Depot and Eastern Mountain Sports, and found them selling what he alleged were gravity knives. The videos are somewhat farcical: Fresh-faced, name-tagged employees struggle, at the direction of investigators, to get the knives on their shelves to flick open, and have a great deal of trouble doing it. Steve Holmes, a spokesman for Home Depot, the only one of the targeted retailers who returned calls for comment, said his company didn\u2019t realize back then that its knives violated local laws. Vance\u2019s office declined to discuss any aspect of the investigation, but a few things are clear: Though Vance determined the stores involved had made more than $1.9 million from the sale of allegedly illegal knives, he offered the largest businesses a \u201cdeferred prosecution agreement,\u201d a form of legal settlement in which charges are withheld as long as certain conditions are met. People familiar with the investigation say the owners of at least one small store were arrested. But larger companies like Home Depot faced only limited financial consequences. The stores were collectively ordered to hand over 1,343 allegedly illegal knives, and to forfeit proceeds from the previous four years of sales of the knives in question; this was restitution, but not a penalty. Richard Neal, who was in prison at the time, didn\u2019t hear about the raids (which took place as he was still wading his way through the appeals process). But the availability issue came up in one of his briefs. Since these knives were so common, it was reasonable to expect they were legal, his attorneys argued; essentially, he pleaded ignorance. In a December 2010 brief opposing Neal\u2019s release, filed six months after the Home Depot raids, Vance\u2019s office refuted that claim. \u201cOf course,\u201d they wrote, the sellers of illegal weapons are \u201calso susceptible to criminal prosecution.\u201d As proof, the brief cited a New York Post article about the raids, remarking, \u201cignorance of the law is not a valid defense to the commission of a crime.\u201d But ignorance was apparently a defense for the retailers involved, as Steve Pokart, an attorney with the Legal Aid Society in Manhattan, points out. He says Vance\u2019s settlement offer was \u201cincredibly hypocritical,\u201d comparing it to arresting a heroin user while letting the dealer simply give the drug money back. Robrish was furious when she read about the raids. \u201cThese stores were allowed to pay a fine,\u201d she says. \u201cBut our clients went to jail.\u201d [ After years of challenging the language of the law on every conceivable basis, nothing had budged. But by the winter of 2012, Robrish\u2019s files had gotten thick. And a chance encounter at her daughter\u2019s preschool would finally give her an opportunity to make use of them when, over coffee and snacks, she started chatting with another parent, Dan Quart, the New York State assemblyman. Compact and serious, with boyish features and a shock of black hair, Quart had done pro bono work in Legal Aid\u2019s civil division years before. A fortuitous meeting to say the least. The two started talking shop, and Robrish filled Quart in on the gravity-knife problem. Quart was intrigued by what he heard; he invited her to make a visit to his Manhattan office and tell him more. A few months later, Robrish and a colleague, William Gibney, arrived with a pitch for the assemblyman, along with a stack of files \u2014 and two props. One was a pocketknife they\u2019d borrowed from a colleague. The other was a screwdriver. Robrish went through her whole spiel: the unfair arrests, the odd quirks in the statute. And as her final flourish, she produced the pocketknife. By loosening the hinge on the blade, just a bit, she showed Quart how a perfectly legal pocketknife could become a potential felony. Quart soon began drafting a bill that that contained a small tweak to the gravity-knife law, requiring the prosecutor to prove the defendant had \u201cunlawful intent\u201d for the knife in his or her possession. It\u2019s the same fix proposed by the New York State Office of Court Administration, and Quart\u2019s bill won the endorsement of the Legal Aid Society and some organized labor groups, including IATSE. Quart thinks it\u2019s a reasonable middle ground that still recognizes the dangers knives can pose. Anyone who threatened someone with a gravity knife, for example, would still be liable for prosecution. But simple possession would no longer be enough to put someone in jail. In that sense, it would bring gravity knives in line with other kinds of pocketknives, and ensure that the vagaries of knife design aren\u2019t of such material importance. That knives can be dangerous and even lethal weapons is, as a spokesperson for Vance says, \u201ctoo obvious to require elaboration.\u201d Knives are used in thousands of attacks in New York City every year, many of them fatal. But no law enforcement agency in New York City was willing, even after repeated requests, to explain what makes gravity knives more dangerous than other kinds of folding knives. If the discussion surrounding the original law\u2019s passing in 1956 is any indication, the ability of a knife to be brandished quickly, coupled with a folding ability that made it easy to conceal, was seen as good reason to treat it differently under the law. Aside from brief statements, none of the district attorneys in the five boroughs responded to detailed questions for any other aspect of this story, and the NYPD didn\u2019t respond at all. Of the five D.A.s involved, only the office of Bronx District Attorney Robert Johnson was willing to acknowledge that there was \u201csome confusion\u201d about the gravity-knife statute. A spokesperson for Johnson says prosecutors there have been \u201cseeing cases of people using gravity knives for innocent purposes,\u201d but that they have been \u201csorting out\u201d those cases before prosecution, with a number resulting in dismissal. The Manhattan D.A., in a brief statement, notes that many knives have legitimate purposes, but says the legislature has determined that gravity knives, among other types, are \u201cespecially susceptible\u201d to being used as dangerous weapons. In other words, the New York City D.A.s believe they\u2019re simply enforcing the laws as written. By the time of Robrish\u2019s meeting with Quart, even more opposition to the gravity-knife statute had begun to emerge. But this time it hailed from a very different source. Arizona-based nonprofit Knife Rights, as its name implies, is sort of like an NRA for knives. Formed in 2006, with endorsements from the likes of Ted Nugent and NRA leader Wayne LaPierre, the group views knives through the prism of the Second Amendment. The organization is about as far as one can get, politically, from a liberal Manhattan assemblyman like Quart. But after Vance\u2019s raids in 2010, Knife Rights, too, began to take a keen interest in New York\u2019s knife laws. In 2013, the group filed a federal lawsuit against Vance, challenging the state\u2019s law on constitutional grounds. The suit, which is ongoing, argues that the law in New York is so vague that it\u2019s impossible to know which knives are legal and which aren\u2019t, exposing people to prosecution in a way that violates basic rights. A similar argument has been rejected before in state court. And a reasonable person might say the language of the law, while extremely broad, is actually pretty clear. But Doug Ritter, the group\u2019s president, spokesman, and pretty much everything else, thinks he\u2019s got a good shot at winning. \u201cThere\u2019s simply no way for an honest citizen to know how to comply with the law the way the city is enforcing it,\u201d Ritter says. \u201cThat is the very essence of \u2018vagueness,\u2019 and that precedent is very well established in law.\u201d If Ritter is successful, it will be another of quite a few recent victories for knife advocates. Over the past six years, laws against switchblades and gravity knives have been rolled back in Arizona, Alaska, New Hampshire, and elsewhere. It\u2019s an effort driven, at least partly, by an increasingly vocal \u201cknife lobby,\u201d although such a term would have been laughable only a decade ago. There are really only two organizations involved, Knife Rights and its more genteel counterpart, the American Knife and Tool Institute (AKTI), a less strident trade group that forgoes the Second Amendment language that Knife Rights employs. The groups are so tiny as to be virtual non-entities in lobbying terms; neither group\u2019s 2012 revenues exceeded low six figures. But they\u2019ve been making headway. That the \u201cknife lobby\u201d has found common cause with labor unions and the Legal Aid Society makes for quite an odd pairing. In other states, support for relaxing knife laws has come mostly from the conservative right, Second Amendment true believers, or politicians eager to score points with hunters and outdoorsmen. Even more remarkably, there doesn\u2019t appear to be any significant, direct coordination between the two sides in New York. So when Quart\u2019s bill came up for a vote, it seemed like that rarest of things: an almost coincidental bipartisan moment. The support of labor unions and the Legal Aid Society would likely ensure that one side of the aisle would support the bill. And, fresh off a losing battle over the state\u2019s assault-weapons ban, plenty of Republicans in the body would presumably welcome a chance to rep their Second Amendment cred. The casual observer might even have expected a unanimous vote. But a strange thing happened when Quart\u2019s bill came to the floor: It was attacked, immediately and passionately, by one of the most conservative lawmakers in the state. Al Graf, a Long Island Republican, had voted against New York\u2019s assault-weapons ban only a few months previously. But he was definitely in favor of this particular weapon restriction. \u201cLook, I\u2019m a retired police officer,\u201d Graf, thick-brogued and burly, told Quart in a testy exchange, \u201cand I\u2019ve seen gravity knives. I\u2019ve arrested people with gravity knives. And they\u2019re about this big\u201d \u2014 Graf held his hands up, about shoulder-width apart. \u201cGravity knives were put on the list [of banned weapons] for a reason.\u201d The back-and-forth on the assembly floor lasted for several minutes and focused, to Quart\u2019s obvious annoyance, on switchblades. \u201cThere\u2019s no mention of a switchblade in my bill,\u201d Quart insisted. The bill ultimately passed 88-17. But all the nay votes, save two, belonged to Republicans. Those who follow the issue speculate that GOP opposition might stem from concerns about law and order. As one attorney put it, no one wants that vote thrown back in their face the next time some teenager is stabbed to death. The District Attorneys Association of the State of New York, the group most likely to weigh in, says it hasn\u2019t taken a position; so do the city\u2019s individual D.A.s. And in a conversation with the Voice this summer, Quart put it diplomatically: \u201cI assume they [the district attorneys] are not supportive of this legislation.\u201d Quart\u2019s bill landed in the state senate last year, where it languished for months; today it\u2019s effectively dead. Quart says he\u2019s determined to reintroduce the measure when the legislature reconvenes after the new year. But a staffer for the senate sponsor, Democrat Dianne Savino, said she might not pursue the legislation this time around. Meanwhile, in July, a Bronx court took the extraordinary step of setting aside a gravity-knife prosecution \u201cin the interest of justice,\u201d the judicial equivalent of jury nullification. While acknowledging that the evidence likely supported the charge, the judge said the higher call of justice demanded the prosecution be rejected. The judge\u2019s reasoning \u2014 the wide availability of the knives, the original intent of the statute, outlined in a six-page brief \u2014 would be familiar by now, and the ruling caused something of a stir among knife nerds in the legal community. Most of the defense attorneys who spoke to the Voice were unaware that the gravity-knife provision was being addressed by the legislature. Quart\u2019s bill was a low-profile affair, and went largely unnoticed, even among those who worry about the issue. But Robrish, for one, who helped set the legislation in motion, has been watching closely. She said it was frustrating to see the bill come so close only to meet an undignified demise. She\u2019s also not entirely convinced the change will solve the problem. \u201cIt\u2019s not a 100 percent solution,\u201d Robrish admits. The gravity-knife story is all about gray areas, and introducing a new gray area \u2014 intent \u2014 still might leave some people vulnerable. But Robrish says the change would help eliminate the most egregious cases. And since there\u2019s really no defense against a gravity-knife charge under current law, requiring the D.A. to prove unlawful intent would at least give defense attorneys something to work with. \u201cI think we\u2019ll have a really good shot at defense. Or a better shot, I should say.\u201d She laughs, and adds, dryly, \u201cBut of course, what would be best is if they just got rid of that particular term.\u201d [jcampbell@villagevoice.com][@j0ncampbell] \nMore:Gravity Knives NYCLongform","time":1525656650,"title":"A 1950s-Era New York Knife Law Has Landed Thousands in Jail","type":"story","url":"https:\/\/www.villagevoice.com\/2014\/10\/07\/how-a-50s-era-new-york-knife-law-has-landed-thousands-in-jail\/#page-all"},{"by":"ramgorur","descendants":17,"id":17009675,"kids":"[17010243, 17010522, 17011228, 17011431, 17018307, 17014996]","score":52,"text":"\n\n      By CHRIS POMORSKI\n\nMAY 2, 2018\n \nIt\u2019s pricey, it\u2019s portable, its users need it constantly, and retailers love to buy it at a discount. All of which makes it a perfect product to steal.\n It\u2019s pricey, it\u2019s portable, its users need it constantly, and retailers love to buy it at a discount. All of which makes it a perfect product to steal. Insys Therapeutics paid millions of dollars to doctors. The company called it a \u201cspeaker program,\u201d but prosecutors now call it something else: a kickback scheme. In 2016, a mysterious syndicate tried to steal $951 million from Bangladesh\u2019s central bank - and laid bare a profound weakness in the system by which money moves around the world. When the Iowa attorney general\u2019s office began investigating an unclaimed lottery ticket worth millions, an incredible string of unlikely winners came to light - and a trail that pointed to an inside job. How the biggest scammers get away with it. \nBy CHRIS POMORSKIIllustrations by FRANCESCO FRANCAVILLA\nMAY 2, 2018\n It\u2019s pricey, it\u2019s portable, its users need it constantly, and retailers love to buy it at a discount. All of which makes it a perfect product to steal. New Port Richey, perched on a knuckle of Gulf Coast 35 miles northwest of Tampa, is a typically Floridian enclave of strip malls, subdivisions and brackish waterways. During the 1920s, it enjoyed a brief period of glamour when professional golfers and silent-film actors bought land, built handsome homes and socialized with visiting stars from Broadway and vaudeville at the Hacienda Hotel. But the town owed much of its success to the first of Florida\u2019s many real estate bubbles, and the fantasy ended around 1925, dashing forever New Port Richey boosters\u2019 hopes of its becoming a kind of Hollywood East. By November 2005, when Alexis and Ronald Dattadeen bought a home there \u2014 a cozy ranch house shaded by a generous oak \u2014 it was just another Tampa suburb. Alexis and Ronald, who were in their mid-20s, had recently welcomed their first child, A., and within a few years they had another son, D. (The children in this article are identified by their first initial only.) Like his brother, D. had dark hair and big brown eyes. But D. also had a rare genetic disorder that would require many visits over the years to gastroenterologists, neurologists and hospitals. Ronald worked long hours for low pay, maintaining pools during the day and scrubbing operating rooms at night. Alexis, who had held jobs sterilizing medical equipment and wrangling phone lines at a hospital, found D.\u2019s unpredictable need for medical attention incompatible with even part-time employment. You could change schedules only so many times before exasperating even the most understanding manager. And she soon found upsides to staying home \u2014 napping with D. during the day; the satisfactions of a clean car, folded laundry, the waft of pot roast from the oven. But homemaking could be boring and lonely \u2014 and Dattadeen wasn\u2019t earning any money, further limiting her life outside the house. In 2011, when D. was 2, Dattadeen had a realization: She could be selling her excess baby formula. D. needed an expensive brand called EleCare, which was designed for easy digestion. Dattadeen got it through Medicaid, and it arrived at her home automatically from a medical supplier. She always ended up with extra cans, so she posted an ad on Craigslist and quickly found a buyer, a man who indicated that the formula would go to a child in need. But before long, a second buyer \u2014 a buyer who would prove far more lucrative \u2014 responded to the ad. Her name was Alicia Tondreau-Leve. Dattadeen and Tondreau-Leve first met in a McDonald\u2019s parking lot about an hour\u2019s drive from New Port Richey. Soon Tondreau-Leve became a repeat client, meeting Dattadeen every few weeks to buy some of the EleCare. During one of their first meetings, Tondreau-Leve explained that she had a business distributing excess powdered formula to needy families. Dattadeen expressed interest in the venture, and Tondreau-Leve soon agreed to bring her aboard \u2014 emphasizing, though, that she wasn\u2019t an employer. Dattadeen would be an independent contractor, sourcing formula for resale to Tondreau-Leve. As in a multilevel marketing operation, her success would depend on her ability to create a large network. Still, for Dattadeen, the benefits would be manifold: She could set her own hours, earning an income while tending to D.\u2019s appointments. Like Mary Kay or Amway, Tondreau-Leve provided a start-up guide. She showed Dattadeen how to replicate a Craigslist ad she had been posting to promote the business. It had an elegant logo \u2014 a silhouette of a woman with flowing hair holding an infant aloft. \u201cFormula Mom,\u201d it read. \u201cHelping Other Moms ... Helps You!\u201d The ad outlined Formula Mom\u2019s services: free pickups and cash payments for brands including Gerber, Enfamil and Similac. Dattadeen would swap in her own phone number and a Formula Mom email address that Tondreau-Leve suggested she create. There was an invoice template and a price guide with photos of the formulas Tondreau-Leve accepted. She instructed Dattadeen not to stray far from the Tampa area and advised her to meet sellers in public places. Later, she even provided business cards. To help her get started, Tondreau-Leve gave Dattadeen a few leads. Craigslist ads \u2014 answering and posting them \u2014 yielded additional sellers, and Dattadeen\u2019s first weeks were successful. Attentive and patient, Tondreau-Leve guided her by phone and text. \u201cThat\u2019s great that you are so willing to help,\u201d Dattadeen texted her in early 2012. \u201cWe will make a great team.\u201d \u201cYes we will,\u201d Tondreau-Leve replied, \u201cYou have the same drive that I have.\u201d Dattadeen was included in business decisions, providing input on flyer design and marketing. One day, she had an idea of her own. To make things more official and to better track sales, she thought, they should provide sellers with receipts. Taking initiative, she went to an Office Depot and designed a prototype. But before returning to print copies, she mentioned the idea to Tondreau-Leve, who saw things differently. Receipts wouldn\u2019t work for Formula Mom, Tondreau-Leve said, because that would leave a paper trail. Some $4.3 billion worth of infant formula was sold in the United States last year, a vast majority of it in powdered form. Between factory and baby aisle, its cheap ingredients (dehydrated milk and vitamins) become steeply, even mysteriously expensive. Basic types run about $15 for a 12.5-ounce can, amounting to perhaps $150 a month for a fully formula-fed infant. Specialty recipes like EleCare can cost two or three times as much. Strict Food and Drug Administration regulations govern formula production, and three companies dominate. Abbott Laboratories, which makes Similac, and Mead Johnson, which makes Enfamil, each control about 40 percent of the market. The Nestl\u00e9-owned brand Gerber holds a roughly 15-percent share. A market with so little competition is bound to have generous margins, and formula makers have grown richer still because a single buyer accounts for roughly half of all domestic sales: the United States government. The Special Supplemental Nutrition Program for Women, Infants and Children, commonly known as WIC, provides needy mothers with cash assistance for certain foods, including powdered formula. When it began, in 1972, WIC represented a fresh, lush source of inelastic demand, by effectively eliminating from the formula market those customers most sensitive to price. During the \u201980s, formula prices rose by more than 150 percent, vastly outpacing increases in milk costs. By the middle of that decade, formula was absorbing 40 percent of WIC\u2019s food budget, prompting shortfalls that shunted many eligible families to a waiting list. In the \u201990s, the Senate Subcommittee on Antitrust, Monopolies and Business Rights; the Federal Trade Commission; and attorneys general from 19 states pursued formula manufacturers for price-fixing and illicit marketing. Multimillion-dollar fines were assessed, but no firm admitted wrongdoing. Even today, formula prices bear the imprint of yesteryear\u2019s state-enabled gouging; according to a 2009 report by the Notre Dame economist David Betson, \u201cthe WIC program accounts for 91 percent of the increase in the growth of real formula prices\u201d between 1981 and 2002. Products like formula \u2014 expensive but with slim retail margins \u2014 are vulnerable to black-marketeers. Independent store owners, for example, don\u2019t buy enough formula to qualify for the bulk discounts that manufacturers offer big chains. But if they can acquire off-market formula at subwholesale prices and resell it for the usual rates, they can improve their bottom lines. By the middle of 2012, Dattadeen\u2019s formula business began to thrive. But certain irregularities emerged in her supply chain. Some of her \u201ccustomers,\u201d as she called the people from whom she bought formula, would sell her three to 10 cans every few weeks. That seemed about right. Why, after all, would anyone have more leftover formula than that? But others routinely had much more. There was a woman named Julie who met Dattadeen regularly, sometimes with more than $1,000 worth of formula. A couple named Krystal and Chris offered 80 to 150 cans at each transaction. Another couple, Brian and Jessica, often showed up to meetings with so much formula that they had to load it into their trunk. Dattadeen listened to explanations from such sellers about their sources: an aunt with a baby store, a warehouse-based wholesaling business. But when Dattadeen voiced reservations about them to Tondreau-Leve, Tondreau-Leve suggested that she accept the stories at face value, or adopt a don\u2019t-ask-don\u2019t-tell attitude. This all seemed out of step with a business predicated on buying up surplus product, but it soon became clear that Formula Mom did not function quite as advertised; Tondreau-Leve seemed most interested in \u201ccustomers\u201d who could offer formula in bulk. To ensure that Dattadeen could handle these large purchases, Tondreau-Leve had her set up an account with Bank of America, and wired her cash in advance of sales. Tondreau-Leve even began making requests. \u201cI need 35 Similac Advance cans,\u201d she wrote in a text message. \u201cCan you see if Julie can get that for us?\u201d Dattadeen quickly found good uses for her new income. In June 2012, she traveled to a medical conference in Illinois for D. That July, she bought a new minivan, texting a photo to Tondreau-Leve. \u201cI still can\u2019t believe my dream is parked up in my driveway,\u201d she wrote. She bought a walker for D. and enrolled A. in the Cub Scouts. A. \u201cis going to call you tonight, to try and sell you popcorn for boyscouts,\u201d Dattadeen texted Tondreau-Leve soon after. \u201cIts more of a teaching thing for him so don\u2019t feel obligated to buy. I just had him make a list of everyone we are close to.\u201d Dattadeen\u2019s social life had been limited, and perhaps as much as her job, she seemed to value the friendship that had blossomed between her and Tondreau-Leve. \u201cI missed talking to you today!!!! GIRLFRIEND,\u201d she texted in October 2012. \u201cDo u realize we\u2019ve known each other for like a year now.\u201d Fifteen years older than Dattadeen, Tondreau-Leve had studied computer science at college; she was logical and organized \u2014 everything Dattadeen wasn\u2019t. But like Dattadeen, she had two sons. Her husband, a salesman, was often away from home, so she, too, was frequently alone. In Dattadeen she\u2019d found an openhearted prot\u00e9g\u00e9e, ever eager to please. Dattadeen sometimes called her Momma. Once, when Tondreau-Leve was swindled by an out-of state seller, she called Dattadeen in tears. When Dattadeen fought with her husband, Tondreau-Leve offered counsel. \u201cDon\u2019t feel bad for pushing him away,\u201d she texted. \u201cHe has to see that you still love him, but he has to build the relationship again.\u201d Outside work, they met for dinner at the Cheesecake Factory, took their boys camping and saw a Trans-Siberian Orchestra concert. In 2013, Dattadeen took her first real vacation in years, staying not far from Tondreau-Leve\u2019s home on the Atlantic coast so that they could spend time together. On her last night in town, Dattadeen sent her a text: \u201cYou are the best friend a woman can have.\u201d   In spring 2012, Kevin Shultz, a loss-prevention manager for Publix Supermarkets, received the first of what would be many reports that year concerning a mysterious plague of thefts. Initially, the missives trickled in from stores around Tampa, where Shultz is based. But Publix has more than 1,000 locations scattered through the Southeast. Some 400, mostly in Florida, fall under his purview, and soon, he was getting similar reports from all over the state: Cape Coral, Fort Myers, Orlando, Miami. The thieves seemed to be multiplying \u2014 and all they wanted was baby formula. Loss prevention is the rare topic about which competing retailers will trade intelligence, and from talking to his counterparts at Walmart, Target and Walgreens, Shultz learned that they were losing large volumes of formula, too. That sort of overlap tended to rule out the employee theft that often accounts for large-scale pilferage. To store-security officers and local cops, who were addressing the crimes on a case-by-case basis, the incidents didn\u2019t appear related. But Shultz had a unique perch, and as he dug deeper, the thefts began to take on a pattern \u2014 the work, he believed, of organized crime. Shultz joined Publix in 2006 after a long, varied career in law enforcement \u2014 time on the homicide squad in Plant City, Fla.; stints embedded with the United States Marshals and the Drug Enforcement Administration \u2014 and was soon assigned to a newly created position, Organized Retail Crime (O.R.C.) Investigator, to help stem what retailers had come to recognize as a growing problem. Bob Moraca, the vice president of loss prevention at the National Retail Federation (N.R.F.), a trade group, says that in the last few years, O.R.C., which accounts for $30 billion in annual losses in the United States, has overtaken \u201cinternal shrink\u201d \u2014 that is, employee theft \u2014 as the greatest threat to retailers\u2019 bottom line. A 2016 survey by the N.R.F. found that 100 percent of respondents \u2014 a sample representing thousands of stores \u2014 had been victimized in the last 12 months by organized crime, more than in any other year. Retail-crime groups generally share a pyramidal structure: a boss up top, captains and lieutenants below and professional shoplifters, or \u201cboosters,\u201d at the base. The internet has been catalytic, providing those without underworld ties new ways of fencing goods: auction sites and payment methods that facilitate anonymity. Prime targets include clothing and handbags \u2014 expensive, high-demand goods that are relatively easy to conceal \u2014 as well as top-shelf liquor, pain-killers and laptops. Pharmacy wares are favorites, too. In 2008, Shultz helped neutralize a theft ring dealing in health and beauty products. The following year, he broke up a group of middle-aged Florida men who sometimes feigned infirmity \u2014 affecting a limp, using a motorized cart \u2014 to help them relieve retailers of countless razor blades. The third-most-targeted item, according to the 2016 N.R.F. report, was infant formula. Shultz\u2019s formula inquiry began in the usual way, with information flowing to him from lower-level personnel \u2014 mostly video and photo stills depicting shoplifters in various stages of the act. Shultz noted that the thefts did not seem attributable to people stealing for personal use \u2014 they were taking way too much. And they were craftier than your run-of-the-mill smash-and-grabber. One man, in Orlando, liked to select an opaque, lidded storage bin from a sales display, fill it with formula, then proceed through the exit doors, brandishing a phony receipt for the bin. Others worked in teams. One couple used their children as camouflage, stowing their take in a specialized diaper bag that retained its shape empty or full. Another hid formula in a stroller with a spacious undercarriage. Many thieves favored reusable Walmart bags, which had the advantage of a substantial, precise capacity: 18 12.5-ounce cans of formula (three layers of six), or nine 1.45-pound tubs (three layers of three). As Shultz identified repeat offenders, he circulated the footage to other stores he considered likely targets for the same thieves. But clever boosters are difficult to apprehend; store-security officers serve a largely deterrent purpose, and cashiers and stock clerks cannot be expected to confront criminals. To improve its prospects, Publix stepped up inventory checks in formula aisles, enabling the company to zero in on the window during which a theft occurred, alert nearby stores and swiftly fold the data into the case file. One night in July 2012, Shultz got a break \u2014 a phone call from a Publix in Pinellas County, about 20 miles from Tampa. Police officers there had apprehended a couple trying to steal 13 cans of formula. Shultz recognized them from security footage. They made a striking pair; slender, with brown hair, the woman looked slight beside her partner, a lumbering man with an ex-lineman\u2019s physique. Now, under arrest, they had names: Jessica Gordon and Brian Oliver, both about 30. Shultz hoped they could provide some clue about the organization he suspected they were working for. In an interview with Gordon arranged by the Pinellas County Sheriff\u2019s Office, he learned that the couple had two buyers. One proved, after a brief investigation, to be an online business trading in quantities too small to explain the losses retailers were seeing. The other was a 32-year-old woman named Alexis Dattadeen. Dattadeen read online about the arrests. She was frightened \u2014 by then, she\u2019d bought formula from Gordon and Oliver at least 10 times. But when she told Tondreau-Leve what had happened, Tondreau-Leve seemed unruffled, concerned mostly with coaxing Dattadeen back to work \u2014 and Dattadeen didn\u2019t want to disappoint her. Encouraging and sympathetic at times, Tondreau-Leve could also be stern. She had become increasingly focused on high productivity, bristling at mistakes. A sizable haul was one thing that Dattadeen could be sure would make her happy, and so, when Oliver contacted her some weeks later, offering to sell more formula, she agreed to meet. One evening in September 2012, Dattadeen pulled her minivan into a Walmart parking lot in Palm Harbor, a community south of New Port Richey. Soon, Oliver arrived, driven by someone Dattadeen had never met. She got out of her car and greeted Oliver, who hulked over her in a green polo shirt. \u201cNice to see you again,\u201d she said, hugging him. The other man was introduced as Donnie. His real name was George Moffett \u2014 and he was a Pinellas County sheriff\u2019s deputy. From an unmarked car, another officer filmed the exchange. \u201cI\u2019ve stolen a lot of [expletive] in my day,\u201d Moffett says in the video. \u201cBut this [expletive] was hard.\u201d Dattadeen smiles bashfully, but doesn\u2019t otherwise respond. Moffett presents himself as Oliver\u2019s source. In his trunk are 90 tubs and 18 cans of Similac formula, which had been provided to the sheriff\u2019s department by Publix. \u201cSo you\u2019re the guy who\u2019s been getting all this?\u201d Dattadeen asks. \u201cDo you have a number \u2014 I could call you?\u201d   In the coming weeks, Dattadeen met \u201cDonnie\u201d three more times. In recordings of their interactions, she speaks in a high, soft voice, with the scattered animation of a teenager. Details about Formula Mom pour forth: Dattadeen has a partner, near Orlando, whom she meets on Mondays; the formula is shipped to Massachusetts, and also to China. \u201cShe\u2019s not as easygoing as I am,\u201d she said once, referring to Tondreau-Leve. \u201cI can tell you that.\u201d In October, Shultz drove to a gas station off Interstate 4, which connects Orlando and Tampa. He had been guided there by the Pinellas County Sheriff\u2019s Office, which had relayed intelligence to him about Dattadeen\u2019s movements gleaned from a GPS tracker that it had attached to her van. At the rear of the parking lot, he found Dattadeen\u2019s van backed against a white fence, with slats spaced widely enough that he could shoot video through them. Beside it, another van had backed in. Both trunks yawned open. Dattadeen and a woman unknown to Shultz moved formula from one van to the other. \u201cWhite female, appears to be middle-aged \u2014 late 40s, early 50s, shorter hair,\u201d Shultz narrates, describing the stranger over a Rascal Flatts song playing from his radio. \u201cMultiple cans of formula,\u201d he says. \u201cMultiple, multiple stacks.\u201d After the transfer was complete, Shultz followed the older woman to a house about 15 miles away, taking down a license-plate number that he traced to a rental contract signed by one Alicia Tondreau-Leve. Tondreau-Leve arrived in Florida with her two adolescent sons in July 2011, becoming one of the roughly 800 new residents the state absorbs per day, an aspirant lured by its redblooded interpolation of Californian mythos: sun, surf, opportunity. Having recently endured a difficult period, the family had come from Freetown, Mass., a quaint village of about 9,000, where Tondreau-Leve\u2019s husband, Alan Leve, remained in his sales job while he looked for work in Florida. In 2010, Alan realized a long-held dream of opening a restaurant. But the business failed, and the family filed for bankruptcy. Sonoma at Viera, the subdivision 45 miles southeast of Orlando where the Leves settled, might reasonably have seemed an auspicious place to start again. Diminutive palms lined its streets, which bumpered neat lawns garnished by flowering shrubs. Backyards were generously puddled with artificial ponds. Everything was new. Not long before Tondreau-Leve moved to Florida, Alan\u2019s cousin, Michael, presented her with an opportunity. He knew the secondary retail market well, having for years run a store in Massachusetts that took a commission for selling customers\u2019 goods on eBay. He suggested that formula might earn her some extra money: She could buy unused cans from Florida moms and ship them to him. Initially, Tondreau-Leve had little sense of how to go about things, so she simply did what she could; if she had to drive 15 miles to buy two cans, so be it. Gas costs could exceed the value of her purchases, but she viewed the legwork as an investment. Eventually, she learned to schedule all her deals in a given metro area \u2014 Tampa, say \u2014 on the same day. When she\u2019d gathered enough formula to fill a moving box, she shipped it to Michael, profiting about $2 per can. If Tondreau-Leve ever began to sense that her business was mutating from a wholesome D.I.Y. venture into something malignant, there was little in her outward presentation to suggest it. Soon after moving in, she told Cindy Lashomb, who lived next door with her husband, about a company she\u2019d started, dealing in surplus infant formula. There was nothing secret about it, Lashomb told me; Tondreau-Leve even affixed a magnet advertising the business to her car. Another neighbor, Donald Egan, knew about the business, too; he discerned in Tondreau-Leve the makings of a mogul, once describing her as \u201cthe pants in the family. She ran everything. You could tell by her attitude and the way she approached you that she was the alpha male, so to speak.\u201d In the spring of 2012, Lashomb began to suspect that something was not quite right next door. Suddenly, it seemed, trucks were always coming and going, picking things up or dropping them off. Lashomb complained to Tondreau-Leve, but the traffic worsened \u2014 UPS deliveries gave way to tractor-trailers. Once, an 18-wheeler blocked the Lashombs\u2019 driveway, trapping them at home. Tondreau-Leve eventually shifted operations to a storage facility, renting a single unit, then a double, filling it to capacity with head-high stacks of formula. By early 2013, Formula Mom had statewide reach. A woman named April covered Fort Myers. A man named Angel, who owned a consignment store, handled Miami. Giulyanna took care of Orlando. To each subcontractor, Tondreau-Leve provided the same start-up guide. Each set up a Bank of America account. Having some experience with consignment stores, Dattadeen voiced concerns about Angel\u2019s supply, which arrived in huge quantities \u2014 a fact she happened to notice during a drop-off at Tondreau-Leve\u2019s storage unit. But Tondreau-Leve dismissed them. Having expanded her network, Tondreau-Leve was less dependent on Dattadeen, and she had cooled on her, berating her over botched invoices, and comparing her unfavorably with her other deputies. Demand had meanwhile grown alongside supply. That year, Tondreau-Leve stopped selling to Michael in favor of a California woman named Lissette, who ran a formula-wholesale business. Lissette had contacted Tondreau-Leve online, offering her a much better price than Michael did. By playing Lissette off yet another buyer, in Wisconsin, Tondreau-Leve negotiated an even better rate. Buyers from New York and New Jersey materialized, too. Tondreau-Leve did not much trouble herself about what became of her formula after she sold it, but the buyers mostly seemed to be wholesalers, redistributing the product to small stores. At least one owned a Brooklyn bodega, and Tondreau-Leve knew that Lissette had customers in China, where a tainted-formula scare in 2008 had stoked demand for foreign brands, which were seen as safer. Between January 2012 and July 2014, records from several freight carriers indicate that Tondreau-Leve shipped a total of roughly 60 tons of product. During that period, she received nearly $300,000 from her California client, $300,000 from buyers in Wisconsin and nearly $1 million from New York City buyers. No longer a neophyte, she proved herself an able businesswoman, adept at navigating complex logistics. In missives to underlings, she presents as a sober, precise manager. \u201cI appreciate everyone\u2019s patience over the last couple of months,\u201d she once wrote. \u201cBecause of the Chinese market not taking formula from the U.S., it has left a surplus of Nutramigen and Alimentum in everyone\u2019s hands. Hopefully now that the doors are open again in China, we will see some of this product move.\u201d Shultz continued to watch formula disappear from his shelves in 2013, but the mechanics of the operation remained unclear. Late that year, he approached Jeff Newcomb, an agent with the Orange County Sheriff\u2019s Office, which covers metropolitan Orlando, with a lead that he believed was connected to much of the area\u2019s missing baby formula: a Formula Mom Craigslist ad, with contact information for a \u201cJulie.\u201d By then, the Florida Department of Law Enforcement, as Florida\u2019s state police is known, had joined the case in a supervisory role, synchronizing police efforts in different jurisdictions. F.D.L.E. agents had coordinated additional surveillance, following Dattadeen to meetings beyond Pinellas County, and trailing Tondreau-Leve through Central Florida. A prosecutor from the attorney general\u2019s office had also been assigned, adding subpoena power to an investigation that would produce mountains of paper evidence: bank and phone records, wire transfers, emails. Bit by bit, law enforcement was working toward a case against Formula Mom under Florida\u2019s RICO Act, a version of the 1970 federal anti-racketeering law designed to cripple the mafia. Having worked several previous RICO cases, Newcomb was familiar with the methods of the genre \u2014 turning lowly button men against capos and so on. But this time, rather than work up the chain of command, Newcomb would establish a pattern of criminality at the base of the pyramid, sketching a fuller portrait of the enterprise. Using a criminal informant to conduct a controlled sale, Newcomb quickly identified \u201cJulie\u201d as 30-year-old Giulyanna Guzman, Tondreau-Leve\u2019s Orlando deputy. A single mother with a 2-year-old daughter, Guzman was organized and hardworking, often waking early and retiring late. She spent the hours between seeking out formula sellers online and distributing the business cards Tondreau-Leve had given her. Since starting with Formula Mom in early 2013, she had developed a stable of fruitful sources. But like Dattadeen, she had concerns about a number of them. Guzman was meeting some people every day, sometimes more than once. They would demand to see her on short notice, urgently and at odd hours. In some cases, she did not feel right about their being around her daughter; they seemed off. One such supplier was Janine Piccirillo, who\u2019d learned the formula racket from a friend: what to look for; how to get it; and, most important, that there was a woman named Julie who would always buy it. Piccirillo could often manage to make off with two Walmart bags full of formula at a time \u2014 roughly $550 worth at retail. She worked with a driver, Jennifer Day, who would obscure her license plate with a sheet of paper and wait outside. They might hit three stores in a day. After selling their haul to Guzman, Piccirillo and Day usually drove straight to see their dealer. One day in 2013, Day was dope-sick, and went to work alone, visiting a Publix in the morning. Noticing someone filming her with a phone, she left and drove to Walmart. Her symptoms were worsening, and she resolved to steal as much as she could, leaving the store with a bag on each arm. But when she reached the parking lot, she was swarmed by masked police officers with their guns drawn. When I met him recently at an Orange County police station, Newcomb grinned at the memory, explaining that they\u2019d thought Day might be armed \u2014 she\u2019d been surveilled for about a month, and had once been observed leaving a gun shop. During the arrest, Guzman, who was listed in Day\u2019s phone as Formula Mom, called repeatedly \u2014 Day was late for their meeting. She also had numbers saved for Alicia and Alan Leve. In all, Newcomb said, he identified about 15 boosters associated with Guzman. I asked how many were drug users. He paused, considering. \u201cI don\u2019t think there was a single one who wasn\u2019t,\u201d he said. Most if not all were addicted to opioids \u2014 using heroin, prescription painkillers or both. In the summer of 2014, the F.D.L.E. staged a dramatic final scene in Operation Baby Burp, as their investigation ultimately came to be known. They had by then developed an intricate understanding of Formula Mom. But much of the evidence against Tondreau-Leve was circumstantial. The police could barely ever connect her directly to thefts. Several officers who worked the case suggested to me that \u2014 like many dons before her \u2014 Tondreau-Leve had \u201cinsulated herself.\u201d If they got the case to trial, the question of her guilt would turn largely on what she knew or should have known \u2014 Florida\u2019s standard for dealing in stolen property \u2014 and on a legal concept known as willful blindness, or the \u201cdeliberate avoidance of positive knowledge.\u201d For juries, though, such esoterica does not play nearly as well as one last, spectacular bust. (Tondreau-Leve declined to be interviewed for this article. Most of her and Dattadeen\u2019s story comes from court documents.) That April, an F.D.L.E. agent named Shawn Sloan went to the Dattadeens\u2019 home, accompanied by Shultz, hoping to turn Dattadeen against Tondreau-Leve. They did not lack leverage; Dattadeen had repeatedly discussed buying stolen property on tape. When her predicament was made clear to her, she quickly agreed to cooperate. Following Sloan\u2019s instructions, in a recorded meeting later that month \u2014 a meeting during which she was terribly nervous \u2014 Dattadeen told Tondreau-Leve that she didn\u2019t want to work with her anymore. Some of her suppliers, she said, were making her uncomfortable, particularly a man named Steve, who had said he could get whole shipping pallets\u2019 worth of formula. The ploy worked. Soon after their conversation, Tondreau-Leve contacted Dattadeen to ask for Steve\u2019s number. Dattadeen obliged. The phone number she provided belonged to William Powell, an F.D.L.E. agent posing as a supplier. \u201cGood morning,\u201d Tondreau-Leve texted him in early May. \u201cMy name is Alicia, and I received your number from Alexis.\u201d Powell\/Steve wrote back: \u201cI can get it pretty regular, and Alexis said you\u2019re reliable.\u201d   The next day, Powell met Alicia and Alan in a CVS parking lot near their home, selling them 65 Similac tubs, which he indicated he\u2019d gotten from his brother, a Publix employee. As represented to Powell, Tondreau-Leve\u2019s vision of Formula Mom had changed markedly; she made no mention of needy mothers, of redistributing formula in the community. \u201cI\u2019m the go-to person here in Florida,\u201d she says in a recording of the meeting. \u201cI have an endless amount of money basically.\u201d Over the next month, they met twice more. Tondreau-Leve repeatedly sought assurances: \u201cPlease confirm that these cans are acquired legally!\u201d she texted when she first made contact. But when Powell equivocated, as invariably he did, she didn\u2019t seem deterred. \u201cI\u2019d love to know where he\u2019s getting it from,\u201d she says during their second meeting, meaning the brother. When Powell tells her, \u201cEverything\u2019s good, Alicia,\u201d for a moment on the recording, she appears flustered: \u201cNo, not \u2018everything\u2019s good,\u2019 because, you know, I don\u2019t steal \u2014 I don\u2019t buy stolen.\u201d Then she resumes loading her purchase. On July 2, Tondreau-Leve arranged to meet Powell in a Lowe\u2019s parking lot for what was to be the largest deal of her career: 3,300 tubs of formula \u2014 six pallets\u2019 worth. The load had a retail value of about $85,000. Tondreau-Leve had agreed to pay $33,000 in cash, which she stored for some days before the transaction in a coffee can on her kitchen counter. In the days beforehand, she seemed to overcome her trepidation about the formula\u2019s origins, texting Powell requests for future orders: 2,000 Similac Advance cans, 400 Enfamil boxes, Similac Go-and-Grow. But on the morning of the deal, after the pallets were transferred from Powell\u2019s truck to the one Tondreau-Leve had rented, she and her husband, who accompanied her that day, were arrested. Amid a blare of sirens from unmarked cars stationed in the lot, the police descended from all sides. Still in character, Powell cried out, \u201cWhat\u2019d you do to us, Alicia?\u201d In August 2016, a jury convicted Tondreau-Leve of charges including racketeering, dealing in stolen property and money laundering. Alan was convicted of conspiracy to commit racketeering. The judge, Wayne Durden, sentenced Tondreau-Leve to 20 years in prison, citing, among other factors, her refusal to acknowledge wrongdoing. Alan received a seven-year term. (At trial, Alexis Dattadeen and Giulyanna Guzman gave extensive, notably contrite testimony; both received probation.) The Leves\u2019 sentences struck me as severe, and I asked Pam Bondi, the Florida attorney general, if she agreed. \u201cI wish she\u2019d been locked up for as long as humanly possible for what she did,\u201d she said of Tondreau-Leve. \u201cHad she used her wits to start a legit business, she could have been incredibly successful \u2014 a true entrepreneur.\u201d We were sitting in a sparsely decorated corner suite in Bondi\u2019s Tampa office with Paul Dontenville, the lead prosecutor in the case, and Nicholas Cox, Florida\u2019s statewide prosecutor. Before us on a table lay a binder of Formula Mom price lists and invoices. The documents made a polished, professional presentation. They suggested pride of ownership, looking to me not at all like the work of someone trying to hide something. I asked Dontenville if, for an organized crime boss, Tondreau-Leve hadn\u2019t gone about things in a rather unusual fashion. She had registered her company with the state \u2014 displaying related paperwork inside her rented storage unit \u2014 and handled payments via commercial wire transfer. She had printed business cards and sent email that amounted to evidence of conspiracy. Clean cut and rigidly matter-of-fact, Dontenville declined to ruminate on the subject. He\u2019d been surprised, though, when he received discovery materials from the defense, that they included Tondreau-Leve\u2019s text messages, which she hadn\u2019t been required to provide. Tondreau-Leve evidently considered them exculpatory; Dontenville found them useful in making his case. Before trial, the prosecutors presented a deal that would have meant much less prison time for Alicia and mere probation for Alan. But the charges to which they were asked to plead apparently did not comport with their sense of their actions, or of themselves. They turned the deal down. Soon after, the Leves met for a voluntary pretrial interview with prosecutors, during which they insisted stubbornly that Alicia had run a legitimate business. She had worked hard and become successful. If she\u2019d erred, it had been through na\u00efvet\u00e9, trusting the wrong people. She was a business owner like any other, victimized by dishonest underlings. Last July, I went to see Dattadeen at her house in New Port Richey. When I pulled up, she was outside, hanging wet towels and bathing suits. She wore a tank top and had a reddish tan, her hair damp and straight. From the corner of her mouth, she smoked a cigarette. She spoke in a high, soft voice \u2014 the voice from the surveillance footage \u2014 but she\u2019d grown less trusting than she was then, regarding me warily and declining to speak in detail about her experiences with Tondreau-Leve. Formula Mom had been a mistake, and she was moving on with her life. Ronald came outside and we talked in the deepening dusk under a full yellow moon. When Dattadeen went to make a call, Ronald asked me, a little bashfully, about \u201cthe lady,\u201d meaning Tondreau-Leve. When I told him she was in prison, he looked sorry. Then he said: \u201cThe others admitted they were wrong. She was in denial.\u201d When Dattadeen and Tondreau-Leve were still close, Tondreau-Leve often spoke to her of her anger at losing the home she and her husband had owned in Massachusetts \u2014 a stately four-bedroom Colonial on an acre of land. Visiting from Florida, while Alan was still living there, she found it so upsetting to be in the house, which she knew by then that they would lose, that she sometimes preferred to spend time in a rented R.V. Formula Mom became a means of redemption and reinvention. The Leves had been renting in Florida, but about five months before their arrest, they began thinking of buying property: Lot 6HH at Tralee Bay Estates, a new development where the homes had granite countertops, Bosch appliances and \u201cTuscan-inspired architecture.\u201d When law-enforcement officers spoke of Tondreau-Leve \u201cinsulating\u201d herself, they meant it in a legal sense, that the layered structure of Formula Mom had made prosecuting her more difficult. But Tondreau-Leve\u2019s regional deputies also largely buffered her from the sad, grimy underpinnings of her business: the furtive meetings in parking lots; the twitching, nauseated victims of dope-sickness. In a way, the architecture of her organization had insulated her too from a damning kind of self-knowledge, even as her daily duties \u2014 arranging cross-country shipments, negotiating rates, collating spreadsheets, tracking policy changes \u2014 encouraged her to indulge an entrepreneurial delusion. It seemed likely that what Tondreau-Leve knew or should have known had been at least partly occluded by what she badly wanted to believe. On July 2, 2014, when she drove to the Lowe\u2019s parking lot, Tondreau-Leve took with her an immaculate-looking receipt made out to Steve Riley, the full name provided to her by Agent Powell. It had been perhaps two years since she\u2019d told Dattadeen not to pick up her prototype receipt from Office Depot, and Formula Mom had become a different kind of company. In the pretrial interview, she would tell Dontenville that in her last transaction, she believed she was buying from Publix at a wholesale rate. At the top of the receipt for Riley, she\u2019d printed the Formula Mom logo \u2014 the woman with flowing hair holding an infant aloft. Sign up for our newsletter to get the best of The New York Times Magazine delivered to your inbox every week. Chris Pomorski is a freelance writer who has contributed to The Guardian, New York, and Bloomberg Businessweek. This is his first feature for the magazine.  It\u2019s pricey, it\u2019s portable, its users need it constantly, and retailers love to buy it at a discount. All of which makes it a perfect product to steal. Insys Therapeutics paid millions of dollars to doctors. The company called it a \u201cspeaker program,\u201d but prosecutors now call it something else: a kickback scheme. In 2016, a mysterious syndicate tried to steal $951 million from Bangladesh\u2019s central bank - and laid bare a profound weakness in the system by which money moves around the world. When the Iowa attorney general\u2019s office began investigating an unclaimed lottery ticket worth millions, an incredible string of unlikely winners came to light - and a trail that pointed to an inside job. How the biggest scammers get away with it. Advertisement","time":1525655060,"title":"The baby formula crime ring","type":"story","url":"https:\/\/www.nytimes.com\/interactive\/2018\/05\/02\/magazine\/money-issue-baby-formula-crime-ring.html"},{"by":"kiyanwang","descendants":10,"id":17008909,"kids":"[17017625, 17012507, 17012010, 17009966, 17010714, 17010722, 17009702]","score":105,"text":"Infrastructure as code (IaC) tools such as Terraform, Packer, and Docker offer a number of advantages: you can automate your entire provisioning and deployment process, you can store the state of your infrastructure in code (instead of a sysadmin\u2019s head), you can use version control to track the history of how your infrastructure has changed, and so on. But there\u2019s a catch: maintaining a large codebase of infrastructure code is hard. Most IaC tools are immature, modern architectures are complicated, and seemingly minor changes to infrastructure code sometimes cause severe bugs, such as wiping out a server, a database, or even an entire data center. Here\u2019s the hard truth: most teams are terrified of making changes to their infrastructure code. The goal of Terratest is to change that. Terratest is a Go library that makes it easier to write automated tests for your infrastructure code. I won\u2019t claim that writing these tests is actually easy\u2014it\u2019s takes a considerable amount of work to get them just right\u2014but it\u2019s worth the effort, because these tests can run after every commit and verify that the code works as expected, thereby giving you the confidence to make the code changes you need. We developed Terratest at Gruntwork to help maintain the Infrastructure as Code Library, which contains over 250,000 lines of code written in Terraform, Go, Python, and Bash. This code is used in production by hundreds of companies, and Terratest is a big part of what makes it possible for our small team to maintain and support this codebase and our customers. Today, we\u2019re happy to announce that we are open sourcing Terratest under the Apache 2.0 license! You can find Terratest on GitHub. Let\u2019s take it for a spin. The basic usage pattern for writing automated tests with Terratest is to: To make this sort of testing easier, Terratest provides a variety of helper functions and patterns for common infrastructure testing tasks, such as testing Terraform code, testing Packer templates, testing Docker images, executing commands on servers over SSH, making HTTP requests, working with AWS APIs, and so on. Let\u2019s say you have the following (simplified) Terraform code to deploy a web server in AWS (if you\u2019re new to Terraform, check out our Comprehensive Guide to Terraform): The code above deploys an EC2 Instance that is running an Ubuntu Amazon Machine Image (AMI). To keep this example simple, we specify a User Data script that, while the server is booting, fires up a dirt-simple web server that returns \u201cHello, World\u201d on port 8080. How can you test this code to be confident it works correctly? Well, let\u2019s think about how you would test it manually: Using Terratest, you can write an automated test that performs the exact same steps! Here\u2019s what the code looks like: The code above does all the steps we mentioned above, including running terraform init, terraform apply, making HTTP requests to the web server (retrying up to 15 times with 5 seconds between retries), and running terraform destroy (using defer to run it at the end of the test, whether the test succeeds or fails). If you put this code in a file called web_server_test.go, you can run it by executing go test, and you\u2019ll see output that looks like this (truncated for readability): Success! Now, every time you make a change to this Terraform code, the test code can run and make sure your web server works as expected. The Terraform code in example #1 shoved all the web server code into User Data, which is fine for demonstration and learning purposes, but not what you\u2019d actually do in the real world. For example, let\u2019s say you wanted to run a Node.js app, such as the one below in server.js, which listens on port 8080 and responds to requests with \u201cHello, World\u201d: How can you run this Node.js app on an EC2 Instance? One option is to use Packer to create a custom AMI that has this app installed. Here\u2019s a Packer template that installs Node.js and server.js on top of Ubuntu: If you put the code above into web-server.json, you can create an AMI by running packer build web-server.json: At the end of your build, you get a new AMI ID. Let\u2019s update the Terraform code from example #1 to expose an ami_id variable that lets you specify the AMI to deploy and update the User Data script to run the Node.js app: (Note: the User Data script above is still very simplified. In a real-world use case, you\u2019d probably want to run your Node app with a process supervisor such as systemd and configure it to use all cores on the server using the cluster module). So how can you test this Packer template and the Terraform code? Well, if you were doing it manually, you\u2019d: Once again, you can automate this process with Terratest! To build the AMI using Packer and pass the ID of that AMI to Terraform as the ami_id variable, just add the following to the top of the test code from example #1: And that\u2019s it! The rest of the test code is exactly the same. When you run go test, Terratest will build your AMI, run terraform init, terraform apply, make HTTP requests to the web server, etc. The above is just a small taste of what you can do with Terratest. To learn more: Happy testing! By clapping more or less, you can signal to us which stories really stand out. Co-founder of Gruntwork, Author of \u201cHello, Startup\u201d and \u201cTerraform: Up & Running\u201d The Gruntwork Blog","time":1525644849,"title":"Open sourcing Terratest: tools for testing infrastructure code","type":"story","url":"https:\/\/blog.gruntwork.io\/open-sourcing-terratest-a-swiss-army-knife-for-testing-infrastructure-code-5d883336fcd5"},{"by":"dsr12","descendants":314,"id":17008876,"kids":"[17009853, 17009396, 17012210, 17010600, 17010392, 17009736, 17009231, 17013272, 17010554, 17012252, 17009978, 17009431, 17009838, 17010396, 17009687, 17010266, 17011046, 17011626, 17009385, 17009514, 17009912, 17009909, 17009268, 17009773, 17010043, 17009957, 17009787]","score":401,"text":"Advertisement By COREY KILGANNONMAY 6, 2018\n Even by the dizzying standards of New York City philanthropy, a recent $6.24 million donation to the Henry Street Settlement on the Lower East Side was a whopper \u2014 the largest single gift from an individual to the social service group in its 125-year history. It was not donated by some billionaire benefactor, but by a frugal legal secretary from Brooklyn who toiled for the same law firm for 67 years until she retired at age 96 and died not long afterward in 2016. Her name was Sylvia Bloom and even her closest friends and relatives had no idea she had amassed a fortune over the decades. She did this by shrewdly observing the investments made by the lawyers she served. \u201cShe was a secretary in an era when they ran their boss\u2019s lives, including their personal investments,\u201d recalled her niece Jane Lockshin. \u201cSo when the boss would buy a stock, she would make the purchase for him, and then buy the same stock for herself, but in a smaller amount because she was on a secretary\u2019s salary.\u201d Advertisement Since Ms. Bloom never talked about this, even to those closest to her, the fact that she had carefully cultivated more than $9 million among three brokerage houses and 11 banks, emerged only at the end of her life \u2014 \u201can oh my God moment,\u201d said Ms. Lockshin, the executor of Ms. Bloom\u2019s estate. Advertisement \u201cI realized she had millions and she had never mentioned a word,\u201d recalled Ms. Lockshin. \u201cI don\u2019t think she thought it was anybody\u2019s business but her own.\u201d Ms. Bloom\u2019s will allowed for some money to be left to relatives and friends, but directed that the bulk of the fortune go toward scholarships of Ms. Lockshin\u2019s choice for needy students. Ms. Lockshin, the longstanding treasurer of the settlement\u2019s board, called the group\u2019s executive director, David Garza, and asked him if he was sitting down. \u201cWe were all agape, just blown away,\u201d recalled Mr. Garza, who said the money would endow the settlement\u2019s Expanded Horizons College Success Program, which helps disadvantaged students prepare for and complete college. The gift, made in February, was publicly disclosed last week. Ms. Bloom joins the ranks of unassuming and magnanimous millionaires next door, who have died with fortunes far larger than their lifestyles ever would have suggested. Like Ms. Bloom, Leonard Gigowski, a shopkeeper from New Berlin, Wis., who died in 2015, left his secret $13 million fortune to fund scholarships. Grace Groner, who lived in a one-bedroom home in Lake Forest, Ill., and directed that her $7 million estate go to her alma mater when she died in 2010 at 100, shopped at thrift stores and chose to walk, not drive. Donald and Mildred Othmer, who settled in Brooklyn Heights, lived relatively simple lives; he was a professor at Polytechnic University in Brooklyn and she was a former teacher and buyer for her mother\u2019s dress stores. They invested wisely in Berkshire Hathaway, run by a family friend from Omaha, Warren E. Buffett, and died in their 90s with three-quarters of a billion dollars, most of which they donated. While her aunt\u2019s wealth was a surprise, Ms. Bloom\u2019s quiet plan to help students was not, Ms. Lockshin said. Advertisement Ms. Bloom, who never had children of her own, was born to eastern European immigrants and grew up in Brooklyn during the Great Depression. She attended public schools, including Hunter College, where she completed her degree at night while working days to make ends meet. In 1947 she joined a fledgling Wall Street law firm as one of its first employees. Over her 67 years with the firm, Cleary Gottlieb Steen & Hamilton, it grew to its current size, with more than 1,200 lawyers, as well as hundreds of staff members, of which Ms. Bloom was the longest tenured, said Paul Hyams, a human resources executive for the firm who became good friends with Ms. Bloom over his 35 years working there. Ms. Bloom\u2019s husband, Raymond Margolies, who died in 2002, was a city firefighter who retired and became a city schoolteacher with a pharmacist career on the side, relatives said. Even when she married, Ms. Bloom kept her name, which was indicative of her independent nature, said a cousin, Flora Mogul Bornstein, 72. Nearly all the money was in Ms. Bloom\u2019s name alone, Ms. Lockshin said, adding that it was \u201cvery possible\u201d that even Mr. Margolies did not know the size of his wife\u2019s fortune.  Please verify you're not a robot by clicking the box. Invalid email address. Please re-enter. You must select a newsletter to subscribe to. View all New York Times newsletters. The couple lived modestly in a rent-controlled apartment, though \u201cshe could have lived on Park Avenue if she wanted to,\u201d Mr. Hyams said. \u201cShe was certainly not a spendthrift,\u201d Ms. Lockshin added. \u201cShe didn\u2019t have any minks.\u201d Ms. Bloom was known for always taking the subway to work, even on the morning of the Sept. 11, 2001, terror attacks on the World Trade Center, not far from the firm\u2019s offices. That day, Ms. Bloom, at 84, fled north and took refuge in a building before walking over the Brooklyn Bridge and taking a city bus \u2014 not a cab \u2014 home. Just before she retired, Mr. Hyams said he saw the 96-year-old Ms. Bloom trudging out of the subway and headed to work in the middle of a fierce snowstorm. \u201cI said, \u2018What are you doing here?\u2019 and she said, \u2018Why, where should I be?\u2019\u201d he recalled. Advertisement After retiring, Ms. Bloom agreed to move to a senior residence mainly because \u201cshe wanted to find a good bridge game,\u201d said Ms. Bornstein, a retired social worker. To scout them out, and finally to move into one on the Upper West Side, she insisted on taking the subway, Ms. Bornstein said. Mr. Hyams said Ms. Bloom regretted never going to law school. Still, he said, he was \u201ccompletely astounded\u201d to learn of her wealth after her death. \u201cShe never talked money and she didn\u2019t live the high life,\u201d he said. \u201cShe wasn\u2019t showy and didn\u2019t want to call attention to herself.\u201d A lover of chocolate but not lavish gifts, she would only accept his gifts of special chocolate in small quantities. \u201cShe was a child of the Depression and she knew what it was like not to have money. She had great empathy for other people who were needy and wanted everybody to have a fair shake.\u201d Ms. Lockshin said an additional $2 million from Ms. Bloom\u2019s bequest would be split between Hunter College and another scholarship fund to be announced. Mr. Garza called the gift \u201cthe epitome of selflessness,\u201d and a fitting gesture by a woman to the settlement, which was founded in 1893 by the public health pioneer Lillian Wald. The Henry Street Settlement now serves more than 60,000 people and provides an array of services in addition to its education support, including health care programs and transitional housing. Ms. Bloom\u2019s view of education was informed by her own public school experience and by working with successful lawyers from highly rated colleges and law schools, he said. Established in 1946, Cleary Gottlieb Steen & Hamilton has grown to become an international powerhouse and a go-to firm for nations that are having trouble paying their debts. The investment savvy Ms. Bloom gleaned from the firm\u2019s founding lawyers must have been equally sound. Advertisement \u201cShe had that dual perspective,\u201d Mr. Garza said, \u201cand it\u2019s probably why it resonated so deeply in her heart and her gut.\u201d Follow Corey Kilgannon on Twitter: @coreykilgannon. A version of this article appears in print on May 7, 2018, on Page A1 of the New York edition with the headline: Thrifty Brooklyn Secretary Leaves $8 Million for Needy Students.  Order Reprints| Today's Paper|Subscribe\n\n We\u2019re interested in your feedback on this page. Tell us what you think. Go to Home Page \u00bb","time":1525644491,"title":"96-Year-Old Secretary Quietly Amasses Fortune, Then Donates $8.2M","type":"story","url":"https:\/\/www.nytimes.com\/2018\/05\/06\/nyregion\/secretary-fortune-donates.html"},{"by":"tosh","descendants":4,"id":17008854,"kids":"[17011572, 17009440]","score":13,"text":" Mathematics is all around us, and it has shaped our understanding of the world in countless ways.   In 2013, mathematician and science author Ian Stewart published a book on  17 Equations That Changed The World. We recently came across this convenient table on Dr. Paul Coxon's twitter account by mathematics tutor and blogger Larry Phillips that summarizes the equations. (Our explanation of each is below):  performance.mark('first image displayed');Larry Phillips, via @paulcoxon on Twitter  Here is a little bit more about these wonderful equations that have shaped mathematics and human history:  \n                                            Shutterstock\/ igor.stevanovic \n                                    \n1) The Pythagorean Theorem: This theorem is foundational to our understanding of geometry. It describes the relationship between the sides of a right triangle on a flat plane: square the lengths of the short sides, a and b, add those together, and you get the square of the length of the long side, c.   This relationship, in some ways, actually distinguishes our normal, flat, Euclidean geometry from curved, non-Euclidean geometry. For example, a right triangle drawn on the surface of a sphere need not follow the Pythagorean theorem.   2) Logarithms: Logarithms are the inverses, or opposites, of exponential functions. A logarithm for a particular base tells you what power you need to raise that base to to get a number. For example, the base 10 logarithm of 1 is log(1) = 0, since 1 = 10; log(10) = 1, since 10 = 10 1; and log(100) = 2, since 100 = 10 2.   The equation in the graphic, log(ab) = log(a) + log(b), shows one of the most useful applications of logarithms: they turn multiplication into addition.   Until the development of the digital computer, this was the most common way to quickly multiply together large numbers, greatly speeding up calculations in physics, astronomy, and engineering.   3) Calculus: The formula given here is the definition of the derivative in calculus. The derivative measures the rate at which a quantity is changing. For example, we can think of velocity, or speed, as being the derivative of position \u2014 if you are walking at 3 miles per hour, then every hour, you have changed your position by 3 miles.   Naturally, much of science is interested in understanding how things change, and the derivative and the integral \u2014 the other foundation of calculus \u2014 sit at the heart of how mathematicians and scientists understand change.  Isaac NewtonWikimedia Commons\n4) Law of Gravity: Newton's law of gravitation describes the force of gravity between two objects, F, in terms of a universal constant, G, the masses of the two objects, m 1 and m 2, and the distance between the objects, r. Newton's law is a remarkable piece of scientific history \u2014 it explains, almost perfectly, why the planets move in the way they do. Also remarkable is its universal nature \u2014 this is not just how gravity works on Earth, or in our solar system, but anywhere in the universe.   Newton's gravity held up very well for two hundred years, and it was not until Einstein's theory of general relativity that it would be replaced.   5) The square root of -1: Mathematicians have  always been expanding the idea of what numbers actually are, going from natural numbers, to negative numbers, to fractions, to the real numbers. The square root of -1, usually written i, completes this process, giving rise to the complex numbers.   Mathematically, the complex numbers are supremely elegant. Algebra works perfectly the way we want it to \u2014 any equation has a complex number solution, a situation that is not true for the real numbers : x 2 + 4 = 0 has no real number solution, but it does have a complex solution: the square root of -4, or 2 i. Calculus can be extended to the complex numbers, and by doing so, we find some amazing symmetries and properties of these numbers. Those properties make the complex numbers essential in electronics and signal processing.  A cube.Wikimedia Commons  6) Euler's Polyhedra Formula: Polyhedra are the three-dimensional versions of polygons, like the cube to the right. The corners of a polyhedron are called its vertices, the lines connecting the vertices are its edges, and the polygons covering it are its faces.   A cube has 8 vertices, 12 edges, and 6 faces. If I add the vertices and faces together, and subtract the edges, I get 8 + 6 - 12 = 2.   Euler's formula states that, as long as your polyhedron is somewhat well behaved, if you add the vertices and faces together, and subtract the edges, you will always get 2. This will be true whether your polyhedron has 4, 8, 12, 20, or any number of faces.   Euler's observation was one of the first examples of what is now called a topological invariant\u2014 some number or property shared by a class of shapes that are similar to each other. The entire class of \"well-behaved\" polyhedra will have V + F - E = 2. This observation, along with with Euler's solution to  the Bridges of Konigsburg problem, paved the way to the development of topology, a branch of math essential to modern physics.  The normal distribution.economicshelp.org\n7) Normal distribution: The normal probability distribution, which has the familiar bell curve graph to the left, is ubiquitous in statistics.   The normal curve is used in physics, biology, and the social sciences to model various properties. One of the reasons the normal curve shows up so often is that it describes the behavior of large groups of independent processes.   8) Wave Equation: This is a differential equation, or an equation that describes how a property is changing through time in terms of that property's derivative, as above. The wave equation describes the behavior of waves \u2014 a vibrating guitar string, ripples in a pond after a stone is thrown, or light coming out of an incandescent bulb. The wave equation was an early differential equation, and the techniques developed to solve the equation opened the door to understanding other differential equations as well.   9) Fourier Transform: The Fourier transform is essential to understanding more complex wave structures, like human speech. Given a complicated, messy wave function like a recording of a person talking, the Fourier transform allows us to break the messy function into a combination of a number of simple waves, greatly simplifying analysis.   The Fourier transform is at the heart of modern signal processing and analysis, and data compression.   10) Navier-Stokes Equations: Like the wave equation, this is a differential equation. The Navier-Stokes equations describes the behavior of flowing fluids \u2014 water moving through a pipe, air flow over an airplane wing, or smoke rising from a cigarette. While we have approximate solutions of the Navier-Stokes equations that allow computers to simulate fluid motion fairly well, it is still an open question (with a million dollar prize) whether it is possible to construct mathematically exact solutions to the equations.   11) Maxwell's Equations: This set of four differential equations describes the behavior of and relationship between electricity (E) and magnetism (H).   Maxwell's equations are to classical electromagnetism as Newton's laws of motion and law of universal gravitation are to classical mechanics \u2014 they are the foundation of our explanation of how electromagnetism works on a day to day scale. As we will see, however, modern physics relies on a quantum mechanical explanation of electromagnetism, and it is now clear that these elegant equations are just an approximation that works well on human scales.   12) Second Law of Thermodynamics: This states that, in a closed system, entropy (S) is always steady or increasing. Thermodynamic entropy is, roughly speaking, a measure of how disordered a system is. A system that starts out in an ordered, uneven state \u2014 say, a hot region next to a cold region \u2014 will always tend to even out, with heat flowing from the hot area to the cold area until evenly distributed.   The second law of thermodynamics is one of the few cases in physics where time matters in this way. Most physical processes are reversible \u2014 we can run the equations backwards without messing things up. The second law, however, only runs in this direction. If we put an ice cube in a cup of hot coffee, we always see the ice cube melt, and never see the coffee freeze.  Albert EinsteinAssociated Press\n13) Relativity: Einstein radically altered the course of physics with his theories of special and general relativity. The classic equation E = mc 2 states that matter and energy are equivalent to each other. Special relativity brought in ideas like the speed of light being a universal speed limit and the passage of time being different for people moving at different speeds.   General relativity describes gravity as a curving and folding of space and time themselves, and was the first major change to our understanding of gravity since Newton's law. General relativity is essential to our understanding of the origins, structure, and ultimate fate of the universe.   14) Schrodinger's Equation: This is the main equation in quantum mechanics. As general relativity explains our universe at its largest scales, this equation governs the behavior of atoms and subatomic particles.   Modern quantum mechanics and general relativity are the two most successful scientific theories in history \u2014 all of the experimental observations we have made to date are entirely consistent with their predictions. Quantum mechanics is also necessary for most modern technology \u2014 nuclear power, semiconductor-based computers, and lasers are all built around quantum phenomena.   15) Information Theory: The equation given here is for Shannon information entropy. As with the thermodynamic entropy given above, this is a measure of disorder. In this case, it measures the information content of a message \u2014 a book, a JPEG picture sent on the internet, or anything that can be represented symbolically. The Shannon entropy of a message represents a lower bound on how much that message can be compressed without losing some of its content.   Shannon's entropy measure launched the mathematical study of information, and his results are central to how we communicate over networks today.   16) Chaos Theory: This equation is May's logistic map. It describes a process evolving through time \u2014 x t+1, the level of some quantity x in the next time period \u2014 is given by the formula on the right, and it depends on x t, the level of x right now. k is a chosen constant. For certain values of k, the map shows chaotic behavior: if we start at some particular initial value of x, the process will evolve one way, but if we start at another initial value, even one very very close to the first value, the process will evolve a completely different way.   We see chaotic behavior \u2014 behavior sensitive to initial conditions \u2014 like this in many areas. Weather is a classic example \u2014 a small change in atmospheric conditions on one day can lead to completely different weather systems a few days later, most commonly captured in the idea of a butterfly flapping its wings on one continent causing a hurricane on another continent.   17) Black-Scholes Equation: Another differential equation, Black-Scholes describes how finance experts and traders find prices for derivatives. Derivatives \u2014 financial products based on some underlying asset, like a stock \u2014 are a major part of the modern financial system.   The Black-Scholes equation allows financial professionals to calculate the value of these financial products, based on the properties of the derivative and the underlying asset.  Here are some traders in the S&P 500 options pit at the Chicago Board Options Exchange. You won't find a single person here that hasn't heard about the Black-Scholes equation.\n                                            REUTERS\/Frank Polich\n                                       ","time":1525644305,"title":"The 17 equations that changed the course of history","type":"story","url":"http:\/\/www.businessinsider.com\/17-equations-that-changed-the-world-2014-3"},{"by":"akjetma","descendants":1,"id":17008765,"kids":"[17015255]","score":37,"text":"\n\n\n\n by Ariana Tobin When you walk into the lobby of many major tech companies, one of the first things you\u2019ll encounter is a tablet screen laying out what you can and can\u2019t talk about after you leave. When you intern at a major law firm, you might be forced to agree to not to bring your case in front of a court. And when you leave a job at IBM \u2014 willingly or not \u2014 you\u2019re required to sign a whole stack of paperwork agreeing that you won\u2019t take a public stance about your experience. There are, of course, many reasons a company would want to create an atmosphere of confidentiality between employer and employee. Some are arguably to everyone\u2019s benefit \u2014 privacy agreements both sides wish to uphold. But some have been used to conceal harm, and even crimes. Such documents have popped up in story after story over the past year, from celebrity chef Mike Isabella insulting women with impunity after they\u2019d signed NDAs, Bill O'Reilly requiring women to sign settlement documents denying evidence of harassment as \u201ccounterfeit or forgeries,\u201d Harvey Weinstein preventing victims from even getting copies of the documents they\u2019d signed, and, of course, the President of the United States buying silence at most stages of his career, including this one.  We know these aren\u2019t the only examples. We hope to learn more about what effect these documents have on people\u2019s lives and careers. If you\u2019ve got a story to tell, we would of course love to hear it. But even if you don\u2019t, we\u2019d like to see your NDA anyway to learn more about what these agreements can encompass.  We won\u2019t publish a document or sensitive story without your permission. Unless you tell us it\u2019s OK, we won\u2019t share any details about what you submit. The form below is submitted via HTTPS, which means nobody can read what you submit except for us (and ScreenDoor, the service that hosts our submission forms). Someone listening to your internet connection might know you\u2019re submitting a form, but they can\u2019t read what you write. If you\u2019d rather talk on Signal or WhatsApp, which are more secure, send a message to 314-920-5990. Feel free to reach out to me, ariana.tobin@propublica.org, with any questions. \n\n\n\n Ariana is an engagement reporter at ProPublica.  \n\n\n                Get our stories by email.\n            \n\n\n Please enable JavaScript to view the comments powered by Disqus. Comments powered by Disqus  Thank you for your interest in republishing this story. You are are free republish it so long as you do the following: Copy and paste the following into your page to republish: Journalism in the Public\u00a0Interest","time":1525643208,"title":"Propublica Is Researching Employer NDAs","type":"story","url":"https:\/\/www.propublica.org\/getinvolved\/nondisclosure-agreements-employer-secrecy-nda"},{"by":"yazr","descendants":146,"id":17008727,"kids":"[17009451, 17011953, 17009062, 17010088, 17009919, 17009712, 17009894, 17009122, 17009092, 17010834, 17012931, 17010851, 17009119, 17009824, 17009481, 17009548]","score":156,"text":"May 9, 2018  https:\/\/www.wsj.com\/articles\/china-plans-47-billion-fund-to-boost-its-semiconductor-industry-1525434907 BEIJING\u2014In a move that could further heighten tensions with the U.S., China is poised to announce a new fund of about 300 billion yuan\u2014$47.4 billion\u2014to spur development of its semiconductor industry as it seeks to close the technology gap with the U.S. and other rivals, according to people familiar with the matter. The new war chest by the government-backed China Integrated Circuit Industry Investment Fund Co. follows a similar fund launched in 2014 that raised 139 billion yuan ($21.8 billion), largely funded by central and local government-backed enterprises and industry players.  Among other efforts, the fund would be used to improve China\u2019s ability to design and manufacture advanced microprocessors and graphic-processing units, one of the people said. Specific details including the amount could change, another person said. China Integrated Circuit Industry Investment Fund didn\u2019t immediately respond to a request for comment. In an interview with the Journal last year, the fund\u2019s executive vice president said it aims to generate returns for its investors. China is seeking to develop its own semiconductor industry to cut its dependence on foreign technology. The effort has grown more urgent as attempts to buy American chip companies have faced opposition from the U.S. over national-security concerns. The 2014 chip-development fund has been at the heart of U.S. complaints about China\u2019s technology policy in recent years.  In its March 22 report on China\u2019s trade practices, the U.S. Trade Representative\u2019s office said the dominance of government agencies and state-owned enterprises in the 2014 fund indicates \u201cthe high degree of Chinese government involvement in establishing the funds to meet national strategic objectives.\u201d As such, the establishment of the new fund is likely to further fuel U.S. cries of unfair play, said \n\n\n\n\n      William Reinsch, \n\n\n\n\n       a former trade official now at the Center for Strategic and International Studies. \u201cAnytime anybody puts that much money into a particular product or sector, there is going to be a significant market effect,\u201d Mr. Reinsch said. The move is likely to create excess chip supply in global markets that would force product prices down, putting pressure on U.S. and other foreign chip makers, he said. Semiconductors came up during two-day trade talks between the U.S. and China that ended on Friday. China asked the U.S. to ease restrictions on chip exports, according to a Chinese document discussed at the talks. An executive from the semiconductor industry said the move would be a message from Beijing that it is doubling down on its effort to develop its indigenous industry. \u201cWithout doubt, this will further increase tensions between China and the global players,\u201d the person said.  Chinese officials are preparing to announce the new fund \u201csoon,\u201d according to one of the people familiar with the matter. The Ministry of Industry and Information Technology said last week that \u201cvarious companies\u201d are welcome to invest into the fund, according to a transcript of a news conference. U.S. chip makers were among those approached informally by the fund to take part in the latest round, a person familiar with the matter said. But they would be unlikely to do so because of the politically sensitive timing and because the fund ultimately aims at making China less reliant on foreign companies, including the U.S. chip makers, the person said. The ministry didn\u2019t detail the amount of the fund during last week\u2019s news conference. News and research-firm reports over the past few months gave varying estimates of the fund amount in the $19 billion to $32 billion range.  Analysts say the new funding will give a boost to China\u2019s chip industry, but cautioned that China remains far behind leading foreign rivals, including the U.S., in semiconductor technology. Nearly 90% of the $190 billion worth of chips used in China are imported or produced in China by foreign-owned firms, according to International Business Strategies Inc., a research firm. China\u2019s vulnerability of relying on foreign technology was recently highlighted when the U.S. government cut Chinese smartphone and telecommunications-equipment maker \n\n\n\n\n\n\n            ZTE\n Corp.\u2019s\n\n\n       access to U.S.-made components. ZTE, heavily reliant on U.S. companies such as \n\n\n\n\n\n\n            Qualcomm\n Inc.\n\n\n       and \n\n\n\n\n\n\n            Intel\n Corp.\n\n\n       for chips used in its products, is now assessing the implications.  The semiconductor fund established in 2014 had invested in nearly 70 projects by the end of last year, according to people who heard a March speech by the fund\u2019s president, Ding Wenwu. That includes the Yangtze Memory Technologies Co.\u2019s 3D-NAND plant in Wuhan, which is set to start mass-production by the end of the year.  Analysts say it isn\u2019t yet clear whether that plant and others can compete on the world stage. What\u2019s more, China\u2019s leading semiconductor-production foundry still needs years before it could potentially catch up to industry leaders.  Chip making giants Intel Corp. and \n\n\n\n\n\n\n            Taiwan Semiconductor Manufacturing\n Co.\n\n\n       are also making significant investments, with each spending more than $10 billion a year in capital expenditure and research and development.  China is also short of semiconductor talent, despite efforts to attract foreign engineers with a salary level higher than the industry standard, analysts said. The semiconductor industry has lately taken a leading role in the U.S.-China trade conflict. San Diego-based Qualcomm Inc. has been waiting for China\u2019s antitrust regulator to approve its planned $44 billion purchase of \n\n\n\n\n\n\n            NXP Semiconductors\n            \n\n\n       NV\u2014a deal seen as critical to Qualcomm\u2019s future.  This week, Chinese regulators approved Qualcomm\u2019s joint venture with a unit of China\u2019s state-owned \n\n\n\n\n\n\n            Datang Telecom Technology\n Co.\n\n\n       to design smartphone chipsets, people familiar with the matter said.  But China is delaying the review of Qualcomm\u2019s NXP purchase as trade tensions escalate, the Journal has reported.  A spokesman for China\u2019s Commerce Ministry said last month that a preliminary review of the NXP deal had turned up \u201crelated issues that are hard to resolve, making it difficult to eliminate the negative impact.\u201d  Corrections & Amplifications   Ding Wenwu is the president of the China Integrated Circuit Industry Investment Fund. An earlier version of this article incorrectly identified him as the fund\u2019s chairman. (5\/6) \u2014 \n\n\n\n\n      Yang Jie\n\n\n\n\n       contributed to this article.   Write to Yoko Kubota at yoko.kubota@wsj.com \n      Appeared in the May 5, 2018, print edition as 'China Plans Fund to Boost Semiconductors.'\n     Fund would be used to improve China\u2019s ability to design and manufacture advanced microprocessors  An error has occurred, please try again later. Thank you This article has been sent to  WSJ Membership Customer Service Tools & Features Ads More  ","time":1525642811,"title":"China Plans $47B Fund to Boost Its Semiconductor Industry","type":"story","url":"https:\/\/www.wsj.com\/articles\/china-plans-47-billion-fund-to-boost-its-semiconductor-industry-1525434907"},{"by":"samsolomon","descendants":1,"id":17008693,"kids":"[17012036]","score":15,"text":"The recent eruptions from several volcanic vents in a residential neighborhood on Hawaii\u2019s Big Island have prompted the evacuation of thousands of residents. The Hawaiian Volcanoes Observatory said eight lava fissures had opened under Leilani Estates over the past few days. The opening of the fissures and lava flow from Kilauea Volcano follow a series of earthquakes, including a magnitude-6.9 quake on Friday, and the earlier collapse of a nearby crater, emptying the lake of lava within. The unfolding disaster is unpredictable, and may take a very long time to calm down enough to allow residents to return. \nA 2,000-foot-long fissure erupts within the Leilani Estates subdivision, on the east rift zone of the Kilauea volcano threatening homes of hundreds in Hawaii, on May 5, 2018.\n#\n \nLava erupts from a fissure in Leilani Estates subdivision on Hawaii's Big Island on May 4, 2018.\n#\n \nOn the morning of May 5, 2018, lava from fissure 7 slowly advanced to the northeast on Hookapu Street in Leilani Estates subdivision on Kilauea's lower East Rift Zone, burning trees and power poles.\n#\n \nResults of the eruption from Kilauea at night on May 4, 2018.\n#\n \nIn this photo released by U.S. Geological Survey, lava is shown burning trees and ground cover in the Leilani Estates subdivision near the town of Pahoa on May 3, 2018\n#\n \nOn May 4, 2018, a column of robust, reddish-brown ash plume occurred on the south flank of Kilauea, after a magnitude 6.9 earthquake shook the Big Island of Hawaii.\n#\n \nLava from Fissure 5, visible on May 4, 2018.\n#\n \nLava creeps across the road in the Leilani Estates subdivision on May 5, 2018, near Pahoa, Hawaii.\n#\n \nAfter a mandatory evacuation, Leilani Estates residents line up on the road leading to the area, on May 4, 2018. Due to unsafe conditions in the area, authorities were not allowing residents back to their homes.\n#\n \nSteaming cracks appear on May 4, 2018, in Leilani Estates, moments before a fissure opened up on Kaupili Street.\n#\n \nA panoramic view of a lava fissure cutting through Leilani Estates on May 5, 2018, at the corner of Leilani Street and Pohoiki Road. Earlier, a crack opened on Pohoiki Road (right) just east of Leilani Street.\n#\n \nA mailbox stands near the lava flow in Leilani Estates on May 5, 2018.\n#\n \nLava glows from a vent on a lava bed at Leilani Estates on May 5, 2018.\n#\n \nVolcanic gas streams out of a vent around a sign in Leilani Estates on May 5, 2018.\n#\n \nLeilani Estates resident Sam Knox watches the lava stretch across the road on May 5, 2018. Knox's home is less than a few hundred yards from the lava flow and he does not have any plans to evacuate. He said he was hopeful the lava will not take his home.\n#\n \nPower lines are pulled down by lava in Leilani Estates on May 5, 2018.\n#\n \nTi leaves on branches stand as a sacred offering in the cracks in roads in Leilani Estates on May 5, 2018.\n#\n \nA power line and transformer lay on top of a lava flow on May 5, 2018, near Pahoa, Hawaii.\n#\n \nKilauea volcano erupts, on May 4, 2018, seen from Kalapana, Hawaii.\n#\n \nHow Kilauea's 800-foot-wide Pu'u O'o crater appeared less than two weeks ago\u2014completely full of lava, on April 23, 2018. For the previous month and a half, the crater floor of Pu'u O'o experienced ongoing uplift, which generated cracks on the crater floor.\n#\n \nHow Kilauea's Pu'u O'o crater appeared on May 3, 2018\u2014completely drained of lava. In this photo released by U.S. Geological Survey, a plume of ash rises from the Pu'u O'o vent on Hawaii's Kilauea Volcano.\n#\n \nIn this still frame taken from video, lava flows over a road in the Puna District as a result of the eruption from Kilauea Volcano on May 4, 2018.\n#\n \nFissure 3 at Leilani and Kaupili Streets in Leilani Estates on May 4, 2018. Lava on the road was approximately 2 meters thick. \n#\n \nLava from the Kilauea volcano flows across a road in Leilani Estates, on Hawaii's Big Island, on May 5, 2018.\n#\n As we wait to see how today\u2019s eruptions in Hawaii will play out, take a moment to view some of Kilauea\u2019s most striking photos from the Mauna Ulu eruption, which ended only 40 years ago. A collection of images of the soaring landscape around Zhangjiajie in Hunan Province in South Central China. Up close with a sea lion in Vienna, World Dance Day in Budapest, May Day protests in Puerto Rico, ballet in Central Park, flooding in coastal Kenya, yoga in a Mexican desert, and much more. In 1918, the American photographer Lewis Hine traveled across France, photographing refugee families, orphaned children, wounded and shell-shocked soldiers, the nurses and volunteers who cared for them all, and the ruined buildings they fled.  Support 160 years of independent journalism.   TheAtlantic.com Copyright (c) 2018 by The Atlantic Monthly Group. All Rights Reserved.","time":1525642421,"title":"Photos of Kilauea's Lava Fissures on Hawaii's Big Island","type":"story","url":"https:\/\/www.theatlantic.com\/photo\/2018\/05\/photos-of-kilaueas-newest-lava-fissures-on-hawaiis-big-island\/559751\/?single_page=true"},{"by":"bryanrasmussen","descendants":7,"id":17007867,"kids":"[17009536, 17009005, 17009270]","score":22,"text":"\r\nBy \t\t\t\t\t\t\tTom Pittman, January 01, 2006 \n\n \n \n \n \n \nTom is a consultant and can be contacted at [email\u00a0protected]\n \n \n \n \n \nIn January 1976, Dr. Dobb's Journal of Tiny Basic Calisthenics and Orthodontia, Running Light without Overbyte was launched on the popularity of the article \"Build Your Own Basic,\" originally written anonymously by Dennis Allison. He was the \"D\" of \"Dobbs\" in the new magazine name. The \"B\" was Bob Albrecht, who ran a store-front, walk-in, computer time-share service called the \"People's Computer Company\" and who published a newsprint tabloid with the same moniker (PCC). The BYOB article first appeared in PCC after people began to realize that this $400 computer kit they bought was too hard to program in machine language, and Bill Gates's Altair Basic was considered too expensive at $150. \n \nI was not the first implementor. Dick Whipple and John Arnold were there ahead of me. But while there were a number of Tiny Basic projects well underway before I started, mine was distinctive in several ways. For instance, the others all ran on Intel CPUs (mostly 8080), I only did other chips. They were all free, but I charged $5 up front. Many people fondly remember using my Tiny Basic on their 8080 or Z80 when it was most likely actually Lee Chen Wang's Palo Alto Tiny Basic that they were using. \n \nAnother significant difference is that my Tiny Basic was the only one to use Allison's original IL code (available electronically; see \"Resource Center,\" page 4) pretty much as defined. There were several bugs I had to correct, and I added some opcodes to support a couple of Tiny Basic functions, but the BYOB interpreter was written in a special-purpose pseudocode, which Dennis recommended interpreting. I knew about interpreters, having done several of them over the years. Everybody else hand-translated the pseudocode to assembly language. So, as far as I know, my Tiny Basic was the only one with a two-level interpreter.  \n \nThis technology is still interesting and useful today. In this article, I examine what's involved in recreating my original Tiny Basic in today's universal assembly language\u0097ANSI Standard C. \n \nThe first issue of DDJ (which is available electronically as a PDF e-zine; see \"Resource Center,\" page 4), reproduced the original concept article and three follow-up articles from the PCC, showing the progression in Allison's thinking. It's a valuable study in the formulation of a sophisticated software solution to an understandable problem. I don't have space here to recreate all the thinking he alludes to, but I do touch on some of the technical issues and trade-offs of implementing pseudocode interpreters. \n \nMy introduction to virtual machines (VM) came as an off-hand remark at my first full-time job. Drexel Heater pointed out that regularly using my own library of Fortran subroutines amounted to designing my own programming language. Although never articulated so clearly, this idea pervades the programming community even today, particularly in C++ with the Standard Template Library, which by operator overloading actually changes the meaning of the Standard C operators. This concept gives you ultimate control over software design. Where Alan Kay predicts the future by inventing it, we predict software behavior by inventing the computer it runs on. \n \nEvery programming language is the machine language of some abstract computer whose machine operations are exactly that language's primitives. If you remove an operator from the language by not using it, you have effectively changed (limited) the computer. But let's increase, not reduce, the power of the machine. We do this by making the operations do more. That was Drexel's point about the subroutines. \n \nC is more powerful than binary absolute, not because you can do more (you can't), but because the same programmer effort accomplishes more. A simple assignment\u0097four keystrokes\u0097hides a great deal of work the compiler does to allocate the variable: It chooses a representation of the value as well as the hardware instructions to copy those bits into that memory location. All this work is necessary, but not part of the problem the programmer is solving. Correspondingly, those four keystrokes are necessary, but not part of the specified program requirements. The most powerful programming language is where you state the requirements in a task-specific language, then the computer does it. That is the programming language you should write in. \n \nDennis Allison's (and my) Tiny Basic gets close to a direct implementation of a task-specific programming language. \n \nAllison encouraged his collaborators to read a compiler book. At the risk of appearing self serving, I repeat the advice. The Art of Compiler Design: Theory and Practice, which I cowrote with James Peters (Prentice Hall, 1991; ISBN 0130481904), emphasizes the context-free grammar as the primary design tool for the entire grammar. (You can download a free copy of my self-compiling compiler-compiler, written entirely in a grammar, at http:\/\/www.IttyBittyComputers.com\/IttyBitty\/TAGC\/ TAGinfo.html). I learned this emphasis from Allison's Tiny Basic. The important point is that the grammar is a compact notation for expressing a program as a sequence of statements, and each statement is (in the case of Tiny Basic) a keyword followed by other specified parts, and so on, as in Figure 1, the original Tiny Basic grammar. The grammar is itself written in a precise formal language. The grammar is a program; all that remains is to compile (translate) the grammar-program into machine language and run it. \n \nWell, not quite. The grammar only specifies syntax. You also need to specify semantics, what to do when the grammatical (correct) program is accepted and run. I'll expand on the grammar somewhat, by means of English pseudocode: Tiny Basic reads lines. Each line is a statement, possibly with a line number in front (first grammar rule). If it has a line number, insert the numbered statement into the stored program; otherwise just do whatever the statement is (semantics). Repeat indefinitely. \n \nA statement is one of the following 11 things: The keyword PRINT followed by a list of expressions to print, which are evaluated one by one, printed, then spaced over to the next \"zone\"; or else it is the keyword IF followed by an expression, which is evaluated, then a relational operator and another expression that is also evaluated and compared to the first expression value, followed by the keyword THEN and then finally another statement, which is executed if the comparison is True; or else a statement is the keyword GOTO followed by a line number expression, which is evaluated and becomes the next line to execute; and so on. \n \nSimilarly, an expression is a term, possibly preceded by a sign, then followed by any number of additional terms each preceded by + or -. Evaluate each term, then add or subtract each successive term. The result is the expression value. \n \nA term is a factor, followed by any number of additional factors, each preceded by a * or \/. You get the idea. \n \nNow you have specified the whole interpreter. That is the program, more complete than the grammar alone because it also says how to do the computation. But still, even less than the grammar, it is not understandable by 1975 microcomputers. Even now, 30 years later, only people understand English\u0097and not all that well. So let's formalize this a little and make it more like a conventional programming language.  \n \nFor \"Tiny Basic reads lines\" I use the programming command GETLINE to read each line. Still buried in there are all the mechanics of accepting characters into a line buffer, stopping when users press the Enter key, and preventing buffer overrun, details that do not concern us at this level. \n \nFor \"possibly with a line number in front,\" I use the command\/test TSTL and the label of that part of the program to handle the line if there is no number. The English explanation: To \"insert the numbered statement into the stored program,\" I spell INSERT. The English word \"insert\" could mean any number of things in other contexts, none of them relevant to interpreting a Tiny Basic program. Thus, this single word is sufficient to explain the whole intent of this operation. Notice also that the grammar says nothing about insertion; it is semantics\u0097what to do with this line now that you know it has a line number. \n \nFor \"Repeat indefinitely\" (not in Allison's grammar, although it should be there as a star), you can write JMP with the name of the line where we started. That starts to look like a real programming language. That's exactly what it is: the assembly language for a VM that interprets Tiny Basic. Table 1 presents a partial correlation between grammar, English pseudocode, and IL, both Allison's original in DDJ #1 and my own subsequent TBIL. Listing One shows the resulting IL from DDJ #1, with some of the errors corrected. This program in IL will execute a Tiny Basic statement. The operators TST, TSTV, TSTN, and PRS all use a cursor to find characters of the Tiny Basic line. Other operations (NXT, XPER) move the cursor so it points to a Tiny Basic line. I corrected a few obvious errors. TBILasm is an assembler written in Tiny Basic. TBILasm and my extensions showing the hexadecimal byte codes are available as part of the Tiny Basic Experimenter's Kit (TBEK.txt), available at http:\/\/www.IttyBittyComputers.com\/IttyBitty\/TinyBasic\/TBEK.txt.) \n \nJust as the particular words of the English-language pseudocode depend on who is saying it and how they happen to think of the problem at that moment, the particular expression of the IL is also idiosyncratic. You can see that in the difference between Allison's IL and mine. Some of it is just spelling differences (to simplify my assembler) and added features. However, there are also some differences in what the words actually do, particularly in startup and line advance, where Allison was initially somewhat vague. No two independently written programs will ever exactly match, even if they perform identically. \n \nThe point of this exercise is to express all of the relevant program operation in a concise form. In Tiny Basic, a large part of the program specification is already in a concise grammar, but we needed to add semantics. Other projects would have different requirements. \n \nOne of my objectives in doing this C Tiny Basic project was to investigate the mechanics for putting a graphical user interface (GUI) on a Windows program. Three years ago, when Apple killed the only commercially viable WYSIWYG operating system that ever existed, I threw away 67,000 lines of active Mac-only code. I can rewrite that program, but I need to get away from proprietary platforms the vendor can arbitrarily discontinue. C\/C++ is an ANSI-standard multiplatform programming language, but there is no standard GUI. So I chose to build a virtual GUI, emulated on whatever platform is available, and implemented interpretively (in an IL) like Tiny Basic. Tiny Basic is thus a good testbed for it. \n \nThere is a performance cost to interpretation. It depends on the implementation language and the IL design, but typically costs three to 10 machine instructions or lines of source-code overhead on each VM operation, besides the code to do the operation. Very high-level operations such as the TBIL or my GUI emulator spend a lot of time doing each operation, so the overhead is a small penalty. A low-level VM such as Java bytecode, which does much less in each operation, typically runs an order of magnitude slower than native code to do the same job. Because the VM is relatively fixed and widely used, the cost of implementing a just-in-time (JIT) compiler from bytecode to native machine code is justified. Other VMs such as Forth, which has no fixed IL, can reduce the cost by careful IL design: Depending again on the host hardware, a threaded-code (Forth) interpreter costs only one to three overhead machine instructions for each VM operation, giving it performance comparable to compiled code. \n \nAnother trade-off to consider is readability (maintainability). Anybody who studied computer science in the last four decades can read grammars; however, TBIL is as hard to read, but not so widespread, as an assembly language. Forth is completely idiosyncratic to the individual programmer and application; it is truly a \"write-only\" language.  \n \nAgainst that readability fog index we trade off panorama, the ability to see in a single view everything that is going on. Allison's IL was only 110 lines, which could be viewed in less than one column of tiny font on the original PCC tabloid, or in two screenfulls on a modern high-res display. Furthermore, it divides nicely in half, the first half being the statement executor, and the rest is expressions and other subroutines. My own TBIL, at 230 lines, is correspondingly less readable. \n \nThere are a variety of techniques to choose from in implementing intermediate-level or pseudocode languages. Most of us are familiar with the early Java runtime interpreter and its replacement on all modern platforms by a JIT compiler. Apple went through the same transition when moving its customer base from the Motorola 68000 CPU family to the IBM Power PC family, and again when dropping the (classic) Mac OS for UNIX. The 68000 instruction set was fully interpreted on the first PowerMacs, at about a 10\u00d7 performance cost. Several independent developers (including myself) later got substantial performance gains by implementing a binary-to-binary JIT compiler. The \"Classic\" runtime environment is similarly carried along in OS X to run legacy Mac code, with comparable interpretation penalties. \n \nAllison's (and my) TBIL was implemented in the same manner by a direct interpreter, which preserves the original pseudocode. Similarly, the TBIL interpreter itself preserves the original Basic code in memory as it interprets it. Most full Basic interpreters did a simple kind of JIT translation from Basic text to condensed internal tokens. The Whipple and Arnold Tiny Basic effectively did the same by hand-translating the IL to machine code as they wrote. This removes the panorama of the original IL, but they didn't even use an assembler, choosing rather to code everything in octal absolute, a surprisingly popular Luddite methodology whose proponents have never survived long in the marketplace. \n \nThe implementation of Forth bears closer examination because of its heritage in my colleague Drexel Heater's remark. A VM consisting entirely of a library of subroutines called by the high-level problem solution is conceptually not so different from the TBIL approach: Each IL opcode can be thought of as a subroutine (for indeed it is) that is called by the IL code where it is used. Whipple and Arnold replaced those byte codes with the actual subroutine calls, which made their VM more closely resemble my Fortran VMs of 30 years ago. Forth takes that one step further and replaces all the overhead of a normal subroutine call with just the address of the subroutine. In this \"threaded code,\" each successive subroutine call does nothing more than load the next address in sequence into the CPU program counter. The parameters are handled the same way because every operator is threaded code. It still needs to stack and unstack the current IL address entering and leaving nonprimitive subroutines, but the whole interpreter is straightforward. \n \nThe direct interpretation technology chosen for Tiny Basic sacrifices up to an order of magnitude execution speed, but the speed of modern computers reduces the impact. Moreover, the memory bus bandwidth limits in modern computers can completely cancel the speed advantage of native code over interpretation. How can this be? Consider that the Tiny Basic virtual machine (VM) is completely defined in 443 bytes of IL code; the same code in handwritten assembly is more than 2K, a factor of 5\u00d7. Although Tiny Basic is tiny, if the IL interpreter generally fits into the primary CPU cache with its IL, while the much larger native code does not, the IL code will execute at native CPU speed while the native code thrashes much slower.  \n \nTwelve years ago, I implemented a dynamic recompiler to convert legacy 68000 code being interpreted in Apple's PowerMac computers, into native Power PC code. I expected (and got) about 4\u00d7 speedup\u0097for small programs. Larger programs actually ran slower than the pure interpreter. At first, I suspected my recompiler cache was thrashing, forcing unnecessary recompilation, but careful instrumentation showed that the recompiler was executing less than 10 percent of the total time. A logic analyzer showed that most of the time was spent waiting for the CPU cache to reload from main memory. I added a large L2 cache, but got only minor improvements. Modern CPUs executing instructions 20 or more times faster than the memory bus exhibit the problem even worse. Recall that the cost of vanilla interpretation is 10\u00d7. An IL interpreter could actually make your application run faster than native code, depending on actual code sizes. I called this \"the RISC penalty\" because Reduced Instruction Set Computer (RISC) code is so much less dense than complex instruction sets; high-level ILs are even more dense, exaggerating the effect. \n \nIgnoring the RISC penalty, what else can impact performance? The choice of implementation language is significant. Although \"C\/C++\" are often hyphenated as if they were but one language, they really are not. Though compiler vendors have done a lot to mitigate the overhead cost of late-binding methods in support of inheritance and polymorphism, it is still significant compared to pure C.  \n \nEven in pure C, the cost of calling functions is substantial compared to inline code. If the interpreter is carefully designed as a big switch statement inside a while(true) and no function calls, modern optimizing compilers will give nearly optimal machine speed. In my first attempt at Tiny Basic IL in C, I used autoincrement on byte and int pointers for all memory accesses to get maximum performance. I later replaced that with function calls for compatibility to my previous implementations, which specified number stacks implemented as pairs of bytes in memory. This could still be inlined using C macros to eliminate the function call overhead, but at the cost of larger code. \n \nA master artisan controls his tools. For a programmer, that means understanding what kind of code the compiler gives you for each statement type. Allison recommended a cascading tree of nested IFs in his \"Build Your Own Basic\" articles, but his objective was minimal space. I recommend a switch statement for better speed. A good compiler can select any of many individual snippets of code in a single indexed jump in constant time, whereas nested IF trees require log(n) or more individual tests. The Forth interpreter overhead is so small it can be replicated at the end of every operation code, so there isn't even the overhead to jump to a shared interpreter loop. \n \nFollowing Allison's suggestion, my original TBIL interpreters were implemented in assembly language and optimized for minimal space. In this project, I wrote in ANSI Standard C with a modest goal (not entirely served) of tuning for speed. The C source code and some Tiny Basic programs that run in it are available electronically from DDJ and at http:\/\/www.IttyBittyComputers.com\/IttyBitty\/TinyBasic\/. \n \nDDJ \n \n\n\nListing One\n \n\n\n These tags can be used alone and don't need an ending tag.  <br> Defines a single line break \n<hr> Defines a horizontal line These require an ending tag - e.g. <i>italic text<\/i>  <a> Defines an anchor\n<b> Defines bold text\n<big> Defines big text\n<blockquote> Defines a long quotation\n<caption> Defines a table caption\n<cite> Defines a citation\n<code> Defines computer code text\n<em> Defines emphasized text\n<fieldset> Defines a border around elements in a form\n<h1> This is heading 1\n<h2> This is heading 2\n<h3> This is heading 3\n<h4> This is heading 4\n<h5> This is heading 5\n<h6> This is heading 6\n<i> Defines italic text\n<p> Defines a paragraph\n<pre> Defines preformatted text\n<q> Defines a short quotation\n<samp> Defines sample computer code text\n<small> Defines small text\n<span> Defines a section in a document\n<s> Defines strikethrough text\n<strike> Defines strikethrough text \n<strong> Defines strong text \n<sub> Defines subscripted text \n<sup> Defines superscripted text \n<u> Defines underlined text Dr. Dobb's encourages readers to engage in spirited, healthy debate, including taking us to task.  \r\n\t\t  However, Dr. Dobb's moderates all comments posted to our site, and reserves the right to modify or remove any content that it determines to be derogatory, offensive, inflammatory, vulgar, irrelevant\/off-topic, racist or obvious marketing or spam. Dr. Dobb's further reserves the right to disable the profile of any commenter participating in said activities. \nThis month, \nDr. Dobb's Journal is devoted to mobile programming. We introduce you to Apple's new Swift programming language, discuss the perils of being the third-most-popular mobile platform, revisit SQLite on Android\t\t\n\t\t\t\t, and much more!\nDownload the latest issue today. >>\n","time":1525634073,"title":"The Return of Tiny Basic (2006)","type":"story","url":"http:\/\/www.drdobbs.com\/web-development\/the-return-of-tiny-basic\/184406381"},{"by":"baron816","descendants":328,"id":17007630,"kids":"[17008696, 17007695, 17008148, 17008011, 17008493, 17007778, 17008422, 17008988, 17007919, 17010637, 17008950, 17027531, 17007985, 17010517, 17008942, 17008593, 17008368, 17008343, 17014350, 17009307, 17008242, 17008470, 17008289, 17008507, 17009775, 17008472, 17008645, 17008401, 17008680, 17008126, 17007814, 17007793, 17010007, 17008902, 17008653, 17008019, 17008550, 17008818, 17008568, 17007768, 17007766, 17008313, 17009008, 17011289, 17010487, 17009234, 17008080, 17008621, 17008498, 17008428]","score":314,"text":"\n\t\t\tTrending:\t\t For seven years, a handful of homebuilders offered solar as an optional item to buyers willing to pay extra to go green. Now, California is on the verge of making solar standard on virtually every new home built in the Golden State. The California Energy Commission is scheduled to vote Wednesday, May 9, on new energy standards mandating most new homes have solar panels starting in 2020.  Workers for SunPower Corp. install solar panels on the roofs new houses at KB Home\u2019s Terramore development in Riverside County. Solar systems like these will become standard by 2020 on virtually all new California homes under a proposed new energy code up for review in Sacramento on May 9. (Photo by Will Lester- The Press-Enterprise\/SCNG)\n  A hawk surveys the installation of solar panels at KB Home\u2019s Terramore development south of Corona. Panels like these would be required for virtually all California homes by 2020 under a proposed new building code. \u201cIt may not be full zero net energy, but we have left the rest of the country in the dust,\u201d said Bob Raymer, technical director for the California Building Industry Association. (Photo by Will Lester- The Press-Enterprise\/SCNG)\n  Tiles await installation atop a new house in KB Home\u2019s Terramore development in Riverside County while a SunPower Corp. employee installs new solar panels there. Many builders like KB Home have been offering solar packages for years. But solar would become standard by 2020 under energy provisions up for a vote in Sacramento on May 9. KB Home estimates it has built 6,000 \u201cZeroHomes\u201d since 2012. (Photo by Will Lester- The Press-Enterprise\/SCNG)\n  A SunPower employee completes installation of solar panels at KB Home\u2019s Terramore development in western Riverside County. Solar systems like this would become standard at new homes throughout California if state officials adopt proposed new energy standards. \u201cCalifornia is about to take a quantum leap in energy standards,\u201d said Bob Raymer, senior engineer for the California Building Industry Association. (Photo by Will Lester- The Press-Enterprise\/SCNG)\n  A SunPower employee installs rooftop solar panels on a new house under construction in KB Home\u2019s Terramore development near the 15 freeway south of Corona. California is on the verge of becoming the first state in the nation mandating solar power be included in all new homes built after Jan. 1, 2020. \u201cInnovations and sustainability has been at the heart of our business for many years,\u201d said Jacob Atalla, KB Home\u2019s vice president of sustainability initiatives. (Photo by Will Lester- The Press-Enterprise\/SCNG)\n  Wearing a safety tether, a SunPower worker attaches wiring to a newly installed solar panel at a KB Home development in Riverside County. Homes like these already meet proposed state energy standards mandating virtually all new houses, condos and apartments up to three stories tall have solar power starting in 2020. A building industry official estimates that 20 perent or fewer new California houses now have solar. New standards adopted over the past eight years also increased the energy efficiency of California homes. (Photo by Will Lester- The Press-Enterprise\/SCNG)\n  A worker sets a final photovoltaic panel in place atop a house in KB Home\u2019s Caraway at Terramore development south of Corona. Virtually all new homes in California will have to have similar \u201cPV\u201d panels starting in 2020 under proposed rules state energy officials are expected to approve May 9. \u201cIt\u2019s no surprise for us,\u201d said Jacob Atalla, KB Home\u2019s vice president of sustainability initiatives. State officials, Atalla said, \u201chave been preparing for it for several years by ramping up the (building) code.\u201d (Photo by Will Lester- The Press-Enterprise\/SCNG)\n  SunPower workers install solar panels on the roofs of homes under construction at KB Home\u2019s Terramore development south of Corona. Although state energy officials seek to mandate solar on virtually all new California homes starting in 2020, the state is backing away from a 10-year-old goal of making all new homes \u201cnet zero,\u201d meaning they would generate as much energy as they consume. Net zero doesn\u2019t focus on the need to reduce fossil fuel emissions, state officials said. \u201cThe next frontier should be near-zero net emissions rather than zero net energy, said Pierre Delforge, energy efficiency program director at the Natural Resources Defense Council. (Photo by Will Lester- The Press-Enterprise\/SCNG)\n  Fewer solar panels will be required on new California homes by 2020 than originally planned under a proposed new building code. The state has abandoned the goal of making all new homes \u201czero net energy\u201d by 2020, partly because it\u2019s not cost-effective and partly because zero net energy is at odds with goals to reduce fossil fuel emissions.  \u201cZero-net energy isn\u2019t enough,\u201d said Andrew McAllister, one of five state energy commissioners voting May 9 on new homebuilding energy standards mandating solar on new homes by 2020. (Photo by Will Lester- The Press-Enterprise\/SCNG)\n  High atop a new house in KB Home\u2019s Terramore development in Riverside County, a SunPower worker readies another solar panel for installation. The California Energy Commission is scheduled to vote May 9 on new standards mandating that virtually all new California homes have solar systems by 2020. But the state is abandoning a long-term goal of making homes \u201cnet zero.\u201d Said KB Home sustainability Vice President Jacob Atalla: \u201cYou\u2019ve got to start treating (solar) less as a luxury and more as a commodity.\u201d  (Photo by Will Lester- The Press-Enterprise\/SCNG)\n  A SunPower employee completes installation of solar panels at KB Home\u2019s Terramore development in Riverside County. Solar systems like this would become standard at new homes throughout California if state officials adopt proposed new energy standards. \u201cCalifornia is about to take a quantum leap in energy standards,\u201d said Bob Raymer, technical director for the California Building Industry Association. (Photo by Will Lester- The Press-Enterprise\/SCNG)\n  A worker with SunPower Corp. installs solar panels on the roof of a house in KB Home\u2019s Caraway at Terramore development south of Corona. State energy officials are expected to adopt new building standards making California the first state in the nation to mandate solar be installed on most new homes built in the state starting in 2020. (Photo by Will Lester- The Press-Enterprise\/SCNG)\n  Photovoltaic panels like these would become standard on new California homes starting in 2020 under a proposed new energy code up for review in Sacramento on May 9. Currently about 15 percent to 20 percent of new houses in the state have solar power systems, a state building industry officials said. Here a SunPower Corp. employee finishes up installation of new solar panels at KB Home\u2019s Terramore development in Riverside County. (Photo by Will Lester- The Press-Enterprise\/SCNG)\n  Photovoltaic panels like these would become standard on new California homes starting in 2020 under a proposed new energy code up for review in Sacramento on May 9. Currently about 15 percent to 20 percent of new houses in the state have solar power systems, a state building industry officials said. Here a SunPower Corp. employee finishes up installation of new solar panels at KB Home\u2019s Terramore development in Riverside County. (Photo by Will Lester- The Press-Enterprise\/SCNG)\n  Proposed new energy standards up for review May 9 in Sacramento would mandate solar panels like these be installed on virtually all new California homes by 2020. However, the state is abandoning a long-term goal of requiring all new homes achieve \u201cnet zero\u201d status, partly because it\u2019s not cost-effective and partly because the goal is at odds with the need to reduce fossil fuel emissions, state officials said. \u201cNet energy metering\u201d rules also don\u2019t require utilities to compensate customers for extra solar power generated to offset natural gas used in the home. (Photo by Will Lester- The Press-Enterprise\/SCNG)\n  Photovoltaic panels like these would become standard on new California homes starting in 2020 under a proposed new energy code up for review in Sacramento on May 9. Currently about 15 percent to 20 percent of new houses in the state have solar power systems, a state building industry officials said. Here a SunPower Corp. employee finishes up installation of new solar panels at KB Home\u2019s Terramore development in Riverside County. (Photo by Will Lester- The Press-Enterprise\/SCNG)\n  Workers install solar panels at KB Home\u2019s Caraway at Terramore housing development. The company has built about 6,000 \u201cZeroHomes,\u201d most of them in California over the past six years. That represents about 12 percent of all KB Home residences sold. The California Energy Commission is expected to vote on May 6 on new standards mandating virtually all homes built in the state have solar panels starting in 2020. (Photo by Will Lester- The Press-Enterprise\/SCNG)\n  If approved as expected, solar installations on new homes will skyrocket. Just 15 percent to 20 percent of new single-family homes built include solar, according to\u00a0Bob Raymer, technical director for the California Building Industry Association. \u201cCalifornia is about to take a quantum leap in energy standards,\u201d Raymer said. \u201cNo other state in the nation mandates solar, and we are about to take that leap.\u201d Why homebuyers don\u2019t go solar:\u00a0Mortgage industry has failed to adapt, one expert says The proposed new rules would deviate slightly from another much-heralded objective: Requiring all new homes be \u201cnet-zero,\u201d meaning they would produce enough solar power to offset all electricity and natural gas consumed over the course of a year. New thinking has made that goal obsolete, state officials say. True \u201czero-net-energy\u201d homes still rely on the electric power grid at night, they explained, a time when more generating plants come online using fossil fuels to generate power. \u201cZero net energy isn\u2019t enough,\u201d said Andrew McAllister, one of five state energy commissioners voting on the new homebuilding standards. \u201cIf we pursue (zero net energy) as a comprehensive policy, we\u2019d be making investments that would be somewhat out of touch with our long-term goals.\u201d While environmentalists and homebuilders praised the new standards, the proposed rules have some detractors who still support net-zero goals. \u201cWe\u2019re happy they\u2019re making good progress,\u201d said Kelly Knutsen, technology advancement director for the California Solar and Storage Association, a solar-industry group. \u201cWe wish they would go further. There\u2019s always compromises.\u201d In addition to widespread adoption of solar\u00a0power, the new provisions include a push to increase battery storage and increase reliance on electricity over natural gas. Among the highlights: The mandate dates back to 2007 when the state energy commission adopted the goal of making homebuilding so efficient \u201cnewly constructed buildings can be net zero energy by 2020 for residences and by 2030 for commercial buildings.\u201d Builders would prefer the state move slower in imposing the solar mandate, but most nonetheless should be prepared by mid-2020, said the Building Industry Association\u2019s\u00a0Raymer. Meritage Homes currently installs solar on about 10 percent of its homes, and about 1 percent of them are net zero, a company official said. A KB Home official said his firm has built more than 6,000 solar homes in the past seven years, mostly in California. That\u2019s 12 percent of the 49,600 homes KB Home sold in that period. The new energy standards add about $25,000 to $30,000 to the construction costs compared with homes built to the 2006 code, said C.R. Herro, Meritage\u2019s vice president of environmental affairs. Solar accounts for about $14,000 to $16,000 of that cost, with increased insulation and more efficient windows, appliances, lighting and heating accounting for another $10,000 to $15,000. But that $25,000 to $30,000 will result in $50,000 to $60,000 in the owner\u2019s reduced operating costs over the 25-year life of the home\u2019s solar system, Herro said. Bill Watt, a homebuilder and design consultant, said those added costs \u2013 on top of other building mandates like fire sprinklers \u2013 are pushing home prices further out of reach for many buyers. \u201cWe\u2019re not building enough housing already,\u201d said Watt, former president of the Orange County Building Industry Association. \u201cWhy not just pause for a little while, focus on the affordability and housing issues, then circle back?\u201d Environmentalists, however, praised the new standards. \u201cThe technology is developing so fast, we think the timeline was a bit slow,\u201d said Kathryn Phillips, director of Sierra Club California. Pierre Delforge, energy efficiency program director at the Natural Resources Defense Council, called the proposed update \u201canother important step toward the environmentally-friendly, healthy and affordable home of the future.\u201d While net-zero remains an admirable goal, getting there is not yet cost-effective, state officials and experts said. And it fails to address the state\u2019s ultimate goal of curbing global warming. Because electric utilities now rely on renewable energy for much of their power, daytime energy already is quite clean, said McAllister, the lead state commissioner on energy efficiency. At night when there\u2019s no solar power, people come home, turn on the lights, the TV and possibly the air conditioning and start pulling power from the grid, he said. Some gas-powered generating plants then are fired up to help meet that additional load, boosting carbon emissions. \u201cThat additional (home-generated) solar kilowatt-hour isn\u2019t worth very much because it\u2019s displacing what is already clean energy,\u201d McAllister said. \u201cThat net-zero home is not a net-carbon-zero home.\u201d MORE HOUSING NEWS: \u00a0 Get the latest news delivered daily! We invite you to use our commenting platform to engage in insightful conversations about issues in our community. Although we do not pre-screen comments, we reserve the right at all times to remove any information or materials that are unlawful, threatening, abusive, libelous, defamatory, obscene, vulgar, pornographic, profane, indecent or otherwise objectionable to us, and to disclose any information necessary to satisfy the law, regulation, or government request. We might permanently block any user who abuses these conditions. If you see comments that you find offensive, please use the \u201cFlag as Inappropriate\u201d feature by hovering over the right side of the post, and pulling down on the arrow that appears. Or, contact our editors by emailing moderator@scng.com.","time":1525631798,"title":"California to become first U.S. state mandating solar on new homes","type":"story","url":"https:\/\/www.ocregister.com\/2018\/05\/04\/california-to-become-first-u-s-state-mandating-solar-on-new-homes\/"},{"by":"rickhaasteren","descendants":26,"id":17007628,"kids":"[17008618, 17009011, 17007724, 17008973, 17008396, 17008236, 17007929]","score":117,"text":"Owner of SiteGuru.co About a year ago, I launched Siteguru, my SEO tool. Right now, the tool has over a thousand users. This is how I did it. Some background info: SiteGuru is a free SEO tool. Initially, you could check just one page and would have to sign up to analyze your entire site. Signing up is free, and I offer paid plans for analyzing more pages.   Right after I launched the first MVP of my product, I ran a few Adwords ads just to see if it caught on. I knew the product was far from perfect, but I thought it was useful. Adwords was a great way to figure out if other people agreed. I wrote about this in my post\u00a0How I tested my website with 100 real visitors spending just $100. It worked, and after a week SiteGuru had it's first 10 users. Because I didn't have any paid subscribers, I knew Adwords wouldn't be a sustainable solution. But it did help me figure out if the product was worth more effort. I got positive feedback from people who tried Siteguru, so it was time to do some outreach. I started emailing bloggers in the SEO space, inviting them to try Siteguru and write about it. At the same time, I hired a linkbuilder to reach out to relevant sites that could feature my tool. The result? Zero. Nothing. I didn't get a single response, and neither did the guy I hired. I knew it's a competitive space, but this was disappointing. Through some more Adwords campaigns, SiteGuru was at 60 users. In August, I posted SiteGuru on ProductHunt, and it was mildly successful. I got about 100 upvotes, lots of visitors, and about 100 signups. SiteGuru was now at 180 users. In November '17, SiteGuru got featured on StackCommerce. They let me offer a paid deal at a ridiculous discount (90%), featured the deal on sites like The Next Web, and brought in lots of visitors. Lots of these visitors signed up, either using the StackCommerce deal, or just for a free account. The StackCommerce deal ran for about 3 months. SiteGuru now had 750 users. I ran similar deals with parties like DealFuel and GreeDeals. They weren't bad either. After about 8 months, I finally started to see more organic traffic coming to the site. This contributes to the user growth and required little effort. It just took so long before it took off. I guess that's because the SEO tool market is so competitive. A year in, SiteGuru is now at 950 users. For the first 12 months, you could run a free pagecheck on the homepage, that didn't require you to sign up. I hoped that this would convince people to sign up and get the real deal: a full analysis of your website. Many visitors ran a pagecheck (conversion rate \u00b130%), and seemed to be happy with it (based on their click behavior, time on page, etc.). However, only 5% would sign up. I decided to try something else: the free pagecheck is gone, and you need to sign up to get a pagecheck. The full sitecheck is where the real value is, so I wanted people to see that. Results are very positive: conversion increased from around 5% to 20%. It helped break the barrier of 1000 users (woohoo!), and it continues to grow. A lot of things, but the biggest learning: I should have changed to requiring people to sign up before showing anything much sooner. It helps me demonstrate the value of the tool and gives me a much better conversion. That's it! If you have any suggestions about how I can futher increase user growth, or have any questions, let me know!          \n \n      Learn from the founders behind hundreds of profitable online businesses, and connect with others who are starting and growing their own companies.\n    ","time":1525631771,"title":"How I got my first thousand users","type":"story","url":"https:\/\/www.indiehackers.com\/@RickVanHaasteren\/how-i-got-my-first-1000-users-47d06edc3d"},{"by":"avyfain","descendants":0,"id":17006851,"kids":"None","score":6,"text":"There are few investors I have more respect for than Warren Buffett and Charlie Munger. So much of what I believe as an investor has come from watching them conduct themselves over the last thirty-five years (that\u2019s as long as I have been paying attention to investing as a discipline). I believe in fundamental value, I believe in buying when others are selling, I believe in holding positions you find attractive over very long periods of time, and I believe in a lot more that they have espoused and done. So when I read the two of them disparaging the purchase of crypto assets, it bothers me. Obviously I don\u2019t agree with them, but I am trying to see what they are seeing and disliking. This interview that Buffett did with Yahoo! Finance is instructive. Buffet says: \u201cIf you buy something like a farm, an apartment house, or an interest in a business\u2026 You can do that on a private basis\u2026 And it\u2019s a perfectly satisfactory investment. You look at the investment itself to deliver the return to you. Now, if you buy something like bitcoin or some cryptocurrency, you don\u2019t really have anything that has produced anything. You\u2019re just hoping the next guy pays more.\u201d When you buy cryptocurrency, Buffett continues, \u201cYou aren\u2019t investing when you do that. You\u2019re speculating. There\u2019s nothing wrong with it. If you wanna gamble somebody else will come along and pay more money tomorrow, that\u2019s one kind of game. That is not investing.\u201d It is clear from those words that Buffett sees crypto assets like a baseball trading card or some other form of collectible. And if that were true of Bitcoin, Ethereum, EOS, Zcash, or many other popular crypto assets, I would agree with him. But what these crypto tokens are is entirely something else. They are the fuel that powers a new form of technology infrastructure that is being built on top of the foundational internet protocols. Ethereum and EOS are smart contract platforms that allow developers to create decentralized applications (Dapps in the vernacular of crypto). Bitcoin and Zcash are stores of value that allow users to participate in this decentralized application space without the need for fiat currencies. This is the key phrase of Buffet\u2019s that I feel is incorrect\u00a0\u201cif you buy something like bitcoin or some cryptocurrency, you don\u2019t really have anything that has produced anything.\u201d Crypto-assets produce decentralized infrastructure. Bitcoin has produced a transaction processing infrastructure that looks a lot like Amazon Web Services (something I am sure Buffett would agree is extremely valuable). Ethereum has produced a similar transaction processing infrastructure which is also able to run smart contracts. I believe smart contracts are the most important innovation we have yet seen in crypto. What Buffett and Munger may also be saying is that they don\u2019t know how to value this \u201cfuel\u201d that powers the creation of this decentralized infrastructure. If they are saying that, then I agree with them. I don\u2019t know how to value this fuel either. We cannot use discounted cash flow because this decentralized infrastructure may not produce a lot of cash flow. It is designed to create hypercompetitive networks that are self-commoditizing. It is much more likely that these crypto assets will trade and be valued like currencies that underpin economies. There has been a lot of research and writing on that. I have recommended Chris Burniske\u2019s Cryptoassets book here before and I will do so again. Chris outlines much of this thinking in that book. I doubt Warren and Charlie will read this post. But if they do, the one thing I would hope they take from it is that instead of disparaging crypto assets with words like rat poison and dementia, they take a little bit of time to understand that what we are seeing here is the creation of a new internet, built upon protocols that allow for decentralized networks to form and tokens that allow people and companies to be compensated for that formation. And that cryptoassets are the fuel that power and compensate for that formation. And that purchasing these cryptoassets\u00a0is very much a form of investing. And that this investing is the first time that anyone in the world, independent of wealth and domicile, can participate in venture capital style investing in the next big wave of technology.  \nMay 6, 2018 \u2013 blockchain, crypto, stocks\n \nTweet\n","time":1525622357,"title":"Is Buying Crypto Assets \u201cInvesting\u201d","type":"story","url":"https:\/\/avc.com\/2018\/05\/is-buying-crypto-assets-investing\/"},{"by":"jackfoxy","descendants":196,"id":17006740,"kids":"[17007341, 17007007, 17007098, 17007287, 17007520, 17007482, 17007240, 17008198, 17008256, 17007167, 17008830, 17008008, 17008007, 17007366, 17007497, 17007649, 17011535, 17007892, 17011307, 17009509, 17010865, 17010697, 17010082, 17009670, 17008243, 17008682, 17009130, 17007525, 17007309, 17007509, 17007712]","score":182,"text":"This NASA photo from April 18\u00a0shows a SpaceX Falcon 9 rocket lifting off from Cape Canaveral Air Force Station in Florida while carrying NASA's Transiting Exoplanet Survey Satellite. TESS will search for planets outside of our solar system. This NASA photo from April 18\u00a0shows a SpaceX Falcon 9 rocket lifting off from Cape Canaveral Air Force Station in Florida while carrying NASA's Transiting Exoplanet Survey Satellite. TESS will search for planets outside of our solar system. When Elon Musk and his team at SpaceX were looking to make their Falcon 9 rocket even more powerful, they came up with a creative idea \u2014 keep the propellant at super-cold temperatures to shrink its size, allowing them to pack more of it into the tanks. But the approach comes with a major risk, according to some safety experts. At those extreme temperatures, the propellant would need to be loaded just before takeoff \u2014 while astronauts are aboard. An accident, or a spark, during this maneuver, known as \"load-and-go,\" could set off an explosion. The proposal has raised alarms for members of Congress and NASA safety advisers as the agency and SpaceX prepare to launch humans into orbit as early as this year. One watchdog group labeled load-and-go a \"potential safety risk.\" A NASA advisory group warned in a letter that the method was \"contrary to booster safety criteria that has been in place for over 50 years.\" Concerns at NASA over the astronauts' safety hit a high point when, in September 2016, a SpaceX Falcon 9 rocket blew up while it was being fueled ahead of an engine test. No one was hurt, but the payload, a multimillion-dollar satellite, was lost. The question on many people's minds at NASA instantly became: What if astronauts were on board? The fueling issue is emerging as a point of tension between the safety-obsessed space agency and the maverick company run by Musk, a tech entrepreneur who is well known for his flair for the dramatic and for pushing boundaries of rocket science. In this culture clash, SpaceX is the daring, Silicon Valley-style outfit led by a man who literally sells flamethrowers on the Internet and wholeheartedly embraces risk. Musk is reigniting interest in space with acrobatic rocket-booster landings and eye-popping stunts, such as launching a Tesla convertible toward Mars. His sensibilities have collided with a bureaucratic system at NASA that has been accused of being overly conservative in the wake of two shuttle disasters that killed 14 astronauts. The concerns from some at NASA are shared by others. John Mulholland, who oversees Boeing's contract to fly astronauts to the International Space Station and once worked on the space shuttle, said load-and-go fueling was rejected by NASA in the past because \"we never could get comfortable with the safety risks that you would take with that approach. When you're loading densified propellants, it is not an inherently stable situation.\" SpaceX supporters say tradition and old ways of thinking can be the enemy of innovation and thwart efforts to open the frontier of space. Greg Autry, a business professor at the University of Southern California, said the load-and-go procedures were a heated issue when he served on Trump's NASA transition team. \"NASA is supposed to be a risk-taking organization,\" he said. \"But every time we would mention accepting risk in human spaceflight, the NASA people would say, 'But, oh, you have to remember the scar tissue' \u2014 and they were talking about the two shuttle disasters. They seemed to have become victims of the past and unwilling to try anything new, because of that scar tissue.\" In a recent speech, Robert Lightfoot, the former acting NASA administrator, lamented in candid terms how the agency, with society as a whole, has become too risk-averse. He charged the agency with recapturing some of the youthful swagger that sent men to the moon during the Apollo era. \"I worry, to be perfectly honest, if we would have ever launched Apollo in our environment here today,\" he said during a speech at the Space Symposium last month, \"if Buzz [Aldrin] and Neil [Armstrong] would have ever been able to go to the moon in the risk environment we have today.\" NASA is requiring SpaceX and Boeing to meet a requirement that involves some complicated calculations: The chance of death can be no greater than 1 in every 270 flights. One way to ensure that, as Lightfoot said during his speech, is to never fly: \"The safest place to be is on the ground.\" A robotic geologist armed with a hammer and quake monitor rocketed toward Mars on Saturday, aiming to land on the red planet and explore its mysterious insides. In a twist, NASA launched the Mars InSight lander from California rather than Florida's Cape Canaveral. It was the first interplanetary... Still, the scar tissue runs deep. NASA lost 14 astronauts in two space-shuttle disasters, the result of deep systematic problems of a once young and swashbuckling agency that many said had grown sclerotic. In the investigation into the 2003 disaster, the Columbia Accident Investigation Board blasted NASA for failing to learn \"the bitter lessons\" from the Challenger explosion in 1986. Columbia was lost as much by a \"broken safety culture\" as much as the chunk of foam that broke off and damaged the shuttle's heat shield. That second disaster helped lead to the retirement of the shuttle in 2011, leaving NASA in the position of being unable to fly astronauts from U.S. soil. Instead, NASA pays Russia to ferry its astronauts to the International Space Station, an arrangement that costs the agency millions. In 2006, Russia charged $21.3 million a seat. That jumped to $81.9 million by 2015. To end the dependence on Russia, NASA has turned to the private sector, outsourcing the responsibility of flying astronauts to the space station to two companies \u2014 SpaceX and Boeing \u2014 that have been awarded $6.8 billion in contracts combined. Other private companies eventually could compete for other government launch contracts \u2014 including Blue Origin, which was founded by Washington Post owner Jeff Bezos \u2014 but none are expected to send people to the space station anytime soon. The pivot to private companies is enabling NASA to focus on deep space. But SpaceX and Boeing have both faced challenges and delays. Now, as the drought in human spaceflight extends into its seventh year, NASA is facing the prospect of even more delays \u2014 and questions about whether the contractors it plans to rely on will have a better track record than the agency that put men on the moon. \"It really is a very, very difficult problem to do human spaceflight,\" said Phil McAlister, the director of NASA's commercial spaceflight development division. \"You've got thousands of pounds of really highly energetic propellants on board. You've got mini controlled explosions going off. You've got to survive the rigors of space, which is not very friendly for the human body. And then you've got to reenter the atmosphere, and the spacecraft gets heated up to thousands of degrees.\" SpaceX pulled off 18 successful launches last year, a record, and is aiming for more this year. But it has also lost two of its Falcon 9 rockets in explosions, and amid all its triumphs, it has never attempted flying humans. The first failure happened in 2015, when a rocket blew up a couple of minutes after liftoff as it was flying cargo and supplies to the space station. No one was on board, and no one was injured. Then, just over a year later, another rocket exploded, this time on the launchpad while being fueled ahead of an engine test. At the time, Musk declared that if crews had been aboard they would have been safely ferried away by the rocket's abort system. Still, that mishap is forcing the company to redesign bottles of pressurized helium that sit inside the rocket's fuel tanks. Now SpaceX is getting ready to fly astronauts on an upgraded version of the same rocket. And its decision to add propellant to the rocket with astronauts on board is attracting scrutiny. To get more power out of its rocket, SpaceX brings its propellants \u2014 liquid oxygen and refined kerosene \u2014 to unusually low temperatures. That causes them to become dense, meaning SpaceX can pack more fuel into its rockets. To SpaceX, the approach is another example of how it is breaking the mold. The densified propellant \"provides greater propellant margin for increased reliability,\" the company said in a statement. In other words, should something go wrong on the mission, the rocket would have more propellant to adjust to emergencies. SpaceX's dramatic booster landings also require additional propellant. But to others it is an unnecessary risk. At a Capitol Hill hearing earlier this year, members of Congress pressed Hans Koenigsmann, SpaceX's vice president for build and flight reliability, about the safety of the load-and-go procedure. Koenigsmann said that the fueling takes only about a half-hour, a \"relatively quick procedure, and we believe that this exposure time is the shortest and therefore the safest approach.\" And the company points out that if anything goes wrong during fueling, the rocket's launch abort system would allow the astronauts to escape safely. It also conducts a \"static fire,\" a quick test firing of the engines in the days leading up to the launch to make sure the rocket is operating properly. And since its rockets and its Dragon spacecraft are reusable, the company gets to inspect them after each flight, giving it an in-depth understanding of how the vehicles perform. \"As with all hazard analyses across the entire system and operations, controls against those hazards have been identified, and will be implemented and carefully verified prior to certification,\" the company said in a statement. But in a 2015 letter to NASA, Thomas Stafford, a retired Air Force lieutenant general and then chairman of the agency's space-station advisory committee, wrote that \"there is a unanimous, and strong, feeling by the committee that scheduling the crew to be on board the Dragon spacecraft prior to loading oxidizer into the rocket is contrary to booster safety criteria that has been in place for over 50 years, both in this country and internationally.\" At the hearing this year, William Gerstenmaier, NASA's associate administrator for human exploration and operations, said the agency had not decided whether it would allow SpaceX to load crews before loading the fuel, but he did not rule it out. He vowed that the agency would \"make sure that we're really, really safe to go fly, and the system is ready for crew before we put them on board.\" In an interview, Lightfoot, the former acting NASA administrator, said the agency is in deep discussions with SpaceX about the safest way to go. The agency has a long history with SpaceX, first hiring it to fly cargo to the station and now looking for it to send humans into space. \"It's a matter of having a good risk discussion so that we understand that,\" he said. \"I would just say that instead of working it in the press, we work in the engineering review boards.\" Elon Musk, founder, CEO, and lead designer of SpaceX, speaks Feb. 6 after the Falcon 9 SpaceX heavy rocket launched successfully from the Kennedy Space Center in Cape Canaveral, Fla. Elon Musk, founder, CEO, and lead designer of SpaceX, speaks Feb. 6 after the Falcon 9 SpaceX heavy rocket launched successfully from the Kennedy Space Center in Cape Canaveral, Fla. For all its push-the-envelope swagger, SpaceX says it is serious about flying people safely and is going to great lengths to study every aspect of the vehicle, down to individual valves, so that it will meet and surpass the 1-in-270 chance-of-death metric, said Benji Reed, the director of SpaceX's commercial crew program. When Reed was down at Cape Canaveral, Florida, on a recent trip, he came across a room on a special tour where the astronauts' families from the shuttle program used to wait ahead of the rocket launch. They were stunned to see that a whiteboard with drawings made by the children of the crew lost in the 2003 Columbia disaster was still there, preserved. \"That really drives it home,\" Reed said. \"This isn't just the people that we're flying \u2014 these are all of their families. So we take this extremely seriously, and we understand that our job is to fly people safely and bring them back safely. To do that you have to humanize it. You have to see them as your friends and as your colleagues.\" But even with some of the best engineering minds at NASA, calculating risk is an imperfect science. There are too many unknowns in systems that are inherently dangerous and complex. \"Even identifying all of the risks is impossible,\" Gerstenmaier said during a speech last year. \"Also, risk cannot be boiled down to a single statistic.\" Before the very first shuttle flight, NASA estimated that the chance of death was between 1 in 500 and 1 in 5,000. Later, after the agency had compiled data from shuttle flights, it went back and came up with a very different number. The chance of death was actually 1 in 12.","time":1525620474,"title":"NASA advisers say SpaceX rocket technology could put lives at risk","type":"story","url":"http:\/\/www.chicagotribune.com\/news\/nationworld\/ct-nasa-spacex-rocket-elon-musk-20180505-story.html"},{"by":"johnny313","descendants":150,"id":17006715,"kids":"[17014800, 17014436, 17014576, 17015124, 17013969, 17015282, 17016079, 17018651, 17006789, 17015429, 17017907, 17016153, 17015666, 17015009, 17015685, 17017274, 17015384, 17014864, 17020269, 17014125, 17016228, 17014310, 17015269, 17015099]","score":158,"text":"A team of scientists undertakes an ambitious experiment which could change thinking about welfare FEDERAL Hill House is a squat building in central Providence, within earshot of the city\u2019s main highway. On a recent rainy Monday, a school holiday, the building was full. Older children lounged in front of a film, while toddlers roamed around the soft play area. Some regularly spend more than ten hours a day here, on top of school hours, while their parents work. The charity provides essential support for low-income families: it picks up children from home before school starts, and looks after them long after it ends. It accomplishes a lot on a tight budget. In several places, the ceiling lets through water from the grey Rhode Island sky. The youngest group of children at Federal Hill House are between 18 months and five years old. There are 12 of them, with a waiting list to join. The executive director, Kimberly Fernandez, says some cannot name any colours when they first arrive. Some come to the centre hungry (it provides meals) or speaking no English. Others arrive with behaviour problems. Parents\u2019 work schedules are often so inflexible that Federal Hill must cover basic logistics beyond school pick-up and drop-off. Ms Fernandez says she had to use her own car after some children took the wrong bus home from school and wound up stranded at the depot. Their mother was unable to leave work to fetch them. Upgrade your inbox and get our Daily Dispatch and Editor's Picks. Plenty of evidence suggests that growing up poor, living through these kinds of scrapes, has a detrimental impact on child development. Children from rich families tend to have better language and memory skills than those from poor families. More affluent children usually perform better in school, and are less likely to end up in jail. Growing up poor risks the development of a smaller cerebral cortex. But these are associations between poverty and development, not evidence that poverty causes these bad outcomes, says Kimberly Noble, a neuroscientist at Columbia University in New York. She is part of a team of researchers running a three-year experiment which will, for the first time, search for causal links between parental income level and a child\u2019s early development. The team will start recruiting the first of 1,000 low-income mothers next week. They will be invited to join the study, which is called Baby\u2019s First Years, shortly after giving birth at one of ten hospitals in four cities across the United States (to avoid influencing the experiment, the researchers asked The Economist not to publish details about the cities). Of that 1,000, roughly half will be randomly selected to receive an unconditional $333 a month, while the others will form a control group that will receive $20. The money, which is completely unconditional, will be loaded onto a pre-paid debit card every month for 40 months, on the date of the child\u2019s birthday. The hypothesis is that this steady stream of payments will make a positive difference in the cognitive and emotional development of the children whose mothers receive it. The first data gathered will be baseline interviews with the mothers just after recruitment. This will reveal the various backgrounds from which the mothers come (all will have incomes below the poverty line, roughly $23,000 for a family of three). The researchers will conduct phone interviews with all 1,000 mothers around their child\u2019s first birthday, then visit them in their homes when their children turn two. When they turn three, they will be invited with their mothers to a research lab in their city, where their child\u2019s cognitive skills will be tested and the electrical activity of their brains studied. Living experiment The interviews will also measure mothers\u2019 stress, mental health and employment patterns. They will ask how the amount of time mothers spend with their child is changing, and gather data on the quality and cost of child care and other child-related expenses. The researchers will also have a record of transactions made with the debit card. The unconditional nature of the cash transfer is inviolable: even if mothers choose not to take part in the follow-up studies, for which they are paid extra, they will still get the income for 40 months. The 1,000 mothers, minus potential dropouts, will provide enough statistical power to detect effects equivalent to two months\u2019 worth of development in early childhood, says Greg Duncan, an economist on the team from the University of California, Irvine. A real-world experiment of this magnitude comes with challenges. It has been six years in the making, and the team has spent years raising some $15m for it. About $5.8m will be given away over the next four years, to which must be added the cost of recruiting and monitoring 1,000 people over that time. The researchers worked to get new legislation passed in two states in which the experiment will be carried out, in order to make sure that those taking part remain eligible for public benefits while they receive the extra income. The entire experiment has been assessed by the Institutional Review Board (IRB) at Columbia University\u2019s Teachers\u2019 College, with separate IRB boards at all nine hospitals either verifying those terms, or drawing up their own, before the experiment starts. Ethical approval has been particularly complex, since mothers will be both research subjects and medical patients recovering from childbirth when they sign up. The experiment is unique in two aspects. One is its exclusive focus on the impacts of income, unrelated to employment. The other is its focus on the first three years of a child\u2019s life. \u201cWe know virtually nothing about the causal effects of income in years zero to three,\u201d says Lisa Gennetian, who studies the psychology of poverty at New York University. Ms Gennetian, one of several collaborators on Baby\u2019s First Years, says its closest analogues were carried out in Minnesota in the 1990s. There parents were randomly assigned to a different mix of welfare policies which altered their incomes, and their children\u2019s development was monitored. The Minnesota studies suggested that about $4,000 a year is enough to see significant effects on a child\u2019s development, but because the extra money was connected to parents\u2019 work, they did not control for other factors that might also have influenced the children\u2019s development. In contrast, mothers in the new experiment are free to leave their jobs to look after their new child, if they want to. How to spend it Dr Noble, Ms Gennetian and their colleagues are not alone in their ambition to study the impact of cash on well-being. Y Combinator, a startup accelerator in Silicon Valley, has formed a research arm to investigate the more general impacts of direct cash gifts of this kind. That experiment, which has not yet started, plans to give $1,000 a month to a randomly selected third of 3,000 people from two American states, monitoring any changes in health, time-use and crime induced by the cash. Part of the Baby\u2019s First Years study will be about seeing how the extra cash is spent, but signs already suggest where it might go. In a pilot study of just 30 mothers, run in New York in 2014 to work out the logistics of handing out cash, the money was usually spent within three days of receipt, mostly at supermarkets and department stores. Ms Fernandez says nappies are a particular problem for new mothers on low incomes, as they often cannot afford the upfront membership fees required to shop at large discount supermarkets in the suburbs, or the costs of travelling to get there, and so have no way around paying a premium at nearby corner shops. \u201cFood, diapers and travel,\u201d says Ms Fernandez, is what this money will go towards. \u201cYou know what you do when you can\u2019t afford to buy diapers? You change your baby less often. You let them walk around in a dirty diaper,\u201d says Katherine Magnuson, the team\u2019s poverty expert at the University of Wisconsin-Madison. Ms Fernandez suggests that the experimental money will not so much transform new mothers\u2019 lives, as make it possible for them to take advantage of what they already have. For example, many young parents would like to rely on their own parents for child care, but cannot afford the travel costs to drop their children off. In American cities, where public transport is often scarce and connections are slow, having the money for an extra tank of fuel, or even a lease on a cheap car, might save new parents tens of hours every week. That extra time might be spent with their children, earning extra money, or just improving an otherwise stressful life. The results of the experiment will take years to arrive. If the researchers\u2019 hypothesis, that the unconditional handout will have a positive impact on early child development, is confirmed, then old arguments about welfare will get a new evidentiary kick. It would mean that no amount of reflexive bootstrap-tugging could make up for the disadvantages that poverty casts over a child\u2019s developing brain. In the meantime, families like those at Federal Hill will keep struggling to get by. Tell us what you think of Economist.com Need assistance with your subscription? Get 3 free articles per week, daily \n newsletters and more. \n  Published since September 1843 to take part in\n  \u201ca severe contest between intelligence, which presses forward,\n  and an unworthy, timid ignorance obstructing our progress.\u201d\n Copyright \u00a9 The Economist Newspaper Limited 2018. All rights reserved.","time":1525620059,"title":"Does growing up poor harm brain development?","type":"story","url":"https:\/\/www.economist.com\/news\/united-states\/21741586-team-scientists-undertakes-ambitious-experiment-which-could-change-thinking-about"},{"by":"omarkn","descendants":39,"id":17005810,"kids":"[17006133, 17006149, 17006224, 17006233, 17007478, 17006427, 17008062, 17015797, 17006601, 17007046, 17009187]","score":198,"text":"May 2, 2018 Is it a live virus? An extracellular vesicle that delivers information about a cell? An incomplete and defective virus particle? A vesicle carrying viral components? Classifying\u00a0the closely related particles that cells release can be a challenge. Olena Shmahalo\/Quanta Magazine Contributing Writer May 2, 2018 For cells, communication is a matter of life and death. The ability to tell other members of your species \u2014 or other parts of the body \u2014 that food supplies are running low or that an invading pathogen is near can be the difference between survival and extinction. Scientists have known for decades that cells can secrete chemicals into their surroundings, releasing a free-floating message for all to read. More recently, however, scientists discovered that cells could package their molecular information in what are known as extracellular vesicles. Like notes passed by children in class, the information packaged in an extracellular vesicle is folded and delivered to the recipient. The past five years have seen an explosion of research into extracellular vesicles. As scientists uncovered the secrets about how the vesicles are made, how they package their information and how they\u2019re released, it became clear that there are powerful similarities between vesicles and viruses. A small group of researchers, led by Leonid Margolis, a Russian-born virologist at the National Institute of Child Health and Human Development (NICHD), and Robert Gallo, the HIV pioneer at the University of Maryland School of Medicine, has proposed that this similarity is more than mere coincidence. It\u2019s not just that viruses appear to hijack the cellular pathways used to make extracellular vesicles for their own production \u2014 or that cells have also taken on some viral components to use in their vesicles. Extracellular vesicles and viruses, Margolis argues, are part of\u00a0a continuum of membranous particles produced by cells. Between these two extremes are lipid-lined sacs filled with a variety of genetic material and proteins \u2014 some from hosts, some from viruses \u2014 that cells can use to send messages to one another. \u201cThere are fundamental differences between viruses and vesicles: Viruses can replicate and vesicles cannot,\u201d Margolis said. \u201cBut there are many variants in between. Where do viruses start, and where do extracellular vesicles start?\u201d Whether cells started using vesicles for communication first and viruses copied them, or cells stole the idea from viruses, or both evolved the strategy in tandem is currently impossible to determine: Sending information in extracellular vesicles must have first appeared billions of years ago because\u00a0even bacteria do it. \u201cThis idea of using a membrane-bound sac of information to transport between cells has been around a long time,\u201d said David Meckes, Jr., a virologist at Florida State University. One of the most striking pieces of evidence supporting Margolis and Gallo\u2019s hypothesis is the recent discovery, widely reported in January, that a mammalian protein called Arc, which is implicated in learning and memory, is actually a repurposed retroviral protein. More important, Arc appears to be secreted from the synapses of neurons in extracellular vesicles.\u00a0\u201cThese vesicles may be acting like a viral envelope,\u201d said Cedric Feschotte, a retrotransposon expert at Cornell University. Now that humans are aware of this shared membranous medium for transporting information between cells, the idea is paving the way for new discoveries and the development of new therapeutics for cancer and viral diseases. When scientists first started gazing at cells under powerful light microscopes, they noticed a \u201cdust\u201d of minuscule particles surrounding the otherwise crisp edges of the cell\u2019s plasma membrane. Researchers generally chalked up the debris to the cellular equivalent of dandruff and didn\u2019t pay much attention. Over time, scientists noticed that these membranous flakes appeared in a wide range of cell cultures and body fluids, such as plasma and blood. Some formed by budding directly from the cell membrane itself and were first dubbed microvesicles, and later, extracellular vesicles. Other, typically smaller ones were assembled within the cell before being released through the plasma membrane and became known as exosomes. Extracellular vesicles and exosomes range tremendously in size, from 30 nanometers \u2014 approximately the diameter of a small virus \u2014 to as large as one micron. The quantity of these vesicles is extraordinary: Every day, a cell produces the equivalent of its own plasma membrane in extracellular vesicles and exosomes, according to D. Michiel Pegtel, a vesicle expert at VU University Medical Center in Amsterdam. The field took off in 2006\u20132007 when a Swedish team and a joint American-European group independently discovered that exosomes and extracellular vesicles could carry several types of RNA. These included the messenger RNAs (mRNAs) that are intermediaries in the translation of DNA into proteins, as well as the small molecules called microRNAs that affect gene expression. After the initial discovery of extracellular vesicles and exosomes in blood, scientists found them in nearly every type of body fluid they tested, including saliva, urine, amniotic fluid, breast milk and seminal fluid. Although researchers have begun to classify extracellular vesicles and exosomes into different subtypes, they struggle with finding ways to sort and identify those categories. The realization that vesicles can carry RNAs also invites comparisons to viruses. Some of the vesicles that cells shed are similar in size to viruses, but their molecular cargo and their capabilities are of course different. \u201cWhat inherently separates vesicles and exosomes from viruses is that exosomes are not infectious,\u201d Pegtel said. Even so, the reasons for the similarities are significant. The pioneering immunologist Peter Medawar once asserted that viruses are \u201cbad news wrapped in a protein coat\u201d \u2014 but retroviruses also drape a second layer over their protein shell by wrapping themselves in pieces of their host\u2019s cell membrane. The host-derived membrane protects the virus from discovery by the immune system. When virologists probed the cellular pathways hijacked by these minuscule pathogens, they discovered that viruses get their envelopes by tapping into cells\u2019 preexisting pathway for making exosomes and extracellular vesicles. Not all the viruses encased in cell-derived envelopes are fully intact and functional. Many are the equivalent of lemons in a used car lot: secondhand and not operational. These viral trash heaps covered in membrane can\u2019t infect other cells or perpetuate disease outbreaks. Yet in some cases, on the surface, these vesicles carrying viral junk look nearly identical to those carrying cellular RNA. The similarity was so striking that Margolis realized that some viruses \u2014 like HIV and other small RNA viruses \u2014 and exosomes and extracellular vesicles fall on two different extremes of the same continuum. The defective viruses and viruslike particles extruded from infected cells form the vast middle ground on this field, Margolis says. \u201cCell-cell communication is one of the most ancient mechanisms that makes us who we are,\u201d Margolis said. \u201cSince vesicles resemble viruses, the question of course is whether the first extracellular vesicles were primitive viruses and the viruses learned from extracellular vesicles or vice versa.\u201d Margolis and his colleagues at the NICHD and abroad weren\u2019t the first to notice the similarities between vesicles and viruses, but their 2016 paper in the Proceedings of the National Academy of Sciences was the first to hypothesize that they were two extremes of the same phenomenon. The idea was provocative, said Dirk Dittmer, a virologist at the University of North Carolina at Chapel Hill, because people really weren\u2019t thinking in that way. \u201cBut those are the kinds of things we like to debate late at night, and no one has an answer.\u201d What Margolis\u2019s idea needed was more evidence supporting the close relationship between viruses and exosomes. This support eventually came from two independent labs that weren\u2019t even studying this relationship. When the neuroscientist Jason Shepherd and his postdoc Elissa Pastuzyn at the University of Utah began trying to decode the detailed structure of the Arc protein, they knew nothing about extracellular vesicles. What they did know was that mice lacking the Arc gene were unable to learn from scary situations\u2014a deadly defect for an animal that\u2019s a snack-size morsel for many predators. What\u2019s more, another lab had already forged ahead with a less-detailed structure of the protein, and they were strongly motivated to publish a more detailed paper on Arc. As Pastuzyn repeatedly tried to purify Arc, however, the single protein kept self-assembling into a more complex structure. At first, everyone thought it was a mistake. But when it kept happening, Shepherd and Pastuzyn took a peek under the electron microscope. The protein structure looked familiar. \u201cIt looked like a virus,\u201d she said. \u201cIt was a double-ringed structure, and the resemblance was uncanny. I had no idea that\u2019s what it was.\u201d When Pastuzyn looked up the DNA sequence of Arc in GenBank (the NIH\u2019s depository for all gene sequences), she discovered that the predicted structure of Arc most closely resembled that of Gag, a protein that forms a retrovirus\u2019s capsid shell, which is subsequently encased in a host-derived lipid membrane. Gag isn\u2019t the only culprit, either. What researchers have come to realize is that sometime millions of years ago, part of a retrovirus genome inserted itself into its host\u2019s DNA, and that sequence was then passed on to countless generations of offspring. Around 8 percent of the human genome is ultimately derived from viruses. Although some of this DNA is, in fact, \u201cjunk,\u201d scientists are learning that much of it plays a role in our biology. For the host, these viral genes provide a genetic junk drawer full of nuts and bolts for evolution to play with. Evolution, Shepherd says, is the ultimate MacGyver, referring to the 1980s TV hero who could defuse a bomb with bubble gum and a paper clip. It doesn\u2019t invent things outright in an insomnia-fueled burst of creativity. Instead, evolution tinkers, cobbling together inventive solutions out of the spare parts at hand. \u201cAlthough these viruses aren\u2019t good for individuals, they provide the raw materials for new genes,\u201d Shepherd says. \u201cThey\u2019re a potential gold mine.\u201d In the case of Arc, the Gag-derived viral gene gave mammals a ready-made delivery device that could be packaged in an extracellular vesicle. A retrovirus packages RNA and moves it out of the cell, Feschotte said. \u201cArc has preserved many of these same functions.\u201d About two thousand miles east of Shepherd\u2019s lab in Salt Lake City, Vivian Budnik was also working on Arc in her lab at the University of Massachusetts Medical School. Unlike Shepherd, whose interest in memory and learning spurred his interest in Arc, Budnik became interested in the protein through her studies of extracellular vesicles at the synapse of neurons. In 2009, Budnik and her colleagues generated the first animal model that showed how fruit flies use extracellular vesicles to ferry a protein called Wnt across the synapse. When Budnik read a paper that showed extracellular vesicles could carry microRNA, it made her wonder if the vesicles could also carry messenger RNA. She began looking in the fly version of the Arc protein. Then Travis Thomson arrived in her lab as a postdoc after completing another postdoc in a lab that studied the mobile genetic elements called transposons, many of which resemble viruses. As soon as he saw the mRNA from the Arc gene, he noted that it looked like RNA from a virus and wondered if it also behaved like a capsid. Budnik presented her initial findings on Arc at a closed conference two years ago; Shepherd was sitting in the back and realized Budnik had independently reached the same conclusions about Arc. He approached her afterward and explained his identical findings from a different approach. Budnik and Shepherd soon determined that animals had repurposed a retroviral Gag protein twice: once in flies and once in mammals. In both groups of animals, Arc acts to move RNA across synapses. \u201cThey look very similar. The mechanism on a molecular level is very similar, even though they come from different retrotransposons,\u201d Feschotte said. Shepherd and Budnik agreed to publish their papers in parallel, and did so in January 2018 in Cell. Budnik\u2019s experience with Arc led her to look for other transposons and viral elements transported by extracellular vesicles. Thus far, she has found several, and one of them behaves like Arc. \u201cWe have viruslike sequences throughout our genome, but we have mostly no idea what they do,\u201d Budnik said. This work bolsters the close links between extracellular vesicles and viruses. Meanwhile, Shepherd and his colleagues have been scouring the human genome for other genes similar to Arc. Like Budnik, they\u2019ve found several (their results, too, have yet to be published). The recent explosion of research on extracellular vesicles \u2014 from 135 studies published in 2013 to 1,087 studies in 2017 \u2014 testifies to scientists\u2019 new appreciation of their centrality to cellular functioning. Because extracellular vesicles and exosomes can pass information between cells, scientists have begun to implicate them in everything from cancer to viral infections to basic neural functioning. To Lynne Maquat, an expert on retrotransposons at the University of Rochester, this process shows how parts of the genome we used to think of as junk actually have important functions. \u201cYou could say that the host domesticated a viral sequence for its own purposes,\u201d Maquat said. \u201cThat\u2019s the beauty of our complexity \u2014 [these elements] allow tinkering or fine-tuning of genes.\u201d Although it\u2019s now clear that extracellular vesicles are far from simple cellular debris, and the viral genes littering our DNA aren\u2019t exactly junk, researchers have only just begun to crack the mystery of what they can do. Correction: The article was updated on May 4 to specify\u00a0that Leonid Margolis is affiliated with the\u00a0NICHD\u00a0within the National Institutes of Health. Get Quanta Magazine delivered to your inbox Contributing Writer May 2, 2018 Get Quanta Magazine delivered to your inbox Get highlights of the most important news delivered to your email inbox Quanta Magazine moderates comments to\u00a0facilitate an informed, substantive, civil conversation. Abusive, profane, self-promotional, misleading, incoherent or off-topic comments will be rejected. Moderators are staffed during regular business hours (New York time) and can only accept comments written in English.\u00a0","time":1525598546,"title":"Cells Talk in a Language That Looks Like Viruses","type":"story","url":"https:\/\/www.quantamagazine.org\/cells-talk-in-a-language-that-looks-like-viruses-20180502\/"},{"by":"velmu","descendants":68,"id":17005769,"kids":"[17006407, 17006312, 17008179, 17006830, 17006292, 17006318, 17006495, 17007468, 17009075, 17007654, 17006701, 17006337, 17008000, 17006342, 17007623, 17006280]","score":101,"text":"Metropolitan.fi\nNews from Finland in English\n Passengers traveling on the Baltic sea on the Viking Grace vessel can now observe a 24 meter high spinning tube on deck. The structure is a rotary sail, a first of it's kind installed on a passenger ship. The rotor sail is installed on the Grace is built by a Helsinki based company Norsepower. The cylinder shaped sail uses the wind as propulsion, and reduces the need for the main engine. Viking Grace deployed the sail on the 12th of April 2018.  Use of the rotary sail takes advantage of the Magnus effect to fuel and emission savings. The pilot project hopes to save 300 tons of LNG fuel each year. Carbon dioxide emissions are reduced by 900 tons. In addition to reduced strain on the environment, the rotary sail is a strong financial incentive. On the Grace the Norsepower sails are projected to yield the shipping company Viking Line with savings of 180,000 euros annually. Profits out of thin air. Norsepower is also working together with Maersk shipping company. One of the company's oil tankers will get two 30 meter rotor sails later this year. The sails are expected to result in fuel savings of up to 20 percent for the Maersk pilot vessel project, but the average savings are said to be around 10 percent on global shipping routes. The shipping industry is under pressure to reduce emissions. If rotor ships catch wind on the global shipping market, Norsepower could be entering a market worth some 30 Billion euros. The number is estimated from the 25,000 ships' 1.2 MEUR install cost. Norsepower remains conservative, and pegs it's 2024 revenue target at a mere 100 Million euros. See an introduction video to the Viking Grace with the Norsepower rotary sail below: \n\u00ab National Coalition Party to propose canning state alcohol monopoly Alko\n                                -\n                                                    Nokia Android smartphones claim eleven percent marketshare in Finland \u00bb\n Entries overview \u00bb Formula 1 Facts overview \u00bb Pages overview \u00bb \nBuilt with Bolt and Silex\nand Delivered by CloudFlare.\n\n                    A part of the Bootstrap Content Network.\n                \n                ","time":1525596942,"title":"Rotor sail helps Finnish ferry Viking Grace reduce fuel consumption","type":"story","url":"https:\/\/metropolitan.fi\/entry\/rotor-sail-helps-finnish-ferry-viking-grace-reduce-fuel-consumption"},{"by":"hendricius","descendants":19,"id":17005764,"kids":"[17006736, 17006612, 17006369, 17005768, 17006314, 17006592, 17007043, 17006485, 17006765, 17006304, 17006561, 17007382]","score":69,"text":" Use this basic dough recipe as starter for all your upcoming sourdough breads.\nIt is very similar to the standard yeast bread recipe with one major\ndifference. Instead of using industrial yeast, we are using our own sour\ndough. The bacteria and yeast will create all the gas to make the loaf nice\nand fluffy. Using sourdough instead of yeast creates nice sour taste\nwhich creates a pleasant taste experience. The sourish taste comes from the bacteria\ncreating lactic acid. Sourdough converts your whole bread into something fully natural. A sourdough bread only contains flour, water and salt.\nBread has been baked like this for thousands of years. As a side effect your bread will become much more resistant to mold. A sourdough bread\ncan still sometimes be eaten 3-4 weeks after the bake. In your sourdough bread\nbacteria and yeast wage war on each other, blocking each other from taking over the bread.\nIn a yeast bread you do not have bacteria to counteract the yeast.\nThus the yeast bread turns inedible much faster. Overall you can bake every yeast-bread with sourdough instead. You only have to consider\nthat your sourdough is at 100% hydration. Thus you need to adjust the hydration\nlevel on the yeast bread you bake to compensate for the added hydration. This does not\nwork the way around though. You can not bake all the sourdough recipes\nwith yeast instead. Some flours such as rye require the sourdough to become\nbake able. See the picture above for a comparison of how the final sourdough vs.\nyeast bread looks like. Other sourdough recipes in the manifesto inherit from this recipe. They override\na few sections with custom steps and or ingredients. The process regardless is\nalways the same across all the sourdough breads you will bake. Inspirational\nideas are provided as custom recipes in this repository. From a programming\nperspective this recipe is an abstract class that you can't directly\nbake. Please see the standard sourdough bread recipe\nfor an actual recipe you can bake. If you do the math you will end up with 325 grams of water and another 100 grams of water\nfrom the sourdough = 425 grams water in total. Then you have 500 grams of flour\nplus another 100 grams from the sourdough starter. Which means you have a total of\n600 grams of flour in your bread. With 425 grams of water you have a ratio of approximately\n70% hydration in the dough. This is less than on the simple yeast bread.\nHowever since you utilize strong or full grain flour for your sourdough baking\nbecomes more difficult. The dough is much stickier and harder to handle. Thus the combination\nof 40% sourdough on the flour creates an excellent bread which is not too hard to handle. 8 hours before you start the bake remove the mother sour dough from your fridge.  The dough is feeling kind of cold and freezing. Even worse - your dough is hungry!\nDo you hear the bacteria and yeast asking for food? Our goal is to make the dough feel nice again. However - bad luck. For the dough,\nnot the whole dough will be fed, only parts of it. Sometimes I feel bad for the\nother unlucky part that is unlucky, left in the cold and will receive no food.\nWe always feed equal amounts of flour and water to our mother dough just like\nwe did when we initially grew our mother dough. We need 200 grams of sourdough for the recipe. Since we do not want to use our\nfull mother dough we start feeding parts of the mother dough with new flour.\nSome of the mother dough is always left in the fridge for the next bake.\nAlso it could be that the feeding goes bad and you have to throw away your\nnewly fed dough. Realistic example - your cat ate the whole sourdough. What\nnow? You have to wait another 7 days to make your next batch of sourdough! Anyways - 200 grams of sourdough are needed for the bake. We will use 100\ngrams of our mother sourdough and 100 grams of feeding. Things become a little\ncomplex here. Your mother dough is really hungry and will convert approximately\n5 percent of the dough into gas. For that reason we will always make 5% more\nthan we actually need. At the same time 100 grams of mother dough need to go\nback to the fridge. Else we would end up consuming our mother dough until we\nhave none left! So what we need to calculate is 200 grams for the recipe and\n100 grams back to mommy. Add another 5 percent because the yeast and bacteria\nare super hungry. Step 1: In a large bowl in front of you place 100 grams of mother dough.  Step 2: Add 105 grams of full grain or strong flour. Step 3: Add 105 grams of warm water.  You will end up having 310 grams of sourdough starter in\nfront of you. Step 4: Stir everything nicely together. You should end up with a homogeneous\ndough in front of you. If you have less than 8 hours until your bake, you can use\nslightly warmer water. That will re-activate your mother dough faster. However\nI usually mix everything together the evening before I want to bake. Over\nnight everything is ready. This is how your starter should look the next morning. Notice all the\nbubbles that are in the starter. I used rye to feed my starter. But you can\nuse any other strong flour that you have available. I tested all purpose flour\nbut the mother dough turned too sour too fast.  Mix together all the ingredients in a large bowl except the mother dough.\nStir them with a spoon for 2 minutes. Let the dough rest for an hour after\nthis step to have the flour absorb the water.  Furthermore the atoms will\nhomogenize and spread evenly throughout the dough. This will already\ngive you basic gluten structure. Place the 200 grams mother dough evenly on top of your dough. Many sources claim this\nshould be done after the autolysing. However, when baking myself I sometimes add\nthe mother dough right away and could so far not notice a significant difference. I\njust follow this best practice and it works. It bothers me a little that I\nhave not fully tested this myself yet. It would be really good to conduct more\nresearch here with a couple of A\/B tests. We removed 200 grams of our starter in the previous step.\nWe now return the rest of what is left back to the mother dough.\nPlace the mother though container in the fridge and\ncover it. We will re-use the mother dough on the next bake again. This way\npeople sometimes have a 100 year old sour dough. They always return parts back\nto their original mother dough. We mixed everything together we now want to develop the gluten. For that we\nsimply start kneading the dough. Place the dough in front of you on a lightly\nfloured surface and and knead it. You can also simply knead it in the bowl in\nfront of you. There is no special kneading technique. Imagine the dough is\nsomeone you do not like. You want to squeeze that person out. That's how you\ndo the kneading. Do this for around 10 minutes. If you have a dough kneading\nmachine, use that one instead.  On the left hand side you can see my sour dough after the initial kneading. On\nthe right hand side I A\/B tested a dough with yeast instead. We will let the dough rest covered in a bowl for around 4 hours. During that\ntime the mother dough's yeast will spread even more throughout the other dough\ningredients. You can also prolong en this step. The result will be a more sour\ntaste as the bacteria produces more lactic acid. Feel free to experiment on\nthe duration. After 4 hours your dough should already have increased in size.\nSome bubbles should be see-able. This means the yeast starting njamnjam on the\ndough and released gas. If the dough did not raise after 4 hours just wait\nanother X hours until this happened. It can happen that your mother dough is\nnot as reactive as mine. There is different yeast and bacteria even across\nvillages next to each other. In Germany villages sometimes trade the sourdough\nbetween each other for baking.  You can already see bubbles forming in the dough above. That is how the dough\nlooked like after 60 minutes. After the gluten-forming period we will proceed and shape the dough. Don't\nworry the dough will collapse. That is natural. After shaping the dough will\nrest another 60 minutes and increase in size again. Not all gas is removed\nfrom the dough. Experiment here with less kneading when shaping. Less kneading\nmeans your dough will keep more gas. That way for instance air bubbles\nwill be significantly larger in the final bread. Follow the steps for shaping exactly (one exception) as described in the basic dough recipe.\nFlour the surface slightly more as the sourdough is a little more sticky. That\nwill help you a lot with shaping on your initial bakes. Reduce the amount of\nflour later on. The less flour you add here, the more fluffy your bread\nbecomes. Do not worry too much about this at the start. Follow the steps of the basic dough. It is the same for your sourdough. Follow the steps of the basic dough. It is the same for your sourdough. Follow the steps of the basic dough. It is the same for your sourdough. Follow the steps of the basic dough. It is the same for your sourdough. Follow the steps of the basic dough. It is the same for your sourdough. Follow the steps of the basic dough. It is the same for your sourdough. Done!  The above is an implementation of this recipe. It is the most common sourdough\nbread eaten in Germany","time":1525596835,"title":"The Basic Sourdough","type":"story","url":"https:\/\/github.com\/hendricius\/the-bread-code\/blob\/master\/basics\/basic-sour-dough.md"},{"by":"DanBC","descendants":60,"id":17005589,"kids":"[17006277, 17006946, 17006213, 17006907, 17008402, 17009042, 17011371, 17008089, 17006921, 17006916, 17007702]","score":97,"text":"We use cookies to provide you with a better onsite experience. By continuing to browse the site you are agreeing to our use of cookies in accordance with our Cookie Policy. (examples: physics, climate change, etc.) That\u00a0was the ruling by the editors of the authoritative Diagnostic and Statistical Manual in 2013, but it remains controversial Five years ago, the American Psychiatric Association (APA) established autism spectrum disorder (ASD) as an umbrella term when it published the fifth edition of the Diagnostic and Statistical Manual (DSM-5), the primary guide to taxonomy in psychiatry. In creating this single diagnostic category, the APA also removed the subgroup called Asperger syndrome that had been in place since 1994.\u00a0 At the 2018 annual meeting of the International Society for Autism Research (INSAR), there will be plenty of discussion about diagnostic terminology: Despite the many advantages of a single diagnostic category, scientists will be discussing whether, to achieve greater scientific or clinical progress, we need subtypes.\u00a0 THE ADVANTAGES OF A SINGLE DIAGNOSTIC LABEL The APA created a single diagnostic label of ASD to recognize the important concept of the spectrum, since the way autism is manifested is highly variable. All autistic individuals share core features, including social and communication difficulties, unusually narrow interests, a strong need for repetition and, often, sensory issues. Yet these core features vary enormously in how they are manifested, and in how disabling they are. This variability provides one meaning of the term spectrum, and the single diagnostic label ASD makes space for this considerable variability. The term spectrum also refers to the heterogeneity in autism. There are huge disparities in many areas, such as language development or IQ, and in the presence or absence of co-occurring medical conditions and disabilities. This heterogeneity is also part of what is meant by a spectrum. And some autistic people also have very evident talents. This is another sense of the term spectrum, and the single diagnostic label makes room for this source of diversity, too. There have been other benefits of the ASD label: It allows the clinician to describe the person without shoehorning them into a rigid subgroup. Its flexibility also allows for individuals who previously transitioned between different subgroups. And it reduced the risk that service providers might exclude a person because they didn\u2019t meet the eligibility criteria based on a rigid subtype. So, the consensus among clinicians is that the addition of the word \u201cspectrum\u201d was helpful and long overdue. Most clinicians therefore find it useful to have the flexibility of the very broad single diagnostic label.\u00a0 Among proponents of a single diagnostic label, there is some debate about whether we should call it ASD (autism spectrum disorder) or ASC (autism spectrum conditions). This is because some people find the word \u201cdisorder\u201d potentially stigmatizing, and argue that the word \u201ccondition\u201d is equally effective in signaling a medical diagnosis. But leaving this point aside, many scientists are debating what got lost when subgroups were dropped. THE DOWNSIDES OF A SINGLE DIAGNOSTIC LABEL One main reason given by the APA for deleting Asperger Syndrome (AS) was that diagnosis was unreliable. With hindsight, we can see that differentiating AS from classic autism was not the problem. The problem was differentiating AS from high-functioning autism (HFA), a term used by some to refer to autistic people with a history of language delay but with an IQ in the average or above-average range.\u00a0 Most everybody now agrees that the terms high- versus low-functioning were stigmatizing and\u00a0therefore should be avoided, but the clear contrast between AS and classic autism might have had value and perhaps should have been retained and likely could have been distinguished with high reliability. And for many, the term AS had even become part of their identity; it felt like more than just a diagnosis.\u00a0 A widely held view is that medicine makes more progress by identifying subgroups, and AS versus classic autism were two very useful subgroups, because they are quite different in terms of likely levels of independence and educational and occupational attainment. Many parents, such as Alison Singer in her keynote speech in the 2017 INSAR annual meeting, also argued that by lumping AS and classic autism together, the breadth of autistic individuals is not adequately represented\u2014that the single diagnostic category benefits neither subgroup. For those who may think we should revert to two major subgroups, it is no longer clear that AS would be the right name for one of these, given recently published research about Hans Asperger colluding with the Nazi eugenics program during World War II. Those in the autism community who identify as having AS, and others, are actively discussing this difficult question. But the main argument against a single diagnostic label is that the inclusion of subtypes will likely lead to greater scientific progress in understanding the precise causes of the heterogeneity, and greater translational progress in understanding what kinds of interventions and support are needed, and for whom.\u00a0 A MODERATE PROPOSAL One obvious way forward would be to do what other medical diagnoses (such as Diabetes) have done, and introduce a typology of subgroups, as in type 1 and type 2. So, it\u2019s not about either having a single diagnostic label or subgroups. One can have both. Under this approach, we could keep the single umbrella category called the autism spectrum and within this have type 1, type 2, etc.\u00a0 This could maintain the DSM-5\u2019s flexibility, so that a person could transition freely between subtypes as they change across their development. Type 1 could be mapped on to what was formerly known as AS, and type 2 on to what was formerly known as classic autism. Other subtypes will undoubtedly follow, such as the syndromic forms of autism that are due to rare genetic mutations, to become type 3 and so on.\u00a0 Some may worry that this simply reintroduces the high- versus low-functioning distinction. Others will say it avoids the stigmatizing language while recognizing the value of marking the significant differences within the spectrum. Some may argue that this places too much reliance on IQ tests that frequently underestimate the intelligence of autistic people, who might be mistakenly subtyped as type 2 when they are really type 1.\u00a0 But by allowing flexible transitioning, there may be ways to get around this concern. Clinicians will need to have a very flexible notion of intelligence, and not stick rigidly to any specific test, such as a verbal IQ test.\u00a0 Interestingly, the DSM-5 does already have the option to recognize subtypes, referred to as \u201cspecifiers,\u201d and invites clinicians to use these to capture co-occurring conditions. But there may be value in explicitly recognizing subgroups within the autism spectrum, while keeping the helpful concept of specifiers. An individual could have type 1 autism with ADHD, or type 2 autism with language impairment, for example.\u00a0 There will be others who argue that we should only subtype on the basis of biology, not psychology, since in other medical conditions such as diabetes, subgrouping into type 1 and type 2, etc., is based on discovering different causal\/mechanistic factors, which have different prognostic or therapeutic implications.\u00a0 I can\u2019t wait to be at the INSAR 2018 annual meeting this year to listen to the arguments about whether we should subtype the autism spectrum, and if so what is the most useful way to do so. And to learn about the latest cutting edge scientific research that can be harnessed to improve the lives of autistic people and their families.\u00a0 The views expressed are those of the author(s) and are not necessarily those of Scientific American.  Simon Baron-Cohen Simon Baron-Cohen is director of the Autism Research Center at Cambridge University and president of the International Society for Autism Research (INSAR). 0 minute ago  \u2014  Everyday Einstein Sabrina Stierwalt May 9, 2018  \u2014  Lee Riley 1 hour ago  \u2014  Sara Reardon and Nature magazine 1 hour ago  \u2014  Daniel Barron 1 hour ago  \u2014  John R. Platt 1 hour ago  \u2014  Shannon Hall Neuroscience. Evolution. Health. Chemistry. Physics. Technology. Follow us \u00a9 2018 Scientific American, a Division of Nature America, Inc. All Rights Reserved.  Get the perfect gift for mom","time":1525591842,"title":"Is It Time to Give Up on a Single Diagnostic Label for Autism?","type":"story","url":"https:\/\/blogs.scientificamerican.com\/observations\/is-it-time-to-give-up-on-a-single-diagnostic-label-for-autism\/"},{"by":"Jaruzel","descendants":46,"id":17005587,"kids":"[17006156, 17005947, 17006206, 17006853, 17006075, 17006301, 17006581, 17006827, 17006198, 17005916, 17005945, 17006724]","score":58,"text":"Front page layout Site theme Sign up or login to join the discussions! \nRon Amadeo\n    -  May 4, 2018 3:40 pm UTC\n A report from AdAge claims that Google News will soon be going through some more changes. According to the report, Google News is getting a \"new design\" and will \"incorporate elements of the [Google Play] Newsstand app and YouTube.\" The new Google News will reportedly be powered by Google's stripped-down, quick-loading AMP technology and is expected to launch at Google I\/O 2018. Further ReadingGoogle I\/O 2018 preview\u2014What we\u2019re expecting from Google\u2019s big showGoogle has apparently been talking to publishers about the design, and AdAge quotes one anonymous publishing executive as saying, \"It's a consolidation of all the ways you can interact with news on Google...There are a lot of Google services where you find news, and what they're trying to do is bring it all under one brand.\" A Google News redesign is surprising considering that the current design is less than a year old. It's unclear if the current design is just being tweaked to incorporate YouTube and Play Newsstand or if the whole thing is being scrapped and rebuilt. The report also mentions that Google News will get a new app. Google Play Newsstand is currently an odd hybrid of magazine store and RSS reader.\u00a0The report says that Google Play Newsstand is going to close as part of the Google News redesign. This is the second time we've heard of a \"Google Play\" brand getting the axe: Google Play Music is also expected to close when it merges with YouTube. It sure sounds like the awkward \"Google Play\" branding is slowly dying across Google. The Google Play brand currently consists of the Google Play Store (Android's app store), Google Play Movies & TV, Google Play Music, Google Play Books, and Google Play Newsstand. It would be easy to imagine the media apps\u2014Music and Movies & TV\u2014all merging into YouTube. The Android app store needs to stick around, of course, and Google Books could go back to being a standalone service. We'll know a lot more after Google I\/O kicks off next week, starting Tuesday, May 8. You must login or create an account to comment. Join the Ars Orbital Transmission mailing list to get weekly updates delivered to your inbox.","time":1525591803,"title":"Google News to be revamped, incorporate YouTube videos and magazines","type":"story","url":"https:\/\/arstechnica.com\/gadgets\/2018\/05\/google-news-to-be-revamped-incorporate-youtube-videos-and-magazines\/"},{"by":"jkuria","descendants":61,"id":17005569,"kids":"[17007452, 17007071, 17008755, 17006994, 17007459, 17007677]","score":44,"text":"Photo: Thomson Safaris guest, Fain Zimmerman They\u2019re closely related to horses, and they already sport a SWEET paint job, so why haven\u2019t we been riding on zebras for the last few hundred years? Has no one ever thought to domesticate these seemingly ready-made forms of African transport? They have tried, many times in fact. In the late 19th\u00a0and early 20th\u00a0century, there was something of a fad for taming zebras. It\u2019s just never gone that well. In the mid-19th\u00a0century, George Grey imported zebras from South Africa to New Zealand, where he was taking up a governorship, to pull his carriage. The Victorian-era zoologist Lord Walter Rothschild likewise trained zebras to pull vehicles, famously driving a zebra-drawn carriage to Buckingham Palace. And in the early 20th\u00a0century, Rosendo Ribeiro, the first doctor in Nairobi, allegedly made house calls on zebraback. Renowned\u00a0zoologist, Walter Rothschild driving\u00a0a zebra-drawn carriage to Buckingham Palace\n\u201cWalterRothschildWithZebras\u201d by unknown \u2013 The Picture Magazine (publ.: George Newnes). Licensed under Public Domain via Wikimedia Commons \u2013 http:\/\/commons.wikimedia.org\/wiki\/File:WalterRothschildWithZebras.jpg#mediaviewer\/File:WalterRothschildWithZebras.jpg Beyond the contemporary colonial fad for \u201cgoing native,\u201d there were very practical reasons driving the trend. Zebras were already abundant in many of the regions colonialists were penetrating; domesticating the herds would save them the expense and difficulty of importing horses. More importantly, zebras were resistant to the diseases carried by tsetse flies, diseases that were highly fatal to horses. But while one-off attempts to tame a single animal may have been successful, domesticating them\u2014breeding captive herds specifically for human use\u2014proved impossible. They were easily agitated, aggressive when cornered (biting and kicking so hard they could easily maim or kill a would-be rider), and bad tempered. And while they could carry an adult human, they were significantly smaller than European horses; the discomfort of having a passenger for any length of time was likely to activate their worst tendencies, even if they\u2019d been successfully \u201cbroken.\u201d Even Lord Rothschild, the most flamboyant proponent of zebra-transport, never attempted to ride them; he stopped at harnessing them to a carriage. There\u2019s a reason\u2014or a million mini-reasons, depending how you think about it\u2014why zebras just never took to settling down. The quick-and-dirty answer? Evolution. The African landscape is very different for equine species than that of western Europe. Multiple large-animal predators\u2014like lions, leopards, hyenas, and crocodiles\u2014mean prey species, like zebra, must develop intense early-warning mechanisms in order to survive. They have to be jumpier, basically, because they have more predators to fear. This has also led to the zebra\u2019s occasional bursts of violence; when cornered in the wild, they have to be ready to strike their attackers\u2026hard. Moreover, zebras have evolved alongside man, whereas European animals mostly evolved in the absence of man (we didn\u2019t migrate out of Africa until relatively recently). That means zebras are hardwired to view us as threats, too. A few patient weeks in a stable aren\u2019t enough to undo generations of natural selection, as zebras in captivity prove time and time again: they\u2019re the animal responsible for the most injuries to zookeepers every single year. But the dream of a domesticated zebra lives on. As recently as 2013, a teenager in Virginia, Shea Inman, attempted to train a zebra to bear a rider. Through extreme patience and rewards-based training, she\u2019s managed some success, but she notes that even now, \u201cSome days it\u2019s like he\u2019s been riding for 30 years and other days he acts like he\u2019s never seen a human being.\u201d We don\u2019t love those odds, which is why we\u2019ll let zebras keep living as nature intended: without us. \n            Professional photographer, Andy Biggs, just returned from leading two back-to-back Photography Safaris\u00a0 in Tanzania. He searche...           Read More  \n            Jane\u2019s grandchildren are always excited to learn about her extensive travels around the globe. They keep track of her journeys ...           Read More  \n            This was the best trip I\u2019ve ever been done! Everything worked like clockwork the entire trip, from registration to the last mor...           Read More  \n            Queen was known as much for their flamboyant, over-the-top performances as their hit songs\n\u00a0\u201cFreddie Mercury performing in New ...           Read More  Keep a lookout on your inbox for safari news and promos Privacy Policy \u00a9 2018 Thomson Safaris, A Division Of Wineland-thomson Adventures, Inc. Website by Leap XD Reserve Now Free Catalog","time":1525591195,"title":"Wild Horses Can\u2019t be Broken: Zebra Domestication Attempts (2014)","type":"story","url":"https:\/\/thomsonsafaris.com\/blog\/taming-zebras-domestication-attempts\/"},{"by":"gcatalfamo","descendants":29,"id":16987210,"kids":"[16987395, 16987419, 16987402, 16987427, 16987519, 16987530, 16990602, 16991852, 16987407, 16987729, 16988032, 16987470]","score":146,"text":"Achieving GDPR Compliance shouldn't feel like a struggle. This is a basic checklist you can use to harden your GDPR compliancy.  if your organisation is determining the purpose of the storage or processing of personal information, it is considered a controller. If your organisation stores or processes personal data on behalf of another organisation, it is considered a processor. It is possible for your organisation to have both roles. Use the filter below to view only the relevant checklist items for your organisation. This list is far from a legal exhaustive document, it merely tries to help you overcome the struggle.Feel free to contribute directly on GitHub! Your company has a list of all types of personal information it holds, the source of that information, who you share it with, what you do with it and how long you will keep it This is a list of the actual types (columns) of information being held (eg Name, social security nr, address,..). For each type, a source should be documented, the parties this information is shared with, the purpose of the information and the duration for which the company will keep this information.Read more: Your company has a list of places where it keeps personal information and the ways data flows between them This could be a list of databases (eg Mysql), but it could also include offline datastores (paper).Read more: Your company has a publicly accessible privacy policy that outlines all processes related to personal data. You should include information about all processes related to the handling of personal information. This document should include (or have links to) the types of personal information the company holds, and where it holds them. Read more: Your privacy policy should include a lawful basis to explain why the company needs to process personal information It should contain a reason for data processing, eg the fulfillment of a contract.Read more: Your company has appointed a Data Protection Officer (DPO) This person should have knowledge of GDPR guidelines as well as knowledge about the internal processes that involve personal information.Read more: Create awareness among decision makers about GDPR guidelines Make sure key people and decision makers have up-to-date knowledge about the data protection legislation.Read more: Make sure your technical security is up to date.  For SaaS software companies, use the SaaS CTO security checklist as a starting point below.Read more: Train staff to be aware of data protection A lot of security vulnerabilities involve cooperation of an unwitting person with access to internal systems. Make sure your employees are aware of these risks.Read more: You have a list of sub-processors and your privacy policy mentions your use of this sub-processor You should inform your customers of the use of any sub-processor. They should consent by accepting your privacy policy.Read more: If your business operates outside the EU, you have appointed a representative within the EU. If you have a business outside of the EU and you collect data on EU citizens, you should assign a representative in one of the member states for your business. This person should handle all issues related to processing. In particular, a local authority should be able to contact this person.Read more: You report data breaches involving personal data to the local authority and to the people (data subjects) involved Personal data breaches should be reported within 72 hours to the local authority. You should report what data has been lost, what the consequences are and what countermeasures you have taken. Unless the data leaked was encrypted, you should also report the breach to the person (data subject) whose data you lost.Read more: There is a contract in place with any data processors that you share data with  The contract should contain explicit instructions for the storage or processing of data by the processor. For example, this could include a contract with your hosting provider.Read more: Your customers can easily request access to their personal information If you do not already have a process defined for this, we've made an easy online form below.Read more: Your customers can easily update their own personal information to keep it accurate If you do not already have a process defined for this, we've made an easy online form below.Read more: You automatically delete data that your business no longer has any use for You should automate deletion of data you no longer need. For example, you should automatically delete data for customers whose contracts have not been renewed.Read more: Your customers can easily request deletion of their personal data If you do not already have a process defined for this, we've made an easy online form below.Read more: Your customers can easily request that you stop processing their data If you do not already have a process defined for this, we've made an easy online form below.Read more: Your customers can easily request that their data be delivered to themselves or a 3rd party If you do not already have a process defined for this, we've made an easy online form below.Read more: Your customers can easily object to profiling or automated decision making that could impact them This is only applicable if your company does profiling or any other automated decision making. If you do not already have a process defined for this, we've made an easy online form below.Read more: Ask consent when you start processing a person's information If your website collects personal information in some way, you should have an easily visble link to your privacy policy and confirm that the user accepts your terms and conditions.Read more: Your privacy policy should be written in clear and understandable terms  It should be written in clear and simple terms and not conceal it's intent in any way. Failing to do so could void the agreement entirely. When providing services to children, the privacy policy should be easy enough for them to understand.Read more: It should be as easy for your customers to withdraw consent as it was to give it in the first place If you do not already have a process defined for this, we've made an easy online form below.Read more: If you process children's personal data, verify their age and ask consent from their legal guardian For children younger than 16, you need to make sure a legal guardian has given consent for data processing. If consent is given via your website, you should try to make sure approval was actually given by the legal guardian (and not by the child).Read more: When you update your privacy policy, you inform existing customers for example, by emailing upcoming changes of your privacy policy. Your communication should explain in a simple way what has changed.Read more: You regularly review policies for changes, effectiveness, changes in handling of data and changes to the state of affairs of other countries your data flows to. You should follow up on best practies and changes to the policies in your local environment. Sign up at the bottom of this page to receive major updates to this list.Read more: Your business understands when you must conduct a DPIA for high-risk processing of sensitive data. This is only applies to businesses carrying out large-scale data processing, profiling and other activities with high risk to the rights and freedoms of people. A special assessment should be carried out in these cases.Read more: You should only transfer data outside of the EU to countries that offer an appropriate level of protection You should also disclose these cross-border data flows in your privacy policy.Read more: The information above is not the same as legal advice, where an attorney applies the law to your specific circumstances, so we insist that you consult an attorney if you\u2019d like advice on your interpretation of this information or its accuracy. In a nutshell, you may not rely on this as legal advice, nor as a recommendation of any particular legal understanding. Privacy Policy Co-founder Apideck, Beatswitch & Crowdbase Co-founder Knowlex, Officient, Futureproofed & Teamleader Co-founder Next Ventures, Beatswitch & CSD Wunderman","time":1525363853,"title":"GDPR compliance checklist","type":"story","url":"https:\/\/gdprchecklist.io\/"}]